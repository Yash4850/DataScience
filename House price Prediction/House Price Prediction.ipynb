{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Competition for House Prices: Advanced Regression Techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#for removing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011156</td>\n",
       "      <td>-0.010601</td>\n",
       "      <td>-0.033226</td>\n",
       "      <td>-0.028365</td>\n",
       "      <td>0.012609</td>\n",
       "      <td>-0.012713</td>\n",
       "      <td>-0.021998</td>\n",
       "      <td>-0.050298</td>\n",
       "      <td>-0.005024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029643</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>-0.046635</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.057044</td>\n",
       "      <td>-0.006242</td>\n",
       "      <td>0.021172</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>-0.021917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>0.011156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.386347</td>\n",
       "      <td>-0.139781</td>\n",
       "      <td>0.032628</td>\n",
       "      <td>-0.059316</td>\n",
       "      <td>0.027850</td>\n",
       "      <td>0.040581</td>\n",
       "      <td>0.022936</td>\n",
       "      <td>-0.069836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012579</td>\n",
       "      <td>-0.006100</td>\n",
       "      <td>-0.012037</td>\n",
       "      <td>-0.043825</td>\n",
       "      <td>-0.026030</td>\n",
       "      <td>0.008283</td>\n",
       "      <td>-0.007683</td>\n",
       "      <td>-0.013585</td>\n",
       "      <td>-0.021407</td>\n",
       "      <td>-0.084284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>-0.010601</td>\n",
       "      <td>-0.386347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.426095</td>\n",
       "      <td>0.251646</td>\n",
       "      <td>-0.059213</td>\n",
       "      <td>0.123349</td>\n",
       "      <td>0.088866</td>\n",
       "      <td>0.193458</td>\n",
       "      <td>0.233633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088521</td>\n",
       "      <td>0.151972</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.070029</td>\n",
       "      <td>0.041383</td>\n",
       "      <td>0.206167</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>0.351799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>-0.033226</td>\n",
       "      <td>-0.139781</td>\n",
       "      <td>0.426095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105806</td>\n",
       "      <td>-0.005636</td>\n",
       "      <td>0.014228</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>0.104160</td>\n",
       "      <td>0.214103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171698</td>\n",
       "      <td>0.084774</td>\n",
       "      <td>-0.018340</td>\n",
       "      <td>0.020423</td>\n",
       "      <td>0.043160</td>\n",
       "      <td>0.077672</td>\n",
       "      <td>0.038068</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>-0.014261</td>\n",
       "      <td>0.263843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>-0.028365</td>\n",
       "      <td>0.032628</td>\n",
       "      <td>0.251646</td>\n",
       "      <td>0.105806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091932</td>\n",
       "      <td>0.572323</td>\n",
       "      <td>0.550684</td>\n",
       "      <td>0.411876</td>\n",
       "      <td>0.239666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238923</td>\n",
       "      <td>0.308819</td>\n",
       "      <td>-0.113937</td>\n",
       "      <td>0.030371</td>\n",
       "      <td>0.064886</td>\n",
       "      <td>0.065166</td>\n",
       "      <td>-0.031406</td>\n",
       "      <td>0.070815</td>\n",
       "      <td>-0.027347</td>\n",
       "      <td>0.790982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>0.012609</td>\n",
       "      <td>-0.059316</td>\n",
       "      <td>-0.059213</td>\n",
       "      <td>-0.005636</td>\n",
       "      <td>-0.091932</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.375983</td>\n",
       "      <td>0.073741</td>\n",
       "      <td>-0.128101</td>\n",
       "      <td>-0.046231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003334</td>\n",
       "      <td>-0.032589</td>\n",
       "      <td>0.070356</td>\n",
       "      <td>0.025504</td>\n",
       "      <td>0.054811</td>\n",
       "      <td>-0.001985</td>\n",
       "      <td>0.068777</td>\n",
       "      <td>-0.003511</td>\n",
       "      <td>0.043950</td>\n",
       "      <td>-0.077856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>-0.012713</td>\n",
       "      <td>0.027850</td>\n",
       "      <td>0.123349</td>\n",
       "      <td>0.014228</td>\n",
       "      <td>0.572323</td>\n",
       "      <td>-0.375983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.592855</td>\n",
       "      <td>0.315707</td>\n",
       "      <td>0.249503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224880</td>\n",
       "      <td>0.188686</td>\n",
       "      <td>-0.387268</td>\n",
       "      <td>0.031355</td>\n",
       "      <td>-0.050364</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>-0.034383</td>\n",
       "      <td>0.012398</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>0.522897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>-0.021998</td>\n",
       "      <td>0.040581</td>\n",
       "      <td>0.088866</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>0.550684</td>\n",
       "      <td>0.073741</td>\n",
       "      <td>0.592855</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179618</td>\n",
       "      <td>0.128451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205726</td>\n",
       "      <td>0.226298</td>\n",
       "      <td>-0.193919</td>\n",
       "      <td>0.045286</td>\n",
       "      <td>-0.038740</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>-0.010286</td>\n",
       "      <td>0.021490</td>\n",
       "      <td>0.035743</td>\n",
       "      <td>0.507101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>-0.050298</td>\n",
       "      <td>0.022936</td>\n",
       "      <td>0.193458</td>\n",
       "      <td>0.104160</td>\n",
       "      <td>0.411876</td>\n",
       "      <td>-0.128101</td>\n",
       "      <td>0.315707</td>\n",
       "      <td>0.179618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.264736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159718</td>\n",
       "      <td>0.125703</td>\n",
       "      <td>-0.110204</td>\n",
       "      <td>0.018796</td>\n",
       "      <td>0.061466</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>-0.029815</td>\n",
       "      <td>-0.005965</td>\n",
       "      <td>-0.008201</td>\n",
       "      <td>0.477493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>-0.005024</td>\n",
       "      <td>-0.069836</td>\n",
       "      <td>0.233633</td>\n",
       "      <td>0.214103</td>\n",
       "      <td>0.239666</td>\n",
       "      <td>-0.046231</td>\n",
       "      <td>0.249503</td>\n",
       "      <td>0.128451</td>\n",
       "      <td>0.264736</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204306</td>\n",
       "      <td>0.111761</td>\n",
       "      <td>-0.102303</td>\n",
       "      <td>0.026451</td>\n",
       "      <td>0.062021</td>\n",
       "      <td>0.140491</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>-0.015727</td>\n",
       "      <td>0.014359</td>\n",
       "      <td>0.386420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>-0.005968</td>\n",
       "      <td>-0.065649</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.111170</td>\n",
       "      <td>-0.059119</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>-0.049107</td>\n",
       "      <td>-0.067759</td>\n",
       "      <td>-0.072319</td>\n",
       "      <td>-0.050117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067898</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.036543</td>\n",
       "      <td>-0.029993</td>\n",
       "      <td>0.088871</td>\n",
       "      <td>0.041709</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>-0.015211</td>\n",
       "      <td>0.031706</td>\n",
       "      <td>-0.011378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>-0.007940</td>\n",
       "      <td>-0.140759</td>\n",
       "      <td>0.132644</td>\n",
       "      <td>-0.002618</td>\n",
       "      <td>0.308159</td>\n",
       "      <td>-0.136841</td>\n",
       "      <td>0.149040</td>\n",
       "      <td>0.181133</td>\n",
       "      <td>0.114442</td>\n",
       "      <td>-0.495251</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005316</td>\n",
       "      <td>0.129005</td>\n",
       "      <td>-0.002538</td>\n",
       "      <td>0.020764</td>\n",
       "      <td>-0.012579</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.023837</td>\n",
       "      <td>0.034888</td>\n",
       "      <td>-0.041258</td>\n",
       "      <td>0.214479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>-0.015415</td>\n",
       "      <td>-0.238518</td>\n",
       "      <td>0.392075</td>\n",
       "      <td>0.260833</td>\n",
       "      <td>0.537808</td>\n",
       "      <td>-0.171098</td>\n",
       "      <td>0.391452</td>\n",
       "      <td>0.291066</td>\n",
       "      <td>0.363936</td>\n",
       "      <td>0.522396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232019</td>\n",
       "      <td>0.247264</td>\n",
       "      <td>-0.095478</td>\n",
       "      <td>0.037384</td>\n",
       "      <td>0.084489</td>\n",
       "      <td>0.126053</td>\n",
       "      <td>-0.018479</td>\n",
       "      <td>0.013196</td>\n",
       "      <td>-0.014969</td>\n",
       "      <td>0.613581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>0.010496</td>\n",
       "      <td>-0.251758</td>\n",
       "      <td>0.457181</td>\n",
       "      <td>0.299475</td>\n",
       "      <td>0.476224</td>\n",
       "      <td>-0.144203</td>\n",
       "      <td>0.281986</td>\n",
       "      <td>0.240379</td>\n",
       "      <td>0.344501</td>\n",
       "      <td>0.445863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235459</td>\n",
       "      <td>0.211671</td>\n",
       "      <td>-0.065292</td>\n",
       "      <td>0.056104</td>\n",
       "      <td>0.088758</td>\n",
       "      <td>0.131525</td>\n",
       "      <td>-0.021096</td>\n",
       "      <td>0.031372</td>\n",
       "      <td>-0.013604</td>\n",
       "      <td>0.605852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>0.005590</td>\n",
       "      <td>0.307886</td>\n",
       "      <td>0.080177</td>\n",
       "      <td>0.050986</td>\n",
       "      <td>0.295493</td>\n",
       "      <td>0.028942</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>0.140024</td>\n",
       "      <td>0.174561</td>\n",
       "      <td>-0.137079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092165</td>\n",
       "      <td>0.208026</td>\n",
       "      <td>0.061989</td>\n",
       "      <td>-0.024358</td>\n",
       "      <td>0.040606</td>\n",
       "      <td>0.081487</td>\n",
       "      <td>0.016197</td>\n",
       "      <td>0.035164</td>\n",
       "      <td>-0.028700</td>\n",
       "      <td>0.319334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>-0.044230</td>\n",
       "      <td>0.046474</td>\n",
       "      <td>0.038469</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>-0.030429</td>\n",
       "      <td>0.025494</td>\n",
       "      <td>-0.183784</td>\n",
       "      <td>-0.062419</td>\n",
       "      <td>-0.069071</td>\n",
       "      <td>-0.064503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025444</td>\n",
       "      <td>0.018251</td>\n",
       "      <td>0.061081</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>0.026799</td>\n",
       "      <td>0.062157</td>\n",
       "      <td>-0.003793</td>\n",
       "      <td>-0.022174</td>\n",
       "      <td>-0.028921</td>\n",
       "      <td>-0.025606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>0.008273</td>\n",
       "      <td>0.074853</td>\n",
       "      <td>0.402797</td>\n",
       "      <td>0.263116</td>\n",
       "      <td>0.593007</td>\n",
       "      <td>-0.079686</td>\n",
       "      <td>0.199010</td>\n",
       "      <td>0.287389</td>\n",
       "      <td>0.390857</td>\n",
       "      <td>0.208171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247433</td>\n",
       "      <td>0.330224</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>0.020643</td>\n",
       "      <td>0.101510</td>\n",
       "      <td>0.170205</td>\n",
       "      <td>-0.002416</td>\n",
       "      <td>0.050240</td>\n",
       "      <td>-0.036526</td>\n",
       "      <td>0.708624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>0.002289</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.100949</td>\n",
       "      <td>0.158155</td>\n",
       "      <td>0.111098</td>\n",
       "      <td>-0.054942</td>\n",
       "      <td>0.187599</td>\n",
       "      <td>0.119470</td>\n",
       "      <td>0.085310</td>\n",
       "      <td>0.649212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175315</td>\n",
       "      <td>0.067341</td>\n",
       "      <td>-0.049911</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.067616</td>\n",
       "      <td>-0.023047</td>\n",
       "      <td>-0.025361</td>\n",
       "      <td>0.067049</td>\n",
       "      <td>0.227122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>-0.020155</td>\n",
       "      <td>-0.002333</td>\n",
       "      <td>-0.007234</td>\n",
       "      <td>0.048046</td>\n",
       "      <td>-0.040150</td>\n",
       "      <td>0.117821</td>\n",
       "      <td>-0.038162</td>\n",
       "      <td>-0.012337</td>\n",
       "      <td>0.026673</td>\n",
       "      <td>0.067418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040161</td>\n",
       "      <td>-0.025324</td>\n",
       "      <td>-0.008555</td>\n",
       "      <td>0.035114</td>\n",
       "      <td>0.032121</td>\n",
       "      <td>0.020025</td>\n",
       "      <td>-0.007367</td>\n",
       "      <td>0.032873</td>\n",
       "      <td>-0.046524</td>\n",
       "      <td>-0.016844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath</th>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.131608</td>\n",
       "      <td>0.198769</td>\n",
       "      <td>0.126031</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>-0.194149</td>\n",
       "      <td>0.468271</td>\n",
       "      <td>0.439046</td>\n",
       "      <td>0.276833</td>\n",
       "      <td>0.058543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187703</td>\n",
       "      <td>0.259977</td>\n",
       "      <td>-0.115093</td>\n",
       "      <td>0.035353</td>\n",
       "      <td>-0.008106</td>\n",
       "      <td>0.049604</td>\n",
       "      <td>-0.014290</td>\n",
       "      <td>0.055872</td>\n",
       "      <td>-0.019669</td>\n",
       "      <td>0.560664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath</th>\n",
       "      <td>0.006784</td>\n",
       "      <td>0.177354</td>\n",
       "      <td>0.053532</td>\n",
       "      <td>0.014259</td>\n",
       "      <td>0.273458</td>\n",
       "      <td>-0.060769</td>\n",
       "      <td>0.242656</td>\n",
       "      <td>0.183331</td>\n",
       "      <td>0.201444</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108080</td>\n",
       "      <td>0.199740</td>\n",
       "      <td>-0.095317</td>\n",
       "      <td>-0.004972</td>\n",
       "      <td>0.072426</td>\n",
       "      <td>0.022381</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>-0.009050</td>\n",
       "      <td>-0.010269</td>\n",
       "      <td>0.284108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <td>0.037719</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>0.263170</td>\n",
       "      <td>0.119690</td>\n",
       "      <td>0.101676</td>\n",
       "      <td>0.012980</td>\n",
       "      <td>-0.070651</td>\n",
       "      <td>-0.040581</td>\n",
       "      <td>0.102821</td>\n",
       "      <td>-0.107355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046854</td>\n",
       "      <td>0.093810</td>\n",
       "      <td>0.041570</td>\n",
       "      <td>-0.024478</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>0.070703</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.046544</td>\n",
       "      <td>-0.036014</td>\n",
       "      <td>0.168213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>-0.006069</td>\n",
       "      <td>-0.017784</td>\n",
       "      <td>-0.183882</td>\n",
       "      <td>-0.087001</td>\n",
       "      <td>-0.174800</td>\n",
       "      <td>-0.149598</td>\n",
       "      <td>-0.037610</td>\n",
       "      <td>-0.081007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090130</td>\n",
       "      <td>-0.070091</td>\n",
       "      <td>0.037312</td>\n",
       "      <td>-0.024600</td>\n",
       "      <td>-0.051613</td>\n",
       "      <td>-0.014525</td>\n",
       "      <td>0.062341</td>\n",
       "      <td>0.026589</td>\n",
       "      <td>0.031687</td>\n",
       "      <td>-0.135907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>0.027239</td>\n",
       "      <td>0.040380</td>\n",
       "      <td>0.352096</td>\n",
       "      <td>0.190015</td>\n",
       "      <td>0.427452</td>\n",
       "      <td>-0.057583</td>\n",
       "      <td>0.095589</td>\n",
       "      <td>0.191740</td>\n",
       "      <td>0.280682</td>\n",
       "      <td>0.044316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165984</td>\n",
       "      <td>0.234192</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>-0.006683</td>\n",
       "      <td>0.059383</td>\n",
       "      <td>0.083757</td>\n",
       "      <td>0.024763</td>\n",
       "      <td>0.036907</td>\n",
       "      <td>-0.034516</td>\n",
       "      <td>0.533723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>-0.019772</td>\n",
       "      <td>-0.045569</td>\n",
       "      <td>0.266639</td>\n",
       "      <td>0.271364</td>\n",
       "      <td>0.396765</td>\n",
       "      <td>-0.023820</td>\n",
       "      <td>0.147716</td>\n",
       "      <td>0.112581</td>\n",
       "      <td>0.249070</td>\n",
       "      <td>0.260011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200019</td>\n",
       "      <td>0.169405</td>\n",
       "      <td>-0.024822</td>\n",
       "      <td>0.011257</td>\n",
       "      <td>0.184530</td>\n",
       "      <td>0.095074</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.046357</td>\n",
       "      <td>-0.024096</td>\n",
       "      <td>0.466929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.085072</td>\n",
       "      <td>0.070250</td>\n",
       "      <td>-0.024947</td>\n",
       "      <td>0.547766</td>\n",
       "      <td>-0.324297</td>\n",
       "      <td>0.825667</td>\n",
       "      <td>0.642277</td>\n",
       "      <td>0.252691</td>\n",
       "      <td>0.153484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224577</td>\n",
       "      <td>0.228425</td>\n",
       "      <td>-0.297003</td>\n",
       "      <td>0.023544</td>\n",
       "      <td>-0.075418</td>\n",
       "      <td>-0.014501</td>\n",
       "      <td>-0.032417</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>-0.001014</td>\n",
       "      <td>0.486362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>0.016570</td>\n",
       "      <td>-0.040110</td>\n",
       "      <td>0.285691</td>\n",
       "      <td>0.154871</td>\n",
       "      <td>0.600671</td>\n",
       "      <td>-0.185758</td>\n",
       "      <td>0.537850</td>\n",
       "      <td>0.420622</td>\n",
       "      <td>0.364204</td>\n",
       "      <td>0.224054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226342</td>\n",
       "      <td>0.213569</td>\n",
       "      <td>-0.151434</td>\n",
       "      <td>0.035765</td>\n",
       "      <td>0.050494</td>\n",
       "      <td>0.020934</td>\n",
       "      <td>-0.043080</td>\n",
       "      <td>0.040522</td>\n",
       "      <td>-0.039117</td>\n",
       "      <td>0.640409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>0.017634</td>\n",
       "      <td>-0.098672</td>\n",
       "      <td>0.344997</td>\n",
       "      <td>0.180403</td>\n",
       "      <td>0.562022</td>\n",
       "      <td>-0.151521</td>\n",
       "      <td>0.478954</td>\n",
       "      <td>0.371600</td>\n",
       "      <td>0.373066</td>\n",
       "      <td>0.296970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224666</td>\n",
       "      <td>0.241435</td>\n",
       "      <td>-0.121777</td>\n",
       "      <td>0.035087</td>\n",
       "      <td>0.051412</td>\n",
       "      <td>0.061047</td>\n",
       "      <td>-0.027400</td>\n",
       "      <td>0.027974</td>\n",
       "      <td>-0.027378</td>\n",
       "      <td>0.623431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>-0.029643</td>\n",
       "      <td>-0.012579</td>\n",
       "      <td>0.088521</td>\n",
       "      <td>0.171698</td>\n",
       "      <td>0.238923</td>\n",
       "      <td>-0.003334</td>\n",
       "      <td>0.224880</td>\n",
       "      <td>0.205726</td>\n",
       "      <td>0.159718</td>\n",
       "      <td>0.204306</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058661</td>\n",
       "      <td>-0.125989</td>\n",
       "      <td>-0.032771</td>\n",
       "      <td>-0.074181</td>\n",
       "      <td>0.073378</td>\n",
       "      <td>-0.009551</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>0.022270</td>\n",
       "      <td>0.324413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.006100</td>\n",
       "      <td>0.151972</td>\n",
       "      <td>0.084774</td>\n",
       "      <td>0.308819</td>\n",
       "      <td>-0.032589</td>\n",
       "      <td>0.188686</td>\n",
       "      <td>0.226298</td>\n",
       "      <td>0.125703</td>\n",
       "      <td>0.111761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058661</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.093079</td>\n",
       "      <td>-0.005842</td>\n",
       "      <td>0.074304</td>\n",
       "      <td>0.060762</td>\n",
       "      <td>-0.018584</td>\n",
       "      <td>0.071255</td>\n",
       "      <td>-0.057619</td>\n",
       "      <td>0.315856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>0.002889</td>\n",
       "      <td>-0.012037</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>-0.018340</td>\n",
       "      <td>-0.113937</td>\n",
       "      <td>0.070356</td>\n",
       "      <td>-0.387268</td>\n",
       "      <td>-0.193919</td>\n",
       "      <td>-0.110204</td>\n",
       "      <td>-0.102303</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125989</td>\n",
       "      <td>-0.093079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037305</td>\n",
       "      <td>-0.082864</td>\n",
       "      <td>0.054203</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>-0.028887</td>\n",
       "      <td>-0.009916</td>\n",
       "      <td>-0.128578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>-0.046635</td>\n",
       "      <td>-0.043825</td>\n",
       "      <td>0.070029</td>\n",
       "      <td>0.020423</td>\n",
       "      <td>0.030371</td>\n",
       "      <td>0.025504</td>\n",
       "      <td>0.031355</td>\n",
       "      <td>0.045286</td>\n",
       "      <td>0.018796</td>\n",
       "      <td>0.026451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032771</td>\n",
       "      <td>-0.005842</td>\n",
       "      <td>-0.037305</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031436</td>\n",
       "      <td>-0.007992</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.029474</td>\n",
       "      <td>0.018645</td>\n",
       "      <td>0.044584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>0.001330</td>\n",
       "      <td>-0.026030</td>\n",
       "      <td>0.041383</td>\n",
       "      <td>0.043160</td>\n",
       "      <td>0.064886</td>\n",
       "      <td>0.054811</td>\n",
       "      <td>-0.050364</td>\n",
       "      <td>-0.038740</td>\n",
       "      <td>0.061466</td>\n",
       "      <td>0.062021</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074181</td>\n",
       "      <td>0.074304</td>\n",
       "      <td>-0.082864</td>\n",
       "      <td>-0.031436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051307</td>\n",
       "      <td>0.031946</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>0.010694</td>\n",
       "      <td>0.111447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>0.057044</td>\n",
       "      <td>0.008283</td>\n",
       "      <td>0.206167</td>\n",
       "      <td>0.077672</td>\n",
       "      <td>0.065166</td>\n",
       "      <td>-0.001985</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.140491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073378</td>\n",
       "      <td>0.060762</td>\n",
       "      <td>0.054203</td>\n",
       "      <td>-0.007992</td>\n",
       "      <td>0.051307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029669</td>\n",
       "      <td>-0.033737</td>\n",
       "      <td>-0.059689</td>\n",
       "      <td>0.092404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>-0.006242</td>\n",
       "      <td>-0.007683</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>0.038068</td>\n",
       "      <td>-0.031406</td>\n",
       "      <td>0.068777</td>\n",
       "      <td>-0.034383</td>\n",
       "      <td>-0.010286</td>\n",
       "      <td>-0.029815</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009551</td>\n",
       "      <td>-0.018584</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.031946</td>\n",
       "      <td>0.029669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006495</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>-0.021190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoSold</th>\n",
       "      <td>0.021172</td>\n",
       "      <td>-0.013585</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.070815</td>\n",
       "      <td>-0.003511</td>\n",
       "      <td>0.012398</td>\n",
       "      <td>0.021490</td>\n",
       "      <td>-0.005965</td>\n",
       "      <td>-0.015727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>0.071255</td>\n",
       "      <td>-0.028887</td>\n",
       "      <td>0.029474</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>-0.033737</td>\n",
       "      <td>-0.006495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.145721</td>\n",
       "      <td>0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YrSold</th>\n",
       "      <td>0.000712</td>\n",
       "      <td>-0.021407</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>-0.014261</td>\n",
       "      <td>-0.027347</td>\n",
       "      <td>0.043950</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>0.035743</td>\n",
       "      <td>-0.008201</td>\n",
       "      <td>0.014359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022270</td>\n",
       "      <td>-0.057619</td>\n",
       "      <td>-0.009916</td>\n",
       "      <td>0.018645</td>\n",
       "      <td>0.010694</td>\n",
       "      <td>-0.059689</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>-0.145721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.028923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalePrice</th>\n",
       "      <td>-0.021917</td>\n",
       "      <td>-0.084284</td>\n",
       "      <td>0.351799</td>\n",
       "      <td>0.263843</td>\n",
       "      <td>0.790982</td>\n",
       "      <td>-0.077856</td>\n",
       "      <td>0.522897</td>\n",
       "      <td>0.507101</td>\n",
       "      <td>0.477493</td>\n",
       "      <td>0.386420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324413</td>\n",
       "      <td>0.315856</td>\n",
       "      <td>-0.128578</td>\n",
       "      <td>0.044584</td>\n",
       "      <td>0.111447</td>\n",
       "      <td>0.092404</td>\n",
       "      <td>-0.021190</td>\n",
       "      <td>0.046432</td>\n",
       "      <td>-0.028923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Id  MSSubClass  LotFrontage   LotArea  OverallQual  \\\n",
       "Id             1.000000    0.011156    -0.010601 -0.033226    -0.028365   \n",
       "MSSubClass     0.011156    1.000000    -0.386347 -0.139781     0.032628   \n",
       "LotFrontage   -0.010601   -0.386347     1.000000  0.426095     0.251646   \n",
       "LotArea       -0.033226   -0.139781     0.426095  1.000000     0.105806   \n",
       "OverallQual   -0.028365    0.032628     0.251646  0.105806     1.000000   \n",
       "OverallCond    0.012609   -0.059316    -0.059213 -0.005636    -0.091932   \n",
       "YearBuilt     -0.012713    0.027850     0.123349  0.014228     0.572323   \n",
       "YearRemodAdd  -0.021998    0.040581     0.088866  0.013788     0.550684   \n",
       "MasVnrArea    -0.050298    0.022936     0.193458  0.104160     0.411876   \n",
       "BsmtFinSF1    -0.005024   -0.069836     0.233633  0.214103     0.239666   \n",
       "BsmtFinSF2    -0.005968   -0.065649     0.049900  0.111170    -0.059119   \n",
       "BsmtUnfSF     -0.007940   -0.140759     0.132644 -0.002618     0.308159   \n",
       "TotalBsmtSF   -0.015415   -0.238518     0.392075  0.260833     0.537808   \n",
       "1stFlrSF       0.010496   -0.251758     0.457181  0.299475     0.476224   \n",
       "2ndFlrSF       0.005590    0.307886     0.080177  0.050986     0.295493   \n",
       "LowQualFinSF  -0.044230    0.046474     0.038469  0.004779    -0.030429   \n",
       "GrLivArea      0.008273    0.074853     0.402797  0.263116     0.593007   \n",
       "BsmtFullBath   0.002289    0.003491     0.100949  0.158155     0.111098   \n",
       "BsmtHalfBath  -0.020155   -0.002333    -0.007234  0.048046    -0.040150   \n",
       "FullBath       0.005587    0.131608     0.198769  0.126031     0.550600   \n",
       "HalfBath       0.006784    0.177354     0.053532  0.014259     0.273458   \n",
       "BedroomAbvGr   0.037719   -0.023438     0.263170  0.119690     0.101676   \n",
       "KitchenAbvGr   0.002951    0.281721    -0.006069 -0.017784    -0.183882   \n",
       "TotRmsAbvGrd   0.027239    0.040380     0.352096  0.190015     0.427452   \n",
       "Fireplaces    -0.019772   -0.045569     0.266639  0.271364     0.396765   \n",
       "GarageYrBlt    0.000072    0.085072     0.070250 -0.024947     0.547766   \n",
       "GarageCars     0.016570   -0.040110     0.285691  0.154871     0.600671   \n",
       "GarageArea     0.017634   -0.098672     0.344997  0.180403     0.562022   \n",
       "WoodDeckSF    -0.029643   -0.012579     0.088521  0.171698     0.238923   \n",
       "OpenPorchSF   -0.000477   -0.006100     0.151972  0.084774     0.308819   \n",
       "EnclosedPorch  0.002889   -0.012037     0.010700 -0.018340    -0.113937   \n",
       "3SsnPorch     -0.046635   -0.043825     0.070029  0.020423     0.030371   \n",
       "ScreenPorch    0.001330   -0.026030     0.041383  0.043160     0.064886   \n",
       "PoolArea       0.057044    0.008283     0.206167  0.077672     0.065166   \n",
       "MiscVal       -0.006242   -0.007683     0.003368  0.038068    -0.031406   \n",
       "MoSold         0.021172   -0.013585     0.011200  0.001205     0.070815   \n",
       "YrSold         0.000712   -0.021407     0.007450 -0.014261    -0.027347   \n",
       "SalePrice     -0.021917   -0.084284     0.351799  0.263843     0.790982   \n",
       "\n",
       "               OverallCond  YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  \\\n",
       "Id                0.012609  -0.012713     -0.021998   -0.050298   -0.005024   \n",
       "MSSubClass       -0.059316   0.027850      0.040581    0.022936   -0.069836   \n",
       "LotFrontage      -0.059213   0.123349      0.088866    0.193458    0.233633   \n",
       "LotArea          -0.005636   0.014228      0.013788    0.104160    0.214103   \n",
       "OverallQual      -0.091932   0.572323      0.550684    0.411876    0.239666   \n",
       "OverallCond       1.000000  -0.375983      0.073741   -0.128101   -0.046231   \n",
       "YearBuilt        -0.375983   1.000000      0.592855    0.315707    0.249503   \n",
       "YearRemodAdd      0.073741   0.592855      1.000000    0.179618    0.128451   \n",
       "MasVnrArea       -0.128101   0.315707      0.179618    1.000000    0.264736   \n",
       "BsmtFinSF1       -0.046231   0.249503      0.128451    0.264736    1.000000   \n",
       "BsmtFinSF2        0.040229  -0.049107     -0.067759   -0.072319   -0.050117   \n",
       "BsmtUnfSF        -0.136841   0.149040      0.181133    0.114442   -0.495251   \n",
       "TotalBsmtSF      -0.171098   0.391452      0.291066    0.363936    0.522396   \n",
       "1stFlrSF         -0.144203   0.281986      0.240379    0.344501    0.445863   \n",
       "2ndFlrSF          0.028942   0.010308      0.140024    0.174561   -0.137079   \n",
       "LowQualFinSF      0.025494  -0.183784     -0.062419   -0.069071   -0.064503   \n",
       "GrLivArea        -0.079686   0.199010      0.287389    0.390857    0.208171   \n",
       "BsmtFullBath     -0.054942   0.187599      0.119470    0.085310    0.649212   \n",
       "BsmtHalfBath      0.117821  -0.038162     -0.012337    0.026673    0.067418   \n",
       "FullBath         -0.194149   0.468271      0.439046    0.276833    0.058543   \n",
       "HalfBath         -0.060769   0.242656      0.183331    0.201444    0.004262   \n",
       "BedroomAbvGr      0.012980  -0.070651     -0.040581    0.102821   -0.107355   \n",
       "KitchenAbvGr     -0.087001  -0.174800     -0.149598   -0.037610   -0.081007   \n",
       "TotRmsAbvGrd     -0.057583   0.095589      0.191740    0.280682    0.044316   \n",
       "Fireplaces       -0.023820   0.147716      0.112581    0.249070    0.260011   \n",
       "GarageYrBlt      -0.324297   0.825667      0.642277    0.252691    0.153484   \n",
       "GarageCars       -0.185758   0.537850      0.420622    0.364204    0.224054   \n",
       "GarageArea       -0.151521   0.478954      0.371600    0.373066    0.296970   \n",
       "WoodDeckSF       -0.003334   0.224880      0.205726    0.159718    0.204306   \n",
       "OpenPorchSF      -0.032589   0.188686      0.226298    0.125703    0.111761   \n",
       "EnclosedPorch     0.070356  -0.387268     -0.193919   -0.110204   -0.102303   \n",
       "3SsnPorch         0.025504   0.031355      0.045286    0.018796    0.026451   \n",
       "ScreenPorch       0.054811  -0.050364     -0.038740    0.061466    0.062021   \n",
       "PoolArea         -0.001985   0.004950      0.005829    0.011723    0.140491   \n",
       "MiscVal           0.068777  -0.034383     -0.010286   -0.029815    0.003571   \n",
       "MoSold           -0.003511   0.012398      0.021490   -0.005965   -0.015727   \n",
       "YrSold            0.043950  -0.013618      0.035743   -0.008201    0.014359   \n",
       "SalePrice        -0.077856   0.522897      0.507101    0.477493    0.386420   \n",
       "\n",
       "               ...  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "Id             ...   -0.029643    -0.000477       0.002889  -0.046635   \n",
       "MSSubClass     ...   -0.012579    -0.006100      -0.012037  -0.043825   \n",
       "LotFrontage    ...    0.088521     0.151972       0.010700   0.070029   \n",
       "LotArea        ...    0.171698     0.084774      -0.018340   0.020423   \n",
       "OverallQual    ...    0.238923     0.308819      -0.113937   0.030371   \n",
       "OverallCond    ...   -0.003334    -0.032589       0.070356   0.025504   \n",
       "YearBuilt      ...    0.224880     0.188686      -0.387268   0.031355   \n",
       "YearRemodAdd   ...    0.205726     0.226298      -0.193919   0.045286   \n",
       "MasVnrArea     ...    0.159718     0.125703      -0.110204   0.018796   \n",
       "BsmtFinSF1     ...    0.204306     0.111761      -0.102303   0.026451   \n",
       "BsmtFinSF2     ...    0.067898     0.003093       0.036543  -0.029993   \n",
       "BsmtUnfSF      ...   -0.005316     0.129005      -0.002538   0.020764   \n",
       "TotalBsmtSF    ...    0.232019     0.247264      -0.095478   0.037384   \n",
       "1stFlrSF       ...    0.235459     0.211671      -0.065292   0.056104   \n",
       "2ndFlrSF       ...    0.092165     0.208026       0.061989  -0.024358   \n",
       "LowQualFinSF   ...   -0.025444     0.018251       0.061081  -0.004296   \n",
       "GrLivArea      ...    0.247433     0.330224       0.009113   0.020643   \n",
       "BsmtFullBath   ...    0.175315     0.067341      -0.049911  -0.000106   \n",
       "BsmtHalfBath   ...    0.040161    -0.025324      -0.008555   0.035114   \n",
       "FullBath       ...    0.187703     0.259977      -0.115093   0.035353   \n",
       "HalfBath       ...    0.108080     0.199740      -0.095317  -0.004972   \n",
       "BedroomAbvGr   ...    0.046854     0.093810       0.041570  -0.024478   \n",
       "KitchenAbvGr   ...   -0.090130    -0.070091       0.037312  -0.024600   \n",
       "TotRmsAbvGrd   ...    0.165984     0.234192       0.004151  -0.006683   \n",
       "Fireplaces     ...    0.200019     0.169405      -0.024822   0.011257   \n",
       "GarageYrBlt    ...    0.224577     0.228425      -0.297003   0.023544   \n",
       "GarageCars     ...    0.226342     0.213569      -0.151434   0.035765   \n",
       "GarageArea     ...    0.224666     0.241435      -0.121777   0.035087   \n",
       "WoodDeckSF     ...    1.000000     0.058661      -0.125989  -0.032771   \n",
       "OpenPorchSF    ...    0.058661     1.000000      -0.093079  -0.005842   \n",
       "EnclosedPorch  ...   -0.125989    -0.093079       1.000000  -0.037305   \n",
       "3SsnPorch      ...   -0.032771    -0.005842      -0.037305   1.000000   \n",
       "ScreenPorch    ...   -0.074181     0.074304      -0.082864  -0.031436   \n",
       "PoolArea       ...    0.073378     0.060762       0.054203  -0.007992   \n",
       "MiscVal        ...   -0.009551    -0.018584       0.018361   0.000354   \n",
       "MoSold         ...    0.021011     0.071255      -0.028887   0.029474   \n",
       "YrSold         ...    0.022270    -0.057619      -0.009916   0.018645   \n",
       "SalePrice      ...    0.324413     0.315856      -0.128578   0.044584   \n",
       "\n",
       "               ScreenPorch  PoolArea   MiscVal    MoSold    YrSold  SalePrice  \n",
       "Id                0.001330  0.057044 -0.006242  0.021172  0.000712  -0.021917  \n",
       "MSSubClass       -0.026030  0.008283 -0.007683 -0.013585 -0.021407  -0.084284  \n",
       "LotFrontage       0.041383  0.206167  0.003368  0.011200  0.007450   0.351799  \n",
       "LotArea           0.043160  0.077672  0.038068  0.001205 -0.014261   0.263843  \n",
       "OverallQual       0.064886  0.065166 -0.031406  0.070815 -0.027347   0.790982  \n",
       "OverallCond       0.054811 -0.001985  0.068777 -0.003511  0.043950  -0.077856  \n",
       "YearBuilt        -0.050364  0.004950 -0.034383  0.012398 -0.013618   0.522897  \n",
       "YearRemodAdd     -0.038740  0.005829 -0.010286  0.021490  0.035743   0.507101  \n",
       "MasVnrArea        0.061466  0.011723 -0.029815 -0.005965 -0.008201   0.477493  \n",
       "BsmtFinSF1        0.062021  0.140491  0.003571 -0.015727  0.014359   0.386420  \n",
       "BsmtFinSF2        0.088871  0.041709  0.004940 -0.015211  0.031706  -0.011378  \n",
       "BsmtUnfSF        -0.012579 -0.035092 -0.023837  0.034888 -0.041258   0.214479  \n",
       "TotalBsmtSF       0.084489  0.126053 -0.018479  0.013196 -0.014969   0.613581  \n",
       "1stFlrSF          0.088758  0.131525 -0.021096  0.031372 -0.013604   0.605852  \n",
       "2ndFlrSF          0.040606  0.081487  0.016197  0.035164 -0.028700   0.319334  \n",
       "LowQualFinSF      0.026799  0.062157 -0.003793 -0.022174 -0.028921  -0.025606  \n",
       "GrLivArea         0.101510  0.170205 -0.002416  0.050240 -0.036526   0.708624  \n",
       "BsmtFullBath      0.023148  0.067616 -0.023047 -0.025361  0.067049   0.227122  \n",
       "BsmtHalfBath      0.032121  0.020025 -0.007367  0.032873 -0.046524  -0.016844  \n",
       "FullBath         -0.008106  0.049604 -0.014290  0.055872 -0.019669   0.560664  \n",
       "HalfBath          0.072426  0.022381  0.001290 -0.009050 -0.010269   0.284108  \n",
       "BedroomAbvGr      0.044300  0.070703  0.007767  0.046544 -0.036014   0.168213  \n",
       "KitchenAbvGr     -0.051613 -0.014525  0.062341  0.026589  0.031687  -0.135907  \n",
       "TotRmsAbvGrd      0.059383  0.083757  0.024763  0.036907 -0.034516   0.533723  \n",
       "Fireplaces        0.184530  0.095074  0.001409  0.046357 -0.024096   0.466929  \n",
       "GarageYrBlt      -0.075418 -0.014501 -0.032417  0.005337 -0.001014   0.486362  \n",
       "GarageCars        0.050494  0.020934 -0.043080  0.040522 -0.039117   0.640409  \n",
       "GarageArea        0.051412  0.061047 -0.027400  0.027974 -0.027378   0.623431  \n",
       "WoodDeckSF       -0.074181  0.073378 -0.009551  0.021011  0.022270   0.324413  \n",
       "OpenPorchSF       0.074304  0.060762 -0.018584  0.071255 -0.057619   0.315856  \n",
       "EnclosedPorch    -0.082864  0.054203  0.018361 -0.028887 -0.009916  -0.128578  \n",
       "3SsnPorch        -0.031436 -0.007992  0.000354  0.029474  0.018645   0.044584  \n",
       "ScreenPorch       1.000000  0.051307  0.031946  0.023217  0.010694   0.111447  \n",
       "PoolArea          0.051307  1.000000  0.029669 -0.033737 -0.059689   0.092404  \n",
       "MiscVal           0.031946  0.029669  1.000000 -0.006495  0.004906  -0.021190  \n",
       "MoSold            0.023217 -0.033737 -0.006495  1.000000 -0.145721   0.046432  \n",
       "YrSold            0.010694 -0.059689  0.004906 -0.145721  1.000000  -0.028923  \n",
       "SalePrice         0.111447  0.092404 -0.021190  0.046432 -0.028923   1.000000  \n",
       "\n",
       "[38 rows x 38 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b8ce132880>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping features which have high null values or which are not so relevant\n",
    "df.drop(['PoolQC','Fence','MiscFeature','Alley','Id','GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill Missing Values with mode for categorical and mean for continuous features\n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())\n",
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])\n",
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])\n",
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])\n",
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])\n",
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])\n",
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 75)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "                ..\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b8ce0c2490>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAAE5CAYAAAA3GCPGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dedxu5bz/39+9d3N2gyakQaNONChS/Zo5cYokpWRIyiEVIepEySESp0gRFaKIBqFJI812tfduPtJOGcqhsCsNO9/fH99r7Wc997Pm53722juf9+t1v57nXve61nXd617ru67rO5q7I4QQYt4yqe8BCCHEvyISvkII0QMSvkII0QMSvkII0QMSvkII0QNTmu645c5Xyy1CCCFacs1Ptrai7Zr5CiFEDzSe+QrRhMMu3n/U+2N2PKWnkQgxfyPhK4aKhK0QzZDaQQghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghekDCVwghemBK3wMQzy0Ou3j/Ue+P2fGUnkYixPyNhK8YKhK2QjRDagchhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOgBCV8hhOiBKX0PQDy3OOzi/Ue9P2bHU3oaiRDzNxK+YqhI2ArRDAlfMVQ08xWiGRK+YqhI2ArRDBnchBCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiByR8hRCiB1RAUwwVVS8WohkSvmKoSNgK0QypHYQQogckfIUQogckfIUQogckfIUQogckfIUQogckfIUQogckfIUQogckfIUQogckfIUQogckfIUQogckfIUQogeU20EMFSXWEaIZEr5iqEjYCtEMqR2EEKIHJHyFEKIHpHYQQ0U6XyGaIeErhoqErRDNkNpBCCF6QMJXCCF6QMJXCCF6QDpfMVQGDW4gPbAQRUj4iqEiQStEM6R2EEKIHpDwFUKIHpDwFUKIHpDwFUKIHpDwFUKIHpDwFUKIHpDwFUKIHpDwFUKIHpDwFUKIHpDwFUKIHpDwFUKIHpDwFUKIHpDwFUKIHpDwFUKIHpDwFUKIHpDwFUKIHpDwFUKIHpDwFUKIHlAZITFUBmu4qayQEMVI+IqhImErRDOkdhBCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiB6Q8BVCiD5w91YvYP+2bbq2m1dtnqt9ze/j07lYcManczGcdqOO0aHTaR0H27rdvGrzXO1rfh+fzsWCMz6di+G0y7+kdhBCiB6Q8BVCiB7oInxP6dhXl3bzqs1zta/5fXzzsi+Nb8Hpa34f33jazcWS/kIIIcQ8RGoHIYToAQlfIYToAQlfMd9iZqv0PQYhJgoJ3wnCzJatejU8xsFNtvWNmS0xQYc+P9fHOW0amtkkM9t8+EMSw+Rf+QHbyOBmZlsA0939cTPbG9gYOMHdf9ug7frAesCi2TZ3/07JvpOAme6+fsPx59uuCqzl7peZ2WLAFHef3fY4w8LMZgEOGLAK8Gj6f2ngAXdfvcExbnH3jQe23eruG9W0+w/g3xh9zo+uabMFcBSwKjAljdXd/SUVbTYHvgks6e6rmNkGwHvd/f2VX6wh+e/a5HsXtL/e3V/dcN/N3P2GLuPMHWNzYDXi/AHl13rafxHgzQVtCn8rM7uNuKbGfBTN/OUVfa0B/M7dnzKzbYCXA99x97/2Ob78NW5m57j7m8vGU9Ln2sBHGbluszFuV7DvIVXHcvcvVfRjwNuAl7j70emhsZK739RmvHmm1O8CwMnABunmOhQ4FfgOsHVVIzM7EtiGEL4XAq8Drkltx+Du/zSzGWa2irs/0HBsmNl+wP7AssAawMrA14DtC/Z9GfAN4EXARcDH3P3R9NlN7v7Kkj5mU31hTR34Lqundl8DLnD3C9P71wE71HyfPYG9gNXN7ILcR1OBv9S0/RqwOLAtIRh3A5pcIKcCHwJuBp5tsD/A/wD/DlwA4O4zzGyrirG1Pfde8n9TLjWzNwPnev0s4yRiUtFKaGeY2RnEtTedkfPnlFzriR8DfyPO+VMNutmpzZgGOAfYxMzWJH7rC4Azgdf3PD7L/V/6oK/gh8S9/g3qr9vndTh+xknAP4HtgKOB2cQ53bTzERuG0t2S/n4S2De/rabdbYRqY0Z6vyLwk5o2V6QvdjlxgVxACK+qNtOBhYFb832X7HsNsCMxA/0IcAewRvrs1rrv1CEM8eaCbZWhicRTfBvgeuIBl702Jmb0VW1nDvxdEri0wThv7PDdbhw8b9lvPYxzT9xMf0/Xw5zc/7OBvzcY32zihnk617aw3cB3aH0dAHeRVpIt2tw+7Outoq/sHv4ocGCT7zkvxpeXI01kSkH7MffXBJ+/Rtd6k1fTme9sMzsM2BvYyswmAws1aPcPj9nsHDObCvyJ+qfbpxqOKc9T7v50rAzAzKZQPlNa0t0vTv8fZ2Y3Axeb2dsr2ozBzFZg9LK+bKb+ZzM7AvhuOv7e1MxePdQ5vzWzHRg5h2sD6xIPtCr+kf4+YWYvTH3VqjiAK83sC8C55GY57n5LRZsH01LbzWxh4CBCCJXR6ty7++QG4y7F3dvMdCaZ2TLEZCH7f+6szN0fqWl/O7AS8McWfV5nZi9z97rfdBRmthnwFeClxKRjMvC4D6y+BngmrajeCeycttXdw/NifBuY2d+Jc71Y7n8oWFHm+sjsJj8xs/cD5zH6ui39vcxsUWBfxqrm3l3xtZ5Jcs/TMZYnHuydaSp89yCWwfu6+0NJ3/GFBu2mmdnSxJLgZuAxapbA7n51wzHludrMDid+vNcA7wd+UrKvmdlS7v631N+VaWl6DqG2qMTM3gB8EXgh8TBZlRA4/1bSZE/gSOLiAPhF2taEXwD/LwmCy4FpxG/xtoo2P03n/AvALcTF8s0Gfb0q/d0kt82JZVYZ/wmcQKgRfgdcChxQsX+rc29miwPPuPsz6f06xDL5fnc/b3D/XLt13f1uM9u46POSB8pSxDWa3fj5fZySSYOZ/SR9/jzgTjO7idFC4A0FbTLd6BRgHzO7L7Wp1d0mTgTeSiy5NwHeAaxZ02Yf4vf6jLvPMrPViQlB0XeaZ+MbxwP2ZkZsKhAz+rmHpXqSdwZwN6EyO5q4n6omDQBfJu7hFc3sM4Q674j2wx6hqcFtCeBJd382NwO7KLspGnVkthow1d1n1uyX160uTDydK5/qyVC3L/Ba4se4BPimF3w5M9sLuM8HjCvpgfIJd9+vZnwzCIF0mbtvZGbbAnu6+/5V7bqQGSPM7EBgMXc/to3hKRlMFs2E3ZDHNhn4trvv3aJNq3NvZr8gHvi/TrrKm4DvETaEX7n7x0v6OcXd9zezKws+di8wxnTFzCrtHkWTCQvjcFWbSkO2mU1z903MbGYmCM3sOnev9O6wMESv4u731Ow3z8bX9QE7HrJ7KBufmS0EXFJ3XZjZuozYka5w9zqBXU1TvQphxHkR8CDxBPheg3ZGLLM/md6vAryypa5lF+CzDfZbmLDgvgxYeDy6mJp+pqW/M4BJ6f+bCvb7CTmd9eCrYV+3Aq8GbgD+LW0r1GXn2iwOfAL4Rnq/FrBTg76WAr5EzK6nEbP7pWraXDKecw0sUfP5bbn/Pw18NfdbV56HimMuVLJ91fz3JQyWJxBGyNrvCHy+ybaBz89osq1gn1+kc/Ad4Ng0xkr9I6FquAeYld5vWHcdEgbERdL/2xBqpaWHOb6071rp/zWBRwiVxeXA5xr0dUB+TMAywPtr2tyU63t9YDliUlDX18bpHBwIbNzl+su/mvr5mrs/AewKfMXd30T5MjvPSYTwyJbZs4GvNuwTAHc/n+qlb+Za9RtiaXAicG/yKqhqs7aZfcPMLjWzK7JXgyH91cyWJH6475nZCYQxaJDjCAE2i9DDfiO9HiP0g004GDgMOM/d7zCzlwBFs7k8pxNLxMxa/zvgvxv0dRrx++yeXn9Px6rifuBaM/uEmR2Sveo6MrPNzexO0lLPzDYws5MKds2vXLYDfg7g7k/TQt9mwXZm9k3ifBRxNrBE2n9DYsn8ACGkisY2yGsKtlVegwzcQ2k18YoGfb2d0KN+AHgceDHhElbFUcArgb8CuPt06m0B5wDP5jwkVic8JIY5vmXc/dfp/3cCZ7n7gcS5+48Gfe3nOXc5D++ZytUrcEpS5X2CmAzdCXy+qoGZfRL4NqEeWw44PdlyutNEQtNhBpb2aW0hJAR89toN+BxwfU2bu4E1B57Yd9e0mQG8j7ggX5G9GnynJYgLawpxsRwEPL9qFtBk27BejMzMW1llCT/u2m0Dnx9Z9GrQ143EDZkf4xjLOqGTPA44BHgYWDxtX7rhd3oVMXt9gHjovZO42Yv2nZn7/zjg2PT/pPxnBe3eRxhBHwdm5l6zKFkdEg/UvAdH5onxF+CYCbouijxTSr9X+jy7fw+loYdEh3Hlz/u1wC4tr9uZ5LxM0r15R8m+dwL/RfKwaTnOuwgVXvZ+MeCu8Xz3pga3LjMw6GYh3Dn3/xxidvXGmjZ/cvd7c+/vI4xhVcxx95Nr9hmDuz+ee/vtBk2WN7OXuPt9AMnQsXzbfjMyfWbFLk8n3V52ztegmY/mP8xsS3e/JrXbghHPiULcvYtnStb2QbO8i2ehj+Z+xLW3CvBaj9UXhM73uLJjJ4PI7oTQPYswqkxz96rfKz+Y7YjrHQ9Pk6qvcibhs3wMkNdBz/YSi7u7HwMcY2bHuPthVQcvHOhIAM/gcauMTLcnnftkM1uLmDRcV9NV5iHxDpp7SLQd30wzOw74PaF2uDQdY+m6fhKXAmdb+Lc7YVS8uGTfPQlD4KVm9mfi2viBuzfxULmf8Ix4Mr1fhFhtd2ZCU0qa2dsI6/zGhKDaDTjC3X845H5OJnR2ZxM/wFsI/da1AO5+bkGbowgB3dhFJbVrZRA0sx2J3J/3pU2rEVFgl1T0UeZ1YcRsYOWKtq8hrLDrERfmFsC73P2qsjap3YbEb7RU6ueR1G5GRZsrKb7J6tREPyL0yycCmxGCYBN3f2vJ/ge7+wl123Kf/R/x+x8P/NTdnzSz+6qEU1IfvQB4iBA0a7v7M2b2AsI3fZOytgPHaeqCmO2/DKGXz7f5RU2b5+feLkpc78u6+ycr2ixOzPpemzZdAvy3uz9Z0WY9Qphd7+5npYnDHu7+uWGNL00UDibO/WnZ9WbhwriGu59R05cB7yUCl4y45r/p7pUBFxbucHsQ6pB7CXXHNyr2P58IqPg5cc2/hvBb/xOAux9U1V/hMZsI3zRjPZSxfnGlN1nyQNiMuIm3J07M5V5jITSzlQmF+xbEl7wGONjdy3R1mFmVbtK9wH8vPZ2L9m0VZWNmuxBGxMMr9lmE8BCBUJEs7e4PV+z/LPBbRs/GMreaF7n7wiXtJhEPuMuJc2/ADe7+5xbfZyqAu/+9wb55/eSixIU8x90PrWm3HKEO2IFY1l9C/MaF/s/WMsw6rbZeS8x0tiNWaTsAL3b3Iv18dhPvQfjq/tDdf5+2bwSsUPWwTPvtTDxQRrkgunupbcTM3kMInpWJQKHNCEHX2hvDzK5x9y3btptX1I3PzF7h7jcPbNvZ3ctcRrPrvVM6gtwxtiEiNddz90Uq9ntn1XFqVlWljZroOy4lXLnuIiKtTqPGkpvaVepqS9r8nPBJnJJe7wJ+Ph7dykS/CAFXt89SwLuBy4Df1+z7a8IlqOizB2vattInA3unv4cUvTqci6uHeF73JLxGHmW0t8iVhKtfk2MsSjyQziH0xmdW7Du56XEL2s4Ank/SiRLeEqfUtLktjW96er8usQyu62vj3GsTYnZaZ0v5OWO9Ai4p2ffs3PhmDr4maHy3AC8b+O1roy4J18PCe6WizabEg/K3wNWE3n65mjY7kbybhvVqqvN9vrufmpZ6VxNBDU2CIdrE1mcs7+75mey3zOyDVQ06zpYXIk56lovgKuDrXuO7bGa75t5OIi6uwu+WllRvIAJUNiYc8XchPCWqOJ64OYqWrMfWtP25mX0E+AFhBAIq1SlZRrKiaLDK32xAPTKJMFquVDM+ks3gBGKm50QY9Yc86cVzXEdEjC1HeI5kzCYEQS0ey+ofAT8ys+cRhtyyfZ81sycsFwjSgmfc/S8W2dQmeQSQVFrQCd/5J80MM1vEIzBknQZ95c9FZhfZvabNcj7gFZBUJEVkmfO65pLoMr7diN/obcCWhJ75tdVNgFBX3GER3JK/3ouCWz5LrG4eBb4PbFElIwZ4K3CCRXa90328Pr40j3DLBNIfLdy6/kAsleo4hLi555jZk1CchGaAP1tkTjsrvd+TmnBcwiXqTEK3BOFbfDrF7j8ZJxP62syN6O1p23tq+mpkEDSz7xGC/VJCt3kFcK/X6F4B3P2r6Sbe3N2vG/jsKzXNMxVLPtLMKYn4cfevp38vc/drB77DFjV95aOM5hAW/n1r2kD8Vl8F3pTev5X4vV+V38lTmDXJbS6pRLJrdiqh0hqDNXB3q+BJ4DYz+zmjb+Y6nd6gC+KfKHZBzPO7ZFg6n3hoPkrcW5W4+7Z1+xTwT8slrLIIpCh8uHoyQHmDrIXDGp+732dmbyXOxYOEgbXS4JtoY/R9Cnidu/9vh/Htna6/PQk3MydkzFneMXtiU53vTsAvCfegrxAX/qfc/YLKhl0GFNFOJxI3nBOzn4O8wnBhZtPdfcO6bQOfz3D3Deq2dcUiEs4IR/MfeFj3K40+BcdonV2r5DgLe/jGVu1TpFcds20YmNmN7v6qgW03uPtmJfvvTwRZ/IPwlqlMd2mRTa8Ur/DSKNPteY1OzyIK9B/ECuBthJrpe16ixy5ov3Vqc3HVb5V00B8mDKoQATHHuvu9ZjbFy3XameE3W7FuBezv1YbfXQn/1xWIc147eWo7PhubhnIFIpPaU0RndaHMmNmKjGQXu8ndKz2dzOwA4rf5a3q/DBGlWuvPnewVewMfJNSwawJfbjApGsswdRg1OpM1CGtrZaYkYilQu23g88vSCZmcXnsTxr06HdMaufcvoSarEjHDvZaYcT1CzGq3TJ+NiQYjdHhHE5b3XwL/R+QAbXrOPkUYsVply0ptjTA2fRN4uGK/VxM3y4OM1vceRb2e7i3A89L/RxBJeWojfwjf7Y8Tnh+rEsbcTxAO7MsW7P9ranRy89OLUJM0/s2IqMRNCJVb1X6ZZf7dRDTnBun/6el3rLvmlyNUCTs3OZ+pr5e2+B6tx5d+/9JXgz53J1ZH3yYmOrOA3WraFPm0F/ovA7umvzsTnlEziTwSK+R+u992uk5qBvkVImqs8NXgxLyACC28iVjOHUlOqV7SZowALNo28PkqhCHm/whL8/l1PxzhgfEAoeu9mlAfbFux//uJp/h2xMx/avr/OkKPVCeoNiGU/A8A1zW8mLOUiM9QkxIx16ZxYEHaf+v0u/yR0cESh5DCPivaZmkrtyQeLm+kmZFkVsVrTJgn4be5eOuLO4xZBxCqpdOyV8m+hcYlaoxMhN76KuLBsxERvfhQug53LGnzhnS93ULkMZhFBDA9BLyz6nwDqxVsXy3dX5Vh+IQd4ZXErHcrYKua/a9teb47jy+dx+fl3j8PeFWDPmeQBGF6v3yDe7FNYEYWaPKdsvMFbN/22nT3arVDV/cKi+TmexJ64bPT68deUb3BzF4NbE5M5/8n99FU4E0+JHXAQJ+LAOsQs8S73b00GMHM7iJm4I8MbH8+EbJ6iDcI2kguTVt5t+xtVccdDCw4jwgsaJJOEjNb1Vvq+GwkQckxRMTjmVUuYF1JS9nTici4vE92pR7WzH5IuPbtRS57lbsXlWdatepYZefGzKYBhxMqg1MIneINFklYzio6F0kl9ZbU5krg5R46zxWI2eHLSvq6093XK/nsHncvNdZ1cWuz8H1eiZjM5M/7GL/5IYzvVmLV5On9JOL6rVR7mdlt+fOV2s0oO4dpny8QD4R8YMaD7v7hgn0nRPUG9Qa3HxBPo/8bGNAKxEysjK8SFuy93H1aalOnXF6YSPw9hdGW978TltAxmNlXqLDIF92cZradu18x4LUAsIaZlV5Y6XhjDDweFu7fDgreurExonurxCKF5VyPDHf/acmu+xPqjZMZCSxo6mECkf/3C7Tw5QZ+b2ZfJ3xoP58eZrX5QpLAOo1w+yotY5Pj64TB8jba5VBd093fYmZvdPdvm9mZhE9xES/wbmWEprh7FpV1dHYMD8+Fsjb/9GT0MbNZnrw83P1PZlZlpHvGCqq8pAdHXRTjwYRe9AZ33zY9HOqMVVOBJxjtdeDELH/Y47NM8MLcyMImDgEXm9kljBjo9yCq5lTxMeJ+eR+5wIySfdc1syLPmqbpNUup+3JfJpZ8gyf7NcRS830l7V5IPNm/lJThZ1MTlugjLmzfajEDm9ZwvzxbEzfyzgWfVV1YfzezDXwg4suitFKRW1I2ti0I48MP0vu3EF4CtZjZ54gb5ntp08EWIcBFqRRXYiSw4HiL6LPFqowwA3wvjXEnYibwTkKNU8XuRGWK49z9rxbRYB+taQPh3bAPke95GjGrvTR/8w0wx927eDBkXjp/tagl+BAx4ymiaxmh/MNg0Dpf9n3yidv/aaMTt1c9vI4ELksuU5mnyaaE/vxjNeNs7dbm7vvUHHOY47vPzA4iJg8Qar5B18OiMX40TaS2JM7hKV6TitLd/0nMer9m4S65spdHxM2iWFaMnxrdyJ0VnxXqSAr2W5koGXMzYR2s00utTSzfLiWE5BVE7symeqdlaGDsAFZvsi332ZaEYv+o9GPsRMwc7icZ3UraXUkujSHxELqy4XeZSc6xm9BNNXFybxxYkGtzc9ZnblttwARhVPlAem3Q9HdKbScR+s/fEwa/T1FscPsMMVN5AckoV7RfQbv3pOthK0byfby3ZN9OZYQoLnWUvX+mpM2sNJ5GOu+C8/2ddD/dQiQGrz3vhBpq6XT9/oKoz3Zhyb6Hpr+FNp+W4/tOw/GtQPje/im7Zsnpcgv2Xyt9h9uJWe+LWvxmVxGz+mUJNd3NwJfqrothv+oGWZq1p+qz3D6LDLxfh5qsTbTINkbUlFs364sQ1I+kH3CHmn6KDHuV9aCI2eXRhFA7l3B/qvReIFQBy+beLwPc0/AimTnQdlmqjT+TgN0Htk2lwoiT2++G9PcSIpXfRsBvatocnC7+o9PrNlL2qwb9vZzQ7d+TbupXEV4XRZboLkJqzLlocN0tQ0SpZf83FvRtXox4yCw6zOO26H9r4qFXmKeYlP+ZWP2MebXoZ8kJ/A6/JBIvrUNM7s5t0TaLQnwP4TJL2X0FnDhh36FmkFdTkPycWErUhrGWCLg6z4XGBfGIAoyZ0XB/YpY5magdNSbBedpvXcIl5jeMTl/5LhrO5lteJPsQM+ZvpdesphcwoULI2n47tX1rTZtO6SqJmfxSRHLpK4nZwBtq2swklxCdCKipejhcmv3GRP6JvRj7gG58EzX4To3PBbGCaT0bzQvoolfVNV53L1T02Xh12HF838r93+haHWj/aiJ94wPp/QbASQ2+0+UkV1Ti4XxExf7TB943PpfEJOEF6fxtml3LNW1WJHIaX5Ter0cqJtz1Vafz/SiRru1bjOgps5pMhRmoAMxsJaLqxWLJUp3ps6YSfnFVtCmI97SnM0HUY/q+h+7mrgpl/TqEoFma0bqc2VQkYS5wBp/7ERWKd3c/3cwuImZ2Dnzc3R8q62eg7VlmdhXxsDOi1Hpd27bhxdnnmSHvb0RegiYYo1NBPsvoZECDLJf+vsXHhhJn4xgT/mtmbyGCD2ZbJLDeGPi0u99aM77G58LdV6s5VhmDtcRGHZbiyMJnLJJBrWxmXy4YS100XVYu/ZvUl0vvMr78tXwwzVKn5jmeuB8vAHD3GWa2VXUTvkHIm6+nNjOTgbSsEMCiA7JllKzx6sKvRxMrvGvc/VcW4e6/rtgfYgJ0OhGrAPC/xHV1ak27Umoj3JJnwwHEjAhimflVr4giSS5q7yIEdd4oNpt4qpZ6FFiLbGNmdgOxdBszXwsAAB4PSURBVHiYWL6+wt1npc/udvd1B9vk2r7a3a8v+7xg/1WrPvcKI+GAx8LVXpGpKe3fpQBk1rbx+Uv7t/YYybU9hFiKnkdc9G8kft/jS/a/j1gilvVV5sKU1draksibexxwuA9EyRW0a3MtVboT1dzMrUhRUjsQ0WNj0ix6fTTdze7epOJFJ/LuVV1crSxFMObdDq0metTMfuXumw60KY1SteL6fBnuQ6zT12V8Tah15UhC9kiL0uAvJay7le5B6eL5tpm92d3PaTMgb+iXmvggkTRleeB/coL39UT1jTGY2aHufiywl0Wi6MH+C4VNlXCtosBj4SCLnA1VSbQPIdQoXyz4zKkoq9Ty/ME4vDLc/UtpZp6lCtynZja6FLHqKJuFlT2Us9ndfwAnu/uPLfIx1/FSH8hXa1E2vIjsXC9KTBqy8PCXE/7FhekQuwhtjxSf3zezu7wiX3IFrculp7FmXgEO/NKjRFcR2YzcKJidN5iZP2iRj9eT3DiI+urAf7ZI/O9prLsRgT+FeIf8Edm9XzbhqPlej1v49Gfj24xiL6fm46mb+aaOXk8sB35D/CCrE1bji2raLU082efO+oCjvSJjlHXMNtYUSzlCrWUMv41Ooj7qIyri3ZOP4IYe7i1Y5Jq9tUxNkWs3CXi1DyS7aUK68Fcj93B19+/UtLmSSGaSVZFdiNDRVl7kSfj8P+KhfG3NrLyTw7qZ/ZTwiNiBMMD+g9DpVwbeFPVXNwYz+z5RXv229H594CPu/q6S/VvPwMaz2kjtW61uUpuTiDwEeX/Y37j7AQX7Ft4buY7qZub5fM2ZH21pvubU5iWEHntzIuvYLOBtTSY9Ta/3rvd+arsx4f2xPrH6X54IY26UXa/wmA2F792EBfTe9H4N4GdVy/q03zlpoNmXejvhdlKa1s+iyOFCA22edfcx2casJnuVu3+p6vN5QRK+22SzkuRXeFWd8E37tk6sY2ZnEHk0pjMyY/QGN/Q9hLDPxrkM4QFRFZX0SWKGfA5xk+1CJCIv1NNZx+g3iyoMOxJRdL+28Cd+mafghoL9M5vDdwmjXt7m8LUadVTrJE1tGa9w69jnHcD6nm749HC/zSuSvefaLuGjy2dNGBYJiiZ5w0xhXa/3jmObwkhE7D3jnRA2TSnZpUYaROKafNXST5nZ9Jo2mw7MaK6wCMcsIouEW4dY2mdZ1namJGeumf2E6lnHmDygJcdpWi7mGODWNEMyYkbftG5Xl3zImxBZ+Zvun/G53Dgh3JGOqmmzJ7BRtrRPKpZbKDeSvL3lmADwqN12rpktbmabEIlMCgVv4t8Jm8PKRD6NjNlEKHAVd6UJwHeJ62Rv6pfMmNk7SsY+ZgY2XuGaHkaHEEnE97eoybaOl0c/QthEViG8ZyAyFFbO2ixC/k8lIk9XsQgoeq+7v7+m3RgjIrFEn+buPy7Yfx1CzZY9FO+yqFXYJPVj4+vdzCqzMBbd+zY2EjZjbauJiK2jUvjmOr7DzC5kdI20XzU4fuuijESp6jXc/TepzUsoseh6Sg1oZpcSceGz0/ujCItwEVnhxV0Jv93vpvd7Eu5GlVgYz77IQLkYBsqA58bYxWMhI8uH/KyZ/YMaFUfiduJ7NSkKmB9n3isDmnll3E+LooLufjvMva5qUxWmc/1lwnf7CCJs/WFgNTP7WJkQG4/NgXANfB8jCcV/wUjUVRWb5v5flEjclAUZFGJRnutjhK69aUg3hNX9ZmKJDpFb5IdAlfB9PiHUbsqN9/pMIJVMOrp4LUB8l3UZuQffTLiF7mtm27r73OIIScCfS6g1TyGuhY2Aq8xsV68P+W5zvb+aCOY5i9DjV1ZGTVRFt1XZKWqpS6xzelXHXlAbbaB9Fu2yVNr0KOE3WPrENbPtiYvrPuLkrEoYckp1a0ktsoGnxDgWOQZm1Cwvf+HuW9VtK2g3gzB4XeaRVGZbIhdoaUVhM3s5Y3VSnX+0mvFdCWxIZJLLG2NqZ/Rm9iLifOfHWVp1wzoWFTSze4Gdvb6eX6cENLn2ixA3/moD3+noqnbDwMyWAs6oOu9p0vADwgNkbki3u1eG4prZNHffxNp5E2xddUwvSPRkHbwW0j5XEPaDOen9FELv+xpC1bFebt+LiJJkVxWM9+Pu/rqavhpf78ne8hpiovVy4GdE8qM7qvqYKCpnvt4+tnuw/QxgA8sVZbQoCVQqfN398mwZBfXZxhJnADeZ2XmEEHgTFTOORNeS7q3KxZjZacQPfQcjeQAaPTHNzIhMXKu7+6fN7MVEApibKpod1eA7FPX1ecIIMzjOqpJH56VXxlUNu3u4TvAmuiagyfgxsdy9mfrELqR+tiDO4eBDqFVhVSIhzVo1+3Qtz/W0RYmqTH+7BjXfz92vtnCXXMvdL0vtp9ToVrt4LUDo25dgxBtgCeCFHmWaBse5xqDgzY33lAZ9HdVgn+yYzxK5ai5OD+Y9iRn20d4gGbpFFZ/BxFOdH+SNdL5pBlzkmlE5883tl8+AdgixnBnsY29iJn5GErYz0/b9zOxxdz+z4vifMbOLae7yBJFn+CoL31NIJd0bfJ225WI285I0ew04iRCE2xGhzI8RS+9NB3c0sxOJHA5dU1XuQugNGwmpxEU+4O9tZuu4+z017aaZ2Q+oT1XYNQFNxsruvmOD/fKcSlwbN1MfwDCXAVvCJEKVcHZNs67luY4khMiLLcpVbUHouKvGtx+hV12WMFCtTARqbF/R7D8Jr4UXEaqNSxldnqqMY4HpSd2W2Tk+a2FMu2xg3yrh38TINw34h0cWtLUJdUepF1YSuv9BCN7VCLVWk4nQ14gAsW2J4JbdiNl2Z5p6O+SNZosSM8s/dLEomtmD7v7igu23EnluZw9sn0okoql0Kk9LihUZPVspLT2U2owq6d5E8FjLcjFmdirwRXe/s+7YBW1vcfeNmyz7zOxgIurwBcRS9ix3rzNu5ttfRESePdaizT3AJ9z97PT+w0TIZeXDpkSdNUaNZWb3M1I2qGj/ytlomjl9xZPbWBOsoMRRw3b5Zf0cwihYWZzRxlGey8LndDPi3Nzg4Ttctf90Il/KjblraVQu3GFi4ZHyyjS+m9y9sDZdmrx8v+gjIjfHijX93Ey4Oi5DJKSfBjzh7m8r2PfbhKvYRUQ07O0tvk8W6JP9XZIwhDcp8ll8zCbCt2AgkwidZ+soEjN7wN1XKdg+00vcr6o+S58fSMwGHmYkxNWr2qR2rfxhk4C/xN13qDruQJutiPLnDxGzvMZ5QM3sRsKo8qskhJcnfG9L3bXS0vKt6bUoYVz4vtdYji3cAjcg4usbJSxPN9gphMFtRWJJ+uE2AnwiMbM7Cd/WWTQ89xYeG5OJ2VD+PBT6L1ukQH1X+v+dPgFuYiX9ttXPj9LfJj3sLTXnopXXwkDbZQi1S36JPmZ8Nn6f4myCciCwmEcQRaFroJn9k5HZdF7wNalNl52/Gwhj/SOE/rpOtVRKU1ezQdYi3FYKseqAhMVKmi1kBf6EFuW+F64Zz8HEkrlRscJ03EL/QCp0xd6ttPhphItV20TgEEui84AVLCpV7EbUOivFwyn980Ry841S/0cSAqWKCxhx1WuEu/8xqXsOI77bYVWC11pGGNn4Q34rjTUlZLPeTfJdUR5VmF+FNMqDUPb953ZW75PdRT9/tZkdTuRAeA2RL7cyzJ0WXgsD4yusmkHBORzCw8osPCbexkjl7MJr3d2bqKrK+KlF0NixjER+liVgb0RTnW8mTC39fYiK5Mju/ryyzyo4FfiRmb3P3e9P/a5G6Djrklc8SPtQv67+sG1Liz/QZBlZhLt/Ly2rtifO/S51hiqLyLQdiZnv9kRUYV3Fgk43QToHfySWcisDp1l4jJTlb8hUL02T4BeFV2dUhllDPIgs8kGs5eFKtzzhs1qIRXWH/yaW5o/ltlcJ8fZLx9Hf/1PEw7ENXfTzHyPyoNxG2DYupF54rAls5yNeCyeT81qoaNe4aoaN3+/+YOLhf56732HhmloVddgKM9uUKDH06fR+SeK7383ocmftj91F7TBRmNl/Eicyu0EeAz7nNbXRkl51HcJ1JL9ULI1ws6jvdZC7t/KHLVsmlQkvi7DOpYlZRm0drIG2Z7j72+u2pe2ZC81OhA/j94HzB1cSFX3Nong2WhWyuovn8gOkpexh2YVasP88XaJblJDfhBBUa5vZC4kIvC0K9j2IMCbdRbguHZwtra0iJDmnszRiNjpKf9lgFts66q+tfj6pCWe6+/q1O49udw+RUvZv6f1SxINp3apx20gSmulEEcynKlQBma680O/e3euCYvLHWgb4a4cJVdUxbyFygz+SVIjfBw4krpGXunthibMm1AVZrEp8mezkb0s8de8nMps93bXjItw9K+2xJPFgaBRiSGSjf4BQT9SpKDKWA+60cDpv7A/rUQtsMSK6qM6qD6FmeYrmdbDyjArcSDrnMsPj4UT2/494TYKVEvLL7EUJ/9pli3a0lHXN3c+3KEnzFIC7z0mz4TI6pyq0yLEwGIxQ5074JsJh/5a0/x+SGquI/YiseI+lFdePzGw1dz+BYoNfRr5sUpeyVo0FRU5d8QThTdBIP+/hCTDDCuqr1dDGayHP79IS/XwireejhCdH0diuTt/t0z7ax/4nZlalw/4kcLZH9r9FCCPahsAcM9vL3avG14bJuftpD6JM0TnAOVYfrVtJndrhbOIC/puZbUjofo4hvuRJxDJmKFhBngbLFSCsmsV6inRryVEd2mBmOxNRcgsDq6fzcnSZ0PYOvtJmdhghTBczs8xNz4CnibynRf1sm9quYeGa95SZbUMIvO94TaHKAn358WZ2DQUpDwkhn80Er8/9D7laaMMizWC3IYTvhYQu9xrqfbmfdne3VEg0CY0yJmczSXe/P527H6UJSKnwzWbvZvYWdx8VVWmRh3iYZML9Zlrq5wkvmDvSZCOvLiudbHj4IF/IiNfC4T7itVBaq8/d35T+PcoiCGIpwjWuirZ+93sQ7pcQwSmT0v5rEw/1oQlfG6mDuD3hrpfR1WbWqPFiuZO9N3Cau38xLWPGJfULaJ2nISPp8g6lReVdDyfuFRnxmb3JK3IU5ziKuBivSseZni6UsrGtTYSnruju61tEu73BS5LPpGMeAxxjZsd4derJIs4BNjGzNQld+QWEsHx9VaMB49YkYiZcNku0kv+L3ufpmqpwN8Kwdau775N+tybGjrMtqisvbeHn+m5KHl7AQ2a2oSf3vDQD3okwWDZxxzqMsSHtRdsGDdKLDzxg3Uus7jlBvwRREPPZ9H4yEdpdRZcJCoSN44/EfbWmma3p1V4Vo1Qc3tzvvMjvvjRqlLGFFM7y+kIKXTiLMFb+mXAx/SVAur/GlVKybpD5G2k7UkKYtIwZT79j8G55GjJaV941s92BLxBC1ICvmNlH3f1HNX3Ncfe/DXz/qqVj2wz9efLJjLKb7Iiamf4/0/L/TcDx7v4VCx/qOvLGrTmEamn3kn295P+i93m6LtEzJ/o5Fn7ff6K4AgMw98ZY0d2PS7rwvxMP9YsoLyv+DgaCZdJs5x1JgJf19TriwfaigYfJ1MHj5Y7bxSCd53IiXWOm812MMIRtXtaghRCci7XwWsj100nF4e4XW0S2NvW7fyqpoh4mAh/yRt66ajmN8QjgupxUdign8CcRut/O1AnfK8zsbOLJtwxRKyrz7xyqvjfHKgPHfpryct8ZXcI0/4vIoPYnmDt7voxIzl7F7Wa2F7EcWYsIubyuYv/F3f2mAWHdJDQWYHuLAJd9CR31aYT3QhXPWCSJfycjSUEWquvI2yWnLpvBGhENVdZH1yX6tKRD/Aax5H6M6uii40nZy9z950TuCSwyoh1PQbIUrwiI8Oqcyn8gHiRvYHTy+dnEbG4iWDRvbEuz9EKBY2bXuPuWNtb9s0mSpsZeCwO0VnFYeOm8l1webzOryuPdupBCV7wguY83y7hWSZ3w/SChW3kBUXE1OxErMVLLaNh0ydPQJUxz0oCa4S80C1k9kPjuTxHL+UuonsW2ytCfx933MrM9CNeWJ4gEPnXJ1fchZv+fcfdZSSXy3Zo2mSX7SJolvq+awTaZ0TZeogP4SArDr1n4FU/16iTWqxV97u7TkjFtaHjkL5lhZmdWCIph87iZbezJz9nMsgTzRbwtjbPLbPtJd3/SzLAwrN5tkf6xji4qjpOJScJJ6f3b07ZCu5K732DhefRPjzps6xEulne7+5gKNfMjrVzNLEIatyJ8VytLzIxrUHExZXkafuE1eRqsOEzzKK+olWZmXyCMUfnM/jO9PqPURnXjGdh/PBn61yKMB7cRJZzuBA7xyG87VKxb4vvCGezgttxn2RJ9d0bKFUH8Xuu5+ytL2l3u7tvXbct9dq+7r9n2s/GQrsFPMxJ11mRm2bWvTQmXp8we8wKiqvWYB5+Nrsd2jo/Or13Xz3nEw/yDhKrhUWAhd6+0H3TBCsLmi7blPjuSMLxOIVY2ryJUiDsQUaifGfYYh45Xl0v+KZH9HuIH/iPhr3on8MGqtuN5EREqLyRUEKsQbl1tj1E4PsJxfIv0/65Esu3/Iaz6azQ47pWEg/WngX9rMZ4lCAPWFEL4NmlzN7B9+t+AD1NT3p6IPvxR+o3uy14N+preZNvA52PKdRdty322AaEO+W36m712BZYp2H9Rwt1tBqH2ykqerwbcVdHPWcB+Bdv3BX4wQdfsvcTD3Cbi+AN9LULMEtcnjIELAYuU7Htr0f8d+tyaUK0s3GDfzYh8348RasNngb/XXUv5+4/Q6VddS7clObE4odOfmrYvRk0Z+PnlVXcS78j9fzjhskQSIhPyBYll/Z+JMMaZ6SS37ouYnRdt/ymRF3Zw+ybATxoeeyVC13ttGt8RBftMJZbSJxIRQQZ8gDBk/bhhP1MLtq1V0+YawiVmJjELO4pI1lLX1/WEail7vwVwfcm+ryNWGA8TIdDZ61uE10hdXws1/P4HM5KXYVbuNQP4QEW7FQk9/FWEIfGLhBrlemClCbpuryRUWUM/dkFfjR96+e1Vwqyg3STg9o7jm0ZMcm5NAnIf4LM1bbYnfPWvSr/V/cC2FfuXPlSomTTML6+6kzg99//lxNJmQr8gMYN4/hCO82DJ9tILikiU0aaPlxE66qcLPvtxEkbvJfylf54uqg0bHPfQ3P9vGfis7iK+efC7EJVq6/rcIAm1+9PrVgoeUrl9G89gC9rvlI7/CDFrmU3FzAg4sOM1sC3xMD+QCJMd+vWa62tTwpf1MCJt6iGEimiYfaxEBNncRQSPbJxe2xC6zqI2z+bO8Zz0f+05T22/R7dV57T0d2Zu23UN2i1CrB42oGQmn9v3RsKYDbmHHuFT3Pgh0+erzuD2oEW2oN+lH/liAIsIr1oLeke65GkookyZXVY6HMqT/szFzF5K6Id3I4x0PyDUAYO8xFO6PouaYH8mLuQmUXtvJaKLYKwhakeq65A9mXwtf21mHyCq/q5Q8X1WcfcHvCDxfVkbH7+R6XhCUN/m6Y6p4esW4b+tKlp7VD+5ssP4uvAZYpm9KM2jLNvSujadu9clVKqitddC4gmL5OszzOxYQl1ZFeDSxdthKx+JrMwnrFqImAjM99SVEVoBOJr4Eb7qqWihRZjxK9z9uNLGXQfUIk9DgfvM3I+IAJExDxczOwu4wt2/MbB9X6L0yR4147uRUF1cRaR6fLJkv1H5AAbf1/SRz987KoZ+8H1B202JmdHShF56KeBYL6mFNU6DTCcjk0XU0/YDN03V/o0rWveFpdI+86ivLrXpuvSzddF2r/EZtogKfJh4CH2IUMGd7KOL8A62me9/42EzXyXWgblWzDF4txDiouOvSKRpfJoRv8xNiAvlTV5SNNIiauazRJTUAyQfV6Le3H8NPqHN7FlitpA5+C5GuIs1yR2aF4idhXgTqgR9g7b30m4Gm7XblBDaV1PxgLUU1tnWEt4HFnmAr/Dqqsrj7WNvd/+uRdL6Mee7aIIyLzGzNxLVQ76a3t9IrLqcUKWV+tAvCL/xsKlLrNO61PJ4GZaQrTj+w8DmafaeZXn6mbtfUdP0C4ShcXUfib6bSuR5OI6RardZP+NZ7m1gEXJqjM3vUKg2Gcdv5SX/N+FBQofetl3TJfpNhLqrcUXrHjkAONSiRtkzTIyrWbZ0L0qLOfRZlJltRhhWX0r8TpOBxyu+06GEyixjEUJHvSQxSakKYFoQfuOhUqfz7VJqeVxYhzwNXeigD9wJWDsvaDwKgr6PcAk7eLCBdUzl11Fwd/2tqgR9nfA4FLjQIpqwUSrPxLLerPxK9h0+Alxpo+P+x1Xcddj4+EOGm/Cz1NeYCYpFwqdhcyIhTH9IrA7fQXVR0IXd/cHc+2s8MoI9YiVJjSwK6l4LfJyIqJ2VPlqNWGU+Z6kTvisxUmp5L+ZNqeXWeRrmEV40w/OoblE46/Duqfy60Om3GucMvauR6TIze22DJfryNpLt7uukmVfqbyPmnTGtFouqx9Pd/XGLYrAbE7k1hvm7X25m/+6p2ECu732AI6ivTNEad7/XzCZ7JK053cyqQumXGWj7gdzbsgxlKxNFOl8K/C/hAXMzcLqX1H17rlBXOn5cpZY70rWc9kRzp5m9wwdyyKYb7e6Kdl0txq3o6bdqOoMdpOkSfTKxZM3P4rMl97yYabbhZGIVsQGxIjiVcEMsNFp15ENEftzXu/uvgSz96F5D7iejrdfCjWa2X4Ex+72U5OLwVPUk9bMJEQn6auAAM/urd6/8Pd9Tm3rNOpZaHgddy2lPNAcA55rZu4knsxO+nYsR+SfKmFAddp4efqumM9hRtFii/9Hdj+4wrj6Y4+6ejE4npAnEUF2e3P3C9MC6yMx2IfIebEq4XT06zL4SbyeCLQ4gBP/KRB23Mj4EnG+ReCqrr/cKQve7S01fixFeEUul1x+oLlW0wFPnata51HLnAXXI0zAvMbPtCH20ERGAl/c8JKC332o2MRNqZWRqukRv633RJ2l1djGhi96KUJVN9wkozW5Rl+58Iopv9zJ3x3Ecv7PXQto/u0cg7pFSY7aZnZL2nU3YKm4gsqhNxMNkvqJO+HYutTxMzOyD7n78vOhr2HSwGHftZ774rZpgZjOJKKaXE0vzU4Fd3X3rgf2W9W4lkeY5ZrYSsfz/lbv/0sxWAbYZVFONs498IdtFiAfeswz5Nzaza4lo1gfT++lEYp0lCV1sYUKjjn1dTKRLvZ14mFxPNw+aBY75zs+3CDN7wN1LS9XPz5jZNAosxt6iMOD8SlcjU+arbFGH6/dpiT5U/+U+MbPlgL8sqALEUgHM3PsTM+OZmd3g7psNuT8jZr+bp9f6hOHtencv9Pt/LjCeOvbzkgl3cZtIPCJ7Jrv7s+5+OhGL/1zgZMIokxmZfkvMZOuYnQxFewM/s6jQMVHh6hOKmW1mZleZ2blmtpGZ3U7M4h42sx37Hl9HungtdMaD24kqIxcRrmdrUOC++VxiQRG+C+QMIpFZjKeb2bFm9iFq4twXIOak2V1mZDqBZl4IexB64n09IgpfRASxLIicSEQ+nkVUenmPu69E6H2P6XNg4+BGi5p3o6jyWuiKmR1kZt83sweJWo07AfcQkZOF1bOfK8w3agfrkKdhQcDGxrkvBZzkFXHuCwrDMDI9B5bo0919w/T/Xe7+0txnC4zBMI9FTpfziQfkGK8FjyjRYfX1JULXe627N6rw8lxhvhG+z2UsssCt4u739D2WYdLWyJSMj58j9HmfJlQUyxErsHe4e1158fkOm4d5OOY1bbwWRHskfCeYFPZ5HBF6ubqZbUjURht6Xow+aTKDTcbHw4nZ/ynA6zxqca1LROMtiLPEfAKlLHkS6f2i7r5A6rLFxLOg6HwXZI4CXgn8FcDdp1NfjXm+ZhxGpinufqlHjbeHPKW5dPeqCMH5Gnef7O5T3f157j4l/Z+9l+AVpSyQetQFjDnu/jezBdphY5ATGZnBXsHADJaUdL+AfP7ewWq7WoKJfykkfCcIM7uQCMu8PYVbTraoRnwQYWBYkJniI4n1j87PYGseMq1TZQrxXEVqh4njW8AlRD209QnL8ZlEiaQF3X+x0wxWS3QhRpDBbQKxyGH6SaLu2hmMCCb3nqsOjAcZmYQYP1I7TCzPEEJqESIu/jnxpPPx5QAWQiDhO2Ekq/+XgAuAjd39iZomQoh/IaR2mCDM7JfAf/rEVv0QQiygSPgKIUQPyNtBCCF6QMJXCCF6QMJXCCF6QMJXCCF6QMJXCCF64P8DX8rUEtsGluQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the remaining null values as they are very less\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle Categorical Features\n",
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine Test Data \n",
    "\n",
    "test_df=pd.read_csv('formulatedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg         Lvl   \n",
       "1          20       RL         81.0    14267   Pave      IR1         Lvl   \n",
       "2          60       RL         74.0    13830   Pave      IR1         Lvl   \n",
       "3          60       RL         78.0     9978   Pave      IR1         Lvl   \n",
       "4         120       RL         43.0     5005   Pave      IR1         HLS   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...           0             0         0   \n",
       "1    AllPub    Corner       Gtl  ...          36             0         0   \n",
       "2    AllPub    Inside       Gtl  ...          34             0         0   \n",
       "3    AllPub    Inside       Gtl  ...          36             0         0   \n",
       "4    AllPub    Inside       Gtl  ...          82             0         0   \n",
       "\n",
       "  ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "0         120        0        0       6    2010        WD        Normal  \n",
       "1           0        0    12500       6    2010        WD        Normal  \n",
       "2           0        0        0       3    2010        WD        Normal  \n",
       "3           0        0        0       6    2010        WD        Normal  \n",
       "4         144        0        0       1    2010        WD        Normal  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.concat([df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500.0\n",
       "1       181500.0\n",
       "2       223500.0\n",
       "3       140000.0\n",
       "4       250000.0\n",
       "          ...   \n",
       "1454         NaN\n",
       "1455         NaN\n",
       "1456         NaN\n",
       "1457         NaN\n",
       "1458         NaN\n",
       "Name: SalePrice, Length: 2881, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There is no saleprice in test data as it is target feature\n",
    "final_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 75)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehot encoding the categorical values\n",
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "    \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 235)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = final_df.drop(['SalePrice'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data for PCA \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scalar = MinMaxScaler()\n",
    "df_transform = scalar.fit_transform(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "pca = PCA()\n",
    "principalComponents = pca.fit_transform(df_transform)\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.374957</td>\n",
       "      <td>0.507279</td>\n",
       "      <td>-0.734305</td>\n",
       "      <td>0.166559</td>\n",
       "      <td>-0.540328</td>\n",
       "      <td>-0.788998</td>\n",
       "      <td>-0.537333</td>\n",
       "      <td>-0.430001</td>\n",
       "      <td>-0.058398</td>\n",
       "      <td>0.213510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071656</td>\n",
       "      <td>-0.045782</td>\n",
       "      <td>0.039110</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>0.045752</td>\n",
       "      <td>0.035592</td>\n",
       "      <td>0.042946</td>\n",
       "      <td>0.128028</td>\n",
       "      <td>-0.009107</td>\n",
       "      <td>0.051379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.365027</td>\n",
       "      <td>-0.977871</td>\n",
       "      <td>-0.164995</td>\n",
       "      <td>-0.219089</td>\n",
       "      <td>-0.534904</td>\n",
       "      <td>0.112741</td>\n",
       "      <td>0.378390</td>\n",
       "      <td>0.300163</td>\n",
       "      <td>-0.225925</td>\n",
       "      <td>0.217784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128812</td>\n",
       "      <td>0.125321</td>\n",
       "      <td>-0.141672</td>\n",
       "      <td>0.270264</td>\n",
       "      <td>-0.164756</td>\n",
       "      <td>-0.063683</td>\n",
       "      <td>-0.028697</td>\n",
       "      <td>-0.480173</td>\n",
       "      <td>-0.442352</td>\n",
       "      <td>0.249152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.742287</td>\n",
       "      <td>0.282966</td>\n",
       "      <td>-0.951845</td>\n",
       "      <td>0.428702</td>\n",
       "      <td>-0.403940</td>\n",
       "      <td>-0.016543</td>\n",
       "      <td>0.031227</td>\n",
       "      <td>-0.239797</td>\n",
       "      <td>0.359548</td>\n",
       "      <td>0.372738</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133136</td>\n",
       "      <td>-0.051604</td>\n",
       "      <td>0.081158</td>\n",
       "      <td>-0.050342</td>\n",
       "      <td>-0.012230</td>\n",
       "      <td>-0.002258</td>\n",
       "      <td>0.057891</td>\n",
       "      <td>0.161044</td>\n",
       "      <td>0.028953</td>\n",
       "      <td>0.047723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.658065</td>\n",
       "      <td>0.794632</td>\n",
       "      <td>-0.426022</td>\n",
       "      <td>-0.152951</td>\n",
       "      <td>0.637371</td>\n",
       "      <td>1.048850</td>\n",
       "      <td>0.334613</td>\n",
       "      <td>-0.170799</td>\n",
       "      <td>-0.119134</td>\n",
       "      <td>-0.457921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216011</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>0.019439</td>\n",
       "      <td>-0.003640</td>\n",
       "      <td>-0.068425</td>\n",
       "      <td>0.284673</td>\n",
       "      <td>-0.439591</td>\n",
       "      <td>0.105475</td>\n",
       "      <td>-0.151211</td>\n",
       "      <td>0.047374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.769017</td>\n",
       "      <td>0.293021</td>\n",
       "      <td>-1.121618</td>\n",
       "      <td>0.337571</td>\n",
       "      <td>-0.048977</td>\n",
       "      <td>0.310123</td>\n",
       "      <td>-0.007072</td>\n",
       "      <td>0.125810</td>\n",
       "      <td>-0.346535</td>\n",
       "      <td>0.187086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273731</td>\n",
       "      <td>0.453972</td>\n",
       "      <td>-0.125108</td>\n",
       "      <td>0.159688</td>\n",
       "      <td>-0.228599</td>\n",
       "      <td>-0.191250</td>\n",
       "      <td>-0.149214</td>\n",
       "      <td>-0.531572</td>\n",
       "      <td>-0.230655</td>\n",
       "      <td>0.160527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  1.374957  0.507279 -0.734305  0.166559 -0.540328 -0.788998 -0.537333   \n",
       "1 -0.365027 -0.977871 -0.164995 -0.219089 -0.534904  0.112741  0.378390   \n",
       "2  1.742287  0.282966 -0.951845  0.428702 -0.403940 -0.016543  0.031227   \n",
       "3 -0.658065  0.794632 -0.426022 -0.152951  0.637371  1.048850  0.334613   \n",
       "4  1.769017  0.293021 -1.121618  0.337571 -0.048977  0.310123 -0.007072   \n",
       "\n",
       "         7         8         9   ...        50        51        52        53  \\\n",
       "0 -0.430001 -0.058398  0.213510  ... -0.071656 -0.045782  0.039110 -0.011082   \n",
       "1  0.300163 -0.225925  0.217784  ...  0.128812  0.125321 -0.141672  0.270264   \n",
       "2 -0.239797  0.359548  0.372738  ... -0.133136 -0.051604  0.081158 -0.050342   \n",
       "3 -0.170799 -0.119134 -0.457921  ...  0.216011  0.043292  0.019439 -0.003640   \n",
       "4  0.125810 -0.346535  0.187086  ... -0.273731  0.453972 -0.125108  0.159688   \n",
       "\n",
       "         54        55        56        57        58        59  \n",
       "0  0.045752  0.035592  0.042946  0.128028 -0.009107  0.051379  \n",
       "1 -0.164756 -0.063683 -0.028697 -0.480173 -0.442352  0.249152  \n",
       "2 -0.012230 -0.002258  0.057891  0.161044  0.028953  0.047723  \n",
       "3 -0.068425  0.284673 -0.439591  0.105475 -0.151211  0.047374  \n",
       "4 -0.228599 -0.191250 -0.149214 -0.531572 -0.230655  0.160527  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=60)\n",
    "principalComponents = pca.fit_transform(df_transform)\n",
    "df_final = pd.DataFrame(principalComponents)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(final_df))\n",
    "\n",
    "#plt.show()\n",
    "#for column in final_df:\n",
    "    #plt.figure()\n",
    "    #df.boxplot([column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_final.iloc[:1422,:]\n",
    "X_test=df_final.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = final_df['SalePrice'].iloc[:1422,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 60)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 60)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Classifier Modules\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing K value\n",
    "score1 = []\n",
    "# Will take some time\n",
    "for i in range(1,20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    score = cross_val_score(knn, X_train, y_train, cv=k_fold)\n",
    "    score1.append(round(np.mean(score)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Score')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "plt.plot(range(1,20),score1,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Score vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66615594 0.65755001 0.71154549 0.68839385 0.70105639 0.63689329\n",
      " 0.69839963 0.72079848 0.7043931  0.64871571]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68.34"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = KNeighborsRegressor(n_neighbors = 6)\n",
    "score = cross_val_score(reg, X_train, y_train, cv=k_fold)\n",
    "print(score)\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35970483 0.25382739 0.41126928 0.44036345 0.09831774 0.35527792\n",
      " 0.38991978 0.43623492 0.32778373 0.29043958]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33.63"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = DecisionTreeRegressor()\n",
    "score = cross_val_score(reg, X_train, y_train, cv=k_fold)\n",
    "print(score)\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35389962 0.41514217 0.36493286 0.43322347 0.14354781 0.35812813\n",
      " 0.32749481 0.41353974 0.19681735 0.43746105]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34.44"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = DecisionTreeRegressor()\n",
    "score = cross_val_score(reg, X_train, y_train, cv=k_fold)\n",
    "print(score)\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61577148 0.69560195 0.65191891 0.66383412 0.68172834 0.65068163\n",
      " 0.60221403 0.77808786 0.67518827 0.70278143]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67.18"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = RandomForestRegressor(n_estimators=13)\n",
    "score = cross_val_score(reg, X_train, y_train, cv=k_fold)\n",
    "print(score)\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74241618 0.78328722 0.73796346 0.75336776 0.73158929 0.67650114\n",
      " 0.71927681 0.78985973 0.7071761  0.75786082]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73.99"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = xgboost.XGBRegressor()\n",
    "score = cross_val_score(reg, X_train, y_train, cv=k_fold)\n",
    "print(score)\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization showing only for XGBoost due to high computational requirement\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=regression,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  6.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { max_depth, min_child_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, gamma=None,\n",
       "                                          gpu_id=None, importance_type='gain',\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100, n...\n",
       "                                          validate_parameters=None,\n",
       "                                          verbosity=None),\n",
       "                   n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
       "                                        'max_depth': [2, 3, 5, 10, 15],\n",
       "                                        'min_child_weight': [1, 2, 3, 4],\n",
       "                                        'n_estimators': [100, 500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_absolute_error', verbose=5)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.75, booster='gblinear', colsample_bylevel=None,\n",
       "             colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "             gpu_id=-1, importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.05, max_delta_step=None, max_depth=2,\n",
       "             min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=None, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=0, scale_pos_weight=1, subsample=None,\n",
       "             tree_method=None, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.75, booster='gblinear', colsample_bylevel=None,\n",
    "             colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
    "             gpu_id=-1, importance_type='gain', interaction_constraints=None,\n",
    "             learning_rate=0.05, max_delta_step=None, max_depth=2,\n",
    "             min_child_weight=2, monotone_constraints=None,\n",
    "             n_estimators=100, n_jobs=0, num_parallel_tree=None, random_state=0,\n",
    "             reg_alpha=0, reg_lambda=0, scale_pos_weight=1, subsample=None,\n",
    "             tree_method=None, validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:22] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { max_depth, min_child_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.75, booster='gblinear', colsample_bylevel=None,\n",
       "             colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "             gpu_id=-1, importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.05, max_delta_step=None, max_depth=2,\n",
       "             min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=None, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=0, scale_pos_weight=1, subsample=None,\n",
       "             tree_method=None, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(regressor, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ce32daa64732>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#y_pred=regressor.predict(df_Test.drop(['SalePrice'],axis=1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'regressor' is not defined"
     ]
    }
   ],
   "source": [
    "#y_pred=regressor.predict(df_Test.drop(['SalePrice'],axis=1))\n",
    "y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([106295.766, 144711.28 , 178539.92 , ..., 155574.56 ,  94581.38 ,\n",
       "       237820.84 ], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred=pd.DataFrame(y_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 196444.8125 - val_loss: 198415.1094\n",
      "Epoch 2/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 196516.2344 - val_loss: 198392.5938\n",
      "Epoch 3/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 196026.4531 - val_loss: 198311.1875\n",
      "Epoch 4/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 195960.5312 - val_loss: 198097.7188\n",
      "Epoch 5/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 195748.7969 - val_loss: 197638.2812\n",
      "Epoch 6/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 195210.3750 - val_loss: 196773.9062\n",
      "Epoch 7/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 194008.2812 - val_loss: 195320.3438\n",
      "Epoch 8/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 191990.6094 - val_loss: 192939.3438\n",
      "Epoch 9/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 189327.9219 - val_loss: 189394.0781\n",
      "Epoch 10/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 184687.4688 - val_loss: 184265.9219\n",
      "Epoch 11/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 178251.9844 - val_loss: 177003.7969\n",
      "Epoch 12/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 169853.8906 - val_loss: 167105.8125\n",
      "Epoch 13/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 158883.9688 - val_loss: 154040.4062\n",
      "Epoch 14/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 143605.0625 - val_loss: 137247.2188\n",
      "Epoch 15/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 125067.5000 - val_loss: 116204.5234\n",
      "Epoch 16/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 101940.6406 - val_loss: 91229.8672\n",
      "Epoch 17/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 75523.7188 - val_loss: 64604.4492\n",
      "Epoch 18/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51429.4258 - val_loss: 46706.6328\n",
      "Epoch 19/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40648.5625 - val_loss: 42214.3555\n",
      "Epoch 20/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37706.8281 - val_loss: 40219.7852\n",
      "Epoch 21/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35724.7852 - val_loss: 38699.1016\n",
      "Epoch 22/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 34068.7812 - val_loss: 37428.1016\n",
      "Epoch 23/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 32774.6406 - val_loss: 36423.1016\n",
      "Epoch 24/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 32255.3242 - val_loss: 35557.7695\n",
      "Epoch 25/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 31119.4238 - val_loss: 35094.9180\n",
      "Epoch 26/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 30056.0488 - val_loss: 34592.2188\n",
      "Epoch 27/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 29636.2559 - val_loss: 34172.0586\n",
      "Epoch 28/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 29333.5840 - val_loss: 33905.3984\n",
      "Epoch 29/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 29123.7441 - val_loss: 33625.1211\n",
      "Epoch 30/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 28868.8262 - val_loss: 33445.4648\n",
      "Epoch 31/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 28552.9141 - val_loss: 33354.2305\n",
      "Epoch 32/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 27984.5293 - val_loss: 33229.5898\n",
      "Epoch 33/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 27720.0938 - val_loss: 33114.1953\n",
      "Epoch 34/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 27431.9785 - val_loss: 33086.6016\n",
      "Epoch 35/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 27192.6641 - val_loss: 32971.1367\n",
      "Epoch 36/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 27473.8301 - val_loss: 33020.7266\n",
      "Epoch 37/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 27169.6426 - val_loss: 32987.4023\n",
      "Epoch 38/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 27158.7734 - val_loss: 32885.9141\n",
      "Epoch 39/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 27132.2559 - val_loss: 32934.9492\n",
      "Epoch 40/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 27467.1523 - val_loss: 32877.2344\n",
      "Epoch 41/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 27083.0566 - val_loss: 32872.6836\n",
      "Epoch 42/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 27061.2207 - val_loss: 32817.0195\n",
      "Epoch 43/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 27050.7227 - val_loss: 32844.4883\n",
      "Epoch 44/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26917.7969 - val_loss: 32815.7266\n",
      "Epoch 45/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26837.8086 - val_loss: 32890.8945\n",
      "Epoch 46/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26921.1094 - val_loss: 32871.0469\n",
      "Epoch 47/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26502.6406 - val_loss: 32775.9688\n",
      "Epoch 48/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 27139.3828 - val_loss: 32796.9766\n",
      "Epoch 49/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26124.9668 - val_loss: 32784.2109\n",
      "Epoch 50/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26538.1289 - val_loss: 32816.8359\n",
      "Epoch 51/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26177.0723 - val_loss: 32734.7090\n",
      "Epoch 52/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26475.4844 - val_loss: 32782.2148\n",
      "Epoch 53/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26248.9727 - val_loss: 32779.6016\n",
      "Epoch 54/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26349.3457 - val_loss: 32736.8809\n",
      "Epoch 55/1000\n",
      "114/114 [==============================] - 0s 990us/step - loss: 26539.4844 - val_loss: 32712.6602\n",
      "Epoch 56/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26272.4609 - val_loss: 32701.7227\n",
      "Epoch 57/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26360.1172 - val_loss: 32643.0391\n",
      "Epoch 58/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26447.9512 - val_loss: 32744.3262\n",
      "Epoch 59/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26294.9336 - val_loss: 32757.9512\n",
      "Epoch 60/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25999.1582 - val_loss: 32779.6680\n",
      "Epoch 61/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26230.4395 - val_loss: 32753.3008\n",
      "Epoch 62/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26484.0723 - val_loss: 32783.2148\n",
      "Epoch 63/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26363.5430 - val_loss: 32759.6602\n",
      "Epoch 64/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26301.3906 - val_loss: 32735.5859\n",
      "Epoch 65/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26188.5000 - val_loss: 32811.0273\n",
      "Epoch 66/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26060.2988 - val_loss: 32746.8320\n",
      "Epoch 67/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26136.2832 - val_loss: 32810.3984\n",
      "Epoch 68/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26163.1152 - val_loss: 32801.5547\n",
      "Epoch 69/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25915.6250 - val_loss: 32780.5664\n",
      "Epoch 70/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26213.5059 - val_loss: 32773.7656\n",
      "Epoch 71/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26223.1348 - val_loss: 32735.9258\n",
      "Epoch 72/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26194.8281 - val_loss: 32704.3398\n",
      "Epoch 73/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25864.3809 - val_loss: 32749.2871\n",
      "Epoch 74/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26268.0605 - val_loss: 32729.0664\n",
      "Epoch 75/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25673.8809 - val_loss: 32774.8242\n",
      "Epoch 76/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26169.8672 - val_loss: 32736.7969\n",
      "Epoch 77/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26042.4902 - val_loss: 32734.3652\n",
      "Epoch 78/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26009.6660 - val_loss: 32652.0566\n",
      "Epoch 79/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25526.0684 - val_loss: 32678.1465\n",
      "Epoch 80/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25943.9863 - val_loss: 32750.5430\n",
      "Epoch 81/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26110.1348 - val_loss: 32678.0488\n",
      "Epoch 82/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25841.3242 - val_loss: 32761.5195\n",
      "Epoch 83/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25828.8223 - val_loss: 32731.1270\n",
      "Epoch 84/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25540.0625 - val_loss: 32639.9434\n",
      "Epoch 85/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25972.4258 - val_loss: 32697.1367\n",
      "Epoch 86/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 26072.5938 - val_loss: 32719.2637\n",
      "Epoch 87/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25395.1719 - val_loss: 32804.7539\n",
      "Epoch 88/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25461.8633 - val_loss: 32658.6387\n",
      "Epoch 89/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25800.7520 - val_loss: 32666.9082\n",
      "Epoch 90/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25329.3574 - val_loss: 32731.9609\n",
      "Epoch 91/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25829.7383 - val_loss: 32649.6250\n",
      "Epoch 92/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25592.9688 - val_loss: 32735.5078\n",
      "Epoch 93/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25645.5410 - val_loss: 32817.9883\n",
      "Epoch 94/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25250.5566 - val_loss: 32805.5898\n",
      "Epoch 95/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25640.4590 - val_loss: 32768.8672\n",
      "Epoch 96/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25464.8301 - val_loss: 32728.5430\n",
      "Epoch 97/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25613.8203 - val_loss: 32735.3340\n",
      "Epoch 98/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25500.8398 - val_loss: 32749.5371\n",
      "Epoch 99/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25274.4258 - val_loss: 32673.1465\n",
      "Epoch 100/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25368.0625 - val_loss: 32654.5781\n",
      "Epoch 101/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25594.1445 - val_loss: 32630.5254\n",
      "Epoch 102/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25417.9199 - val_loss: 32637.9258\n",
      "Epoch 103/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25541.2500 - val_loss: 32667.7539\n",
      "Epoch 104/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25711.0781 - val_loss: 32628.5605\n",
      "Epoch 105/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25374.6523 - val_loss: 32722.2207\n",
      "Epoch 106/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25234.3574 - val_loss: 32642.1230\n",
      "Epoch 107/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25383.1406 - val_loss: 32689.4844\n",
      "Epoch 108/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25496.4141 - val_loss: 32701.8418\n",
      "Epoch 109/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25353.4785 - val_loss: 32752.1621\n",
      "Epoch 110/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25051.6367 - val_loss: 32697.0879\n",
      "Epoch 111/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25383.1680 - val_loss: 32686.9160\n",
      "Epoch 112/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25197.1758 - val_loss: 32606.6250\n",
      "Epoch 113/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25561.3086 - val_loss: 32675.9688\n",
      "Epoch 114/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25027.3164 - val_loss: 32626.6602\n",
      "Epoch 115/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25292.5508 - val_loss: 32650.1113\n",
      "Epoch 116/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25260.6484 - val_loss: 32710.9609\n",
      "Epoch 117/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25188.7246 - val_loss: 32719.8555\n",
      "Epoch 118/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25311.5312 - val_loss: 32685.0254\n",
      "Epoch 119/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25250.0195 - val_loss: 32667.4531\n",
      "Epoch 120/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25243.4316 - val_loss: 32698.8418\n",
      "Epoch 121/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24944.9121 - val_loss: 32673.5254\n",
      "Epoch 122/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25135.4434 - val_loss: 32658.6035\n",
      "Epoch 123/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24809.4473 - val_loss: 32654.4219\n",
      "Epoch 124/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24957.9316 - val_loss: 32679.6426\n",
      "Epoch 125/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25076.8516 - val_loss: 32593.6816\n",
      "Epoch 126/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24838.5977 - val_loss: 32629.7930\n",
      "Epoch 127/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24946.1133 - val_loss: 32533.2070\n",
      "Epoch 128/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24819.2188 - val_loss: 32583.2148\n",
      "Epoch 129/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24758.1934 - val_loss: 32542.2559\n",
      "Epoch 130/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24677.8516 - val_loss: 32491.8008\n",
      "Epoch 131/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24974.4102 - val_loss: 32496.6602\n",
      "Epoch 132/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 25136.0410 - val_loss: 32706.4746\n",
      "Epoch 133/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24794.3496 - val_loss: 32608.7500\n",
      "Epoch 134/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24955.9766 - val_loss: 32582.7891\n",
      "Epoch 135/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24825.2051 - val_loss: 32557.6113\n",
      "Epoch 136/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24722.2070 - val_loss: 32541.3184\n",
      "Epoch 137/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24806.0000 - val_loss: 32482.1973\n",
      "Epoch 138/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24752.4336 - val_loss: 32533.2598\n",
      "Epoch 139/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24883.8652 - val_loss: 32558.7891\n",
      "Epoch 140/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24669.8340 - val_loss: 32515.9961\n",
      "Epoch 141/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24647.5000 - val_loss: 32518.3652\n",
      "Epoch 142/1000\n",
      "114/114 [==============================] - 0s 991us/step - loss: 24505.3105 - val_loss: 32471.8730\n",
      "Epoch 143/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24614.7383 - val_loss: 32608.6523\n",
      "Epoch 144/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24459.6855 - val_loss: 32649.3516\n",
      "Epoch 145/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24139.0645 - val_loss: 32518.7305\n",
      "Epoch 146/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24518.9824 - val_loss: 32507.6426\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 24082.0801 - val_loss: 32569.8359\n",
      "Epoch 148/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24620.1035 - val_loss: 32582.6738\n",
      "Epoch 149/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24561.2383 - val_loss: 32494.1621\n",
      "Epoch 150/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24067.0977 - val_loss: 32465.2773\n",
      "Epoch 151/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24616.0312 - val_loss: 32523.1055\n",
      "Epoch 152/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24356.3203 - val_loss: 32488.6875\n",
      "Epoch 153/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24652.4609 - val_loss: 32530.0840\n",
      "Epoch 154/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24408.8164 - val_loss: 32477.9375\n",
      "Epoch 155/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24347.4746 - val_loss: 32451.3164\n",
      "Epoch 156/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24201.7793 - val_loss: 32423.3086\n",
      "Epoch 157/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24311.7969 - val_loss: 32464.3887\n",
      "Epoch 158/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23861.5117 - val_loss: 32374.6914\n",
      "Epoch 159/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24378.3027 - val_loss: 32361.8848\n",
      "Epoch 160/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24360.5137 - val_loss: 32457.8672\n",
      "Epoch 161/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24285.3535 - val_loss: 32346.8105\n",
      "Epoch 162/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24265.8770 - val_loss: 32349.3164\n",
      "Epoch 163/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24102.2461 - val_loss: 32563.4531\n",
      "Epoch 164/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24235.3535 - val_loss: 32474.5195\n",
      "Epoch 165/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24107.7266 - val_loss: 32528.5254\n",
      "Epoch 166/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23934.7812 - val_loss: 32397.7676\n",
      "Epoch 167/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24043.3887 - val_loss: 32397.4219\n",
      "Epoch 168/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24127.5664 - val_loss: 32348.9473\n",
      "Epoch 169/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24027.8789 - val_loss: 32404.4395\n",
      "Epoch 170/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23852.2402 - val_loss: 32448.5957\n",
      "Epoch 171/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24086.8887 - val_loss: 32401.6484\n",
      "Epoch 172/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24009.3301 - val_loss: 32424.3867\n",
      "Epoch 173/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24071.4844 - val_loss: 32390.8535\n",
      "Epoch 174/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24108.9336 - val_loss: 32387.8457\n",
      "Epoch 175/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23920.0625 - val_loss: 32301.2324\n",
      "Epoch 176/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24074.3828 - val_loss: 32432.9570\n",
      "Epoch 177/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23677.1777 - val_loss: 32340.9512\n",
      "Epoch 178/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23711.6445 - val_loss: 32358.4629\n",
      "Epoch 179/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23731.6680 - val_loss: 32397.1406\n",
      "Epoch 180/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 24015.0234 - val_loss: 32404.2812\n",
      "Epoch 181/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23532.6387 - val_loss: 32376.4805\n",
      "Epoch 182/1000\n",
      "114/114 [==============================] - 0s 978us/step - loss: 23729.5156 - val_loss: 32319.1016\n",
      "Epoch 183/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23657.7188 - val_loss: 32307.4844\n",
      "Epoch 184/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23363.4336 - val_loss: 32327.9961\n",
      "Epoch 185/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23659.3184 - val_loss: 32288.2852\n",
      "Epoch 186/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23554.5723 - val_loss: 32276.1094\n",
      "Epoch 187/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23359.7969 - val_loss: 32335.9727\n",
      "Epoch 188/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23522.1895 - val_loss: 32317.9160\n",
      "Epoch 189/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23755.6855 - val_loss: 32303.7441\n",
      "Epoch 190/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23620.9219 - val_loss: 32371.5820\n",
      "Epoch 191/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23708.0098 - val_loss: 32328.2461\n",
      "Epoch 192/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23228.9258 - val_loss: 32332.2910\n",
      "Epoch 193/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23767.7402 - val_loss: 32354.2949\n",
      "Epoch 194/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23616.7090 - val_loss: 32277.5996\n",
      "Epoch 195/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23632.8203 - val_loss: 32311.8535\n",
      "Epoch 196/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23404.9902 - val_loss: 32290.3965\n",
      "Epoch 197/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23564.7969 - val_loss: 32473.0918\n",
      "Epoch 198/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23149.4570 - val_loss: 32558.4355\n",
      "Epoch 199/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23478.5762 - val_loss: 32474.2422\n",
      "Epoch 200/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23519.4062 - val_loss: 32309.8633\n",
      "Epoch 201/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23357.2500 - val_loss: 32277.0488\n",
      "Epoch 202/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23427.5742 - val_loss: 32318.8633\n",
      "Epoch 203/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23687.6172 - val_loss: 32457.1016\n",
      "Epoch 204/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23303.1113 - val_loss: 32492.9160\n",
      "Epoch 205/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23316.1641 - val_loss: 32612.8906\n",
      "Epoch 206/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23186.6641 - val_loss: 32473.8984\n",
      "Epoch 207/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23365.1992 - val_loss: 32509.1758\n",
      "Epoch 208/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23041.1289 - val_loss: 32423.1016\n",
      "Epoch 209/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23206.2031 - val_loss: 32456.0957\n",
      "Epoch 210/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23132.1484 - val_loss: 32332.9258\n",
      "Epoch 211/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22996.5039 - val_loss: 32450.4219\n",
      "Epoch 212/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23134.8086 - val_loss: 32367.8809\n",
      "Epoch 213/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23228.6367 - val_loss: 32319.7227\n",
      "Epoch 214/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23256.1719 - val_loss: 32465.2559\n",
      "Epoch 215/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22970.9512 - val_loss: 32500.1094\n",
      "Epoch 216/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22998.0586 - val_loss: 32403.5762\n",
      "Epoch 217/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23171.0762 - val_loss: 32356.2109\n",
      "Epoch 218/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23092.2793 - val_loss: 32421.6602\n",
      "Epoch 219/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23079.4141 - val_loss: 32455.4746\n",
      "Epoch 220/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23207.2598 - val_loss: 32469.7715\n",
      "Epoch 221/1000\n",
      "114/114 [==============================] - 0s 952us/step - loss: 22945.4004 - val_loss: 32474.1934\n",
      "Epoch 222/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22823.7441 - val_loss: 32353.2949\n",
      "Epoch 223/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23060.3984 - val_loss: 32323.2031\n",
      "Epoch 224/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22873.7441 - val_loss: 32463.4805\n",
      "Epoch 225/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22746.5312 - val_loss: 32359.4180\n",
      "Epoch 226/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22822.5098 - val_loss: 32292.1230\n",
      "Epoch 227/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22990.3418 - val_loss: 32366.4180\n",
      "Epoch 228/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 23030.2852 - val_loss: 32403.9199\n",
      "Epoch 229/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22816.5938 - val_loss: 32376.1797\n",
      "Epoch 230/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22902.7910 - val_loss: 32329.1270\n",
      "Epoch 231/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22698.9980 - val_loss: 32410.5508\n",
      "Epoch 232/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22629.8984 - val_loss: 32356.4805\n",
      "Epoch 233/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22889.3711 - val_loss: 32258.6309\n",
      "Epoch 234/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22829.4648 - val_loss: 32366.9395\n",
      "Epoch 235/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22729.2871 - val_loss: 32402.5469\n",
      "Epoch 236/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22745.3477 - val_loss: 32439.2246\n",
      "Epoch 237/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22786.3125 - val_loss: 32431.0039\n",
      "Epoch 238/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22351.2598 - val_loss: 32373.5293\n",
      "Epoch 239/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22862.0273 - val_loss: 32376.9902\n",
      "Epoch 240/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22827.4258 - val_loss: 32429.7012\n",
      "Epoch 241/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22448.6172 - val_loss: 32263.0605\n",
      "Epoch 242/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22486.8730 - val_loss: 32490.0527\n",
      "Epoch 243/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22670.7969 - val_loss: 32342.1543\n",
      "Epoch 244/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22252.4004 - val_loss: 32428.7305\n",
      "Epoch 245/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22208.9258 - val_loss: 32621.5117\n",
      "Epoch 246/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22591.2129 - val_loss: 32499.0840\n",
      "Epoch 247/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22542.8809 - val_loss: 32530.9375\n",
      "Epoch 248/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22445.9141 - val_loss: 32440.8711\n",
      "Epoch 249/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22314.6367 - val_loss: 32435.0527\n",
      "Epoch 250/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22156.9180 - val_loss: 32414.9512\n",
      "Epoch 251/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22344.6113 - val_loss: 32302.1094\n",
      "Epoch 252/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22372.8105 - val_loss: 32439.9922\n",
      "Epoch 253/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22342.5098 - val_loss: 32468.5020\n",
      "Epoch 254/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22356.7598 - val_loss: 32560.4883\n",
      "Epoch 255/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22228.6074 - val_loss: 32419.7500\n",
      "Epoch 256/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22267.5352 - val_loss: 32340.5195\n",
      "Epoch 257/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22103.5840 - val_loss: 32466.7793\n",
      "Epoch 258/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22191.0527 - val_loss: 32528.5859\n",
      "Epoch 259/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22310.7988 - val_loss: 32514.8887\n",
      "Epoch 260/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21776.7598 - val_loss: 32448.6562\n",
      "Epoch 261/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22132.2383 - val_loss: 32532.1543\n",
      "Epoch 262/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21961.5098 - val_loss: 32443.9902\n",
      "Epoch 263/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21808.6875 - val_loss: 32433.5957\n",
      "Epoch 264/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21884.6152 - val_loss: 32409.1543\n",
      "Epoch 265/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21985.8223 - val_loss: 32480.1055\n",
      "Epoch 266/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22019.3750 - val_loss: 32541.8242\n",
      "Epoch 267/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22109.5469 - val_loss: 32492.5469\n",
      "Epoch 268/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22064.7539 - val_loss: 32440.5938\n",
      "Epoch 269/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21884.6484 - val_loss: 32451.1543\n",
      "Epoch 270/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22039.7676 - val_loss: 32534.0566\n",
      "Epoch 271/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21972.0605 - val_loss: 32597.3574\n",
      "Epoch 272/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 22080.6953 - val_loss: 32623.2520\n",
      "Epoch 273/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21967.8457 - val_loss: 32621.7852\n",
      "Epoch 274/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21816.1875 - val_loss: 32546.6992\n",
      "Epoch 275/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21744.5117 - val_loss: 32500.6562\n",
      "Epoch 276/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21904.0664 - val_loss: 32554.0918\n",
      "Epoch 277/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21823.4102 - val_loss: 32500.0957\n",
      "Epoch 278/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21720.7266 - val_loss: 32477.7715\n",
      "Epoch 279/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21440.8125 - val_loss: 32411.4355\n",
      "Epoch 280/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21748.1699 - val_loss: 32458.2949\n",
      "Epoch 281/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21580.2227 - val_loss: 32415.4629\n",
      "Epoch 282/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21721.3184 - val_loss: 32416.4570\n",
      "Epoch 283/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21535.6211 - val_loss: 32377.5723\n",
      "Epoch 284/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21560.6738 - val_loss: 32496.7930\n",
      "Epoch 285/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21605.8164 - val_loss: 32454.1973\n",
      "Epoch 286/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21468.5781 - val_loss: 32448.9648\n",
      "Epoch 287/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21587.9199 - val_loss: 32510.3262\n",
      "Epoch 288/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20911.3301 - val_loss: 32347.0781\n",
      "Epoch 289/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21682.2129 - val_loss: 32451.1641\n",
      "Epoch 290/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21583.0742 - val_loss: 32429.4414\n",
      "Epoch 291/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21383.5938 - val_loss: 32481.3711\n",
      "Epoch 292/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21345.0293 - val_loss: 32479.9863\n",
      "Epoch 293/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 21508.6152 - val_loss: 32576.0918\n",
      "Epoch 294/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21402.1172 - val_loss: 32537.1758\n",
      "Epoch 295/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21545.1094 - val_loss: 32425.8457\n",
      "Epoch 296/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21636.5547 - val_loss: 32458.1328\n",
      "Epoch 297/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21384.5957 - val_loss: 32489.2559\n",
      "Epoch 298/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21340.8965 - val_loss: 32395.2109\n",
      "Epoch 299/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21164.7207 - val_loss: 32563.3711\n",
      "Epoch 300/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21326.6895 - val_loss: 32548.6836\n",
      "Epoch 301/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21408.9883 - val_loss: 32626.8145\n",
      "Epoch 302/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21622.0195 - val_loss: 32494.2422\n",
      "Epoch 303/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21222.8887 - val_loss: 32566.9512\n",
      "Epoch 304/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21510.7578 - val_loss: 32606.2324\n",
      "Epoch 305/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21187.5332 - val_loss: 32599.6426\n",
      "Epoch 306/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21294.6152 - val_loss: 32718.5957\n",
      "Epoch 307/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21372.2773 - val_loss: 32629.5938\n",
      "Epoch 308/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21415.9336 - val_loss: 32595.0254\n",
      "Epoch 309/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21474.9980 - val_loss: 32660.7227\n",
      "Epoch 310/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21099.8711 - val_loss: 32678.2422\n",
      "Epoch 311/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21275.1113 - val_loss: 32578.7324\n",
      "Epoch 312/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21207.7617 - val_loss: 32562.9199\n",
      "Epoch 313/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21040.0293 - val_loss: 32635.4062\n",
      "Epoch 314/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21062.7129 - val_loss: 32485.7715\n",
      "Epoch 315/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20834.9570 - val_loss: 32652.2148\n",
      "Epoch 316/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21081.8203 - val_loss: 32665.9961\n",
      "Epoch 317/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20993.9902 - val_loss: 32599.0000\n",
      "Epoch 318/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20820.0410 - val_loss: 32555.8105\n",
      "Epoch 319/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21206.6602 - val_loss: 32533.7363\n",
      "Epoch 320/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21076.7832 - val_loss: 32571.6074\n",
      "Epoch 321/1000\n",
      "114/114 [==============================] - 0s 959us/step - loss: 20780.8574 - val_loss: 32573.7012\n",
      "Epoch 322/1000\n",
      "114/114 [==============================] - 0s 949us/step - loss: 20748.0801 - val_loss: 32647.2500\n",
      "Epoch 323/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 21080.8281 - val_loss: 32675.6289\n",
      "Epoch 324/1000\n",
      "114/114 [==============================] - 0s 966us/step - loss: 21040.6992 - val_loss: 32550.6250\n",
      "Epoch 325/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20913.7773 - val_loss: 32695.5547\n",
      "Epoch 326/1000\n",
      "114/114 [==============================] - 0s 980us/step - loss: 20879.7227 - val_loss: 32541.7676\n",
      "Epoch 327/1000\n",
      "114/114 [==============================] - 0s 932us/step - loss: 20976.1992 - val_loss: 32543.3691\n",
      "Epoch 328/1000\n",
      "114/114 [==============================] - 0s 945us/step - loss: 21161.0059 - val_loss: 32583.6387\n",
      "Epoch 329/1000\n",
      "114/114 [==============================] - 0s 926us/step - loss: 20714.8906 - val_loss: 32606.1191\n",
      "Epoch 330/1000\n",
      "114/114 [==============================] - 0s 961us/step - loss: 20617.2715 - val_loss: 32566.8633\n",
      "Epoch 331/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20819.9453 - val_loss: 32566.7402\n",
      "Epoch 332/1000\n",
      "114/114 [==============================] - 0s 924us/step - loss: 20482.5801 - val_loss: 32576.5508\n",
      "Epoch 333/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20802.9258 - val_loss: 32643.1758\n",
      "Epoch 334/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20650.6328 - val_loss: 32667.3926\n",
      "Epoch 335/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20719.3867 - val_loss: 32647.7441\n",
      "Epoch 336/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20527.0059 - val_loss: 32644.4570\n",
      "Epoch 337/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20417.8555 - val_loss: 32644.3867\n",
      "Epoch 338/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20670.2363 - val_loss: 32667.7715\n",
      "Epoch 339/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20775.6738 - val_loss: 32750.1270\n",
      "Epoch 340/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20839.1758 - val_loss: 32778.2852\n",
      "Epoch 341/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20653.2969 - val_loss: 32761.9609\n",
      "Epoch 342/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20596.8457 - val_loss: 32726.5293\n",
      "Epoch 343/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20453.3086 - val_loss: 32627.0781\n",
      "Epoch 344/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20506.2793 - val_loss: 32767.8066\n",
      "Epoch 345/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20425.3281 - val_loss: 32614.4180\n",
      "Epoch 346/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20620.3535 - val_loss: 32658.7012\n",
      "Epoch 347/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20400.5801 - val_loss: 32696.9258\n",
      "Epoch 348/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20717.6934 - val_loss: 32703.4414\n",
      "Epoch 349/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20477.2246 - val_loss: 32598.7441\n",
      "Epoch 350/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20253.4863 - val_loss: 32682.5996\n",
      "Epoch 351/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20515.0000 - val_loss: 32650.5723\n",
      "Epoch 352/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20031.2891 - val_loss: 32647.5371\n",
      "Epoch 353/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20191.3789 - val_loss: 32687.9609\n",
      "Epoch 354/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20258.2441 - val_loss: 32712.6289\n",
      "Epoch 355/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20255.6152 - val_loss: 32830.0742\n",
      "Epoch 356/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20447.5391 - val_loss: 32748.8809\n",
      "Epoch 357/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20250.0391 - val_loss: 32803.1719\n",
      "Epoch 358/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20421.6504 - val_loss: 32758.1758\n",
      "Epoch 359/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20396.5488 - val_loss: 32720.5762\n",
      "Epoch 360/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20244.2383 - val_loss: 32887.3359\n",
      "Epoch 361/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20497.4785 - val_loss: 32694.8418\n",
      "Epoch 362/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20296.4824 - val_loss: 32763.1094\n",
      "Epoch 363/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20469.4219 - val_loss: 32861.8438\n",
      "Epoch 364/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19891.4453 - val_loss: 32786.9102\n",
      "Epoch 365/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19925.1777 - val_loss: 32833.3164\n",
      "Epoch 366/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 20050.7969 - val_loss: 32664.1328\n",
      "Epoch 367/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19958.0840 - val_loss: 32666.1934\n",
      "Epoch 368/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20096.0137 - val_loss: 32758.1328\n",
      "Epoch 369/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19900.3984 - val_loss: 32701.1504\n",
      "Epoch 370/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19980.2461 - val_loss: 32611.8770\n",
      "Epoch 371/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20157.0898 - val_loss: 32716.0605\n",
      "Epoch 372/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20113.3867 - val_loss: 32724.0664\n",
      "Epoch 373/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19955.1875 - val_loss: 32768.2656\n",
      "Epoch 374/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19852.9062 - val_loss: 32701.5430\n",
      "Epoch 375/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19834.6289 - val_loss: 32671.3535\n",
      "Epoch 376/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19928.6973 - val_loss: 32745.7852\n",
      "Epoch 377/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19880.1465 - val_loss: 32721.0918\n",
      "Epoch 378/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19832.8027 - val_loss: 32710.5059\n",
      "Epoch 379/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20115.5859 - val_loss: 32820.1602\n",
      "Epoch 380/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20054.2539 - val_loss: 32860.2969\n",
      "Epoch 381/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19753.9902 - val_loss: 32874.0156\n",
      "Epoch 382/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19635.4609 - val_loss: 32830.5234\n",
      "Epoch 383/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19582.7070 - val_loss: 32881.5898\n",
      "Epoch 384/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19832.2422 - val_loss: 32933.7930\n",
      "Epoch 385/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19627.8145 - val_loss: 32777.9883\n",
      "Epoch 386/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 20077.2715 - val_loss: 32867.9570\n",
      "Epoch 387/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19505.6660 - val_loss: 32891.5664\n",
      "Epoch 388/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19721.4570 - val_loss: 32936.8242\n",
      "Epoch 389/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19819.1035 - val_loss: 32857.1289\n",
      "Epoch 390/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19565.5488 - val_loss: 32860.9844\n",
      "Epoch 391/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19549.0469 - val_loss: 32814.3828\n",
      "Epoch 392/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19525.5293 - val_loss: 32881.8828\n",
      "Epoch 393/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19564.1016 - val_loss: 32808.7266\n",
      "Epoch 394/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19741.5938 - val_loss: 32834.3984\n",
      "Epoch 395/1000\n",
      "114/114 [==============================] - 0s 997us/step - loss: 19694.8711 - val_loss: 32954.4883\n",
      "Epoch 396/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19527.4922 - val_loss: 32801.2969\n",
      "Epoch 397/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19441.8828 - val_loss: 32855.6992\n",
      "Epoch 398/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19680.6602 - val_loss: 32925.9805\n",
      "Epoch 399/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19135.0156 - val_loss: 32900.4180\n",
      "Epoch 400/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19244.9297 - val_loss: 32930.8203\n",
      "Epoch 401/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19413.1680 - val_loss: 33037.5352\n",
      "Epoch 402/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19421.5039 - val_loss: 32951.4258\n",
      "Epoch 403/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19413.0391 - val_loss: 32893.4648\n",
      "Epoch 404/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19189.9160 - val_loss: 32979.5234\n",
      "Epoch 405/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19379.0078 - val_loss: 32984.5977\n",
      "Epoch 406/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19305.3203 - val_loss: 32998.7969\n",
      "Epoch 407/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19049.3398 - val_loss: 32915.4336\n",
      "Epoch 408/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19193.7969 - val_loss: 32982.1562\n",
      "Epoch 409/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19407.4023 - val_loss: 32916.3281\n",
      "Epoch 410/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19275.5156 - val_loss: 32929.4844\n",
      "Epoch 411/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19171.4199 - val_loss: 32998.9688\n",
      "Epoch 412/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19446.1055 - val_loss: 32918.3398\n",
      "Epoch 413/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19213.9219 - val_loss: 32928.6680\n",
      "Epoch 414/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19243.5820 - val_loss: 33014.5352\n",
      "Epoch 415/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19382.5645 - val_loss: 32926.3867\n",
      "Epoch 416/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19115.2832 - val_loss: 32947.4297\n",
      "Epoch 417/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19084.4023 - val_loss: 32951.6445\n",
      "Epoch 418/1000\n",
      "114/114 [==============================] - 0s 842us/step - loss: 19009.0723 - val_loss: 33029.5234\n",
      "Epoch 419/1000\n",
      "114/114 [==============================] - 0s 918us/step - loss: 19154.8359 - val_loss: 32919.8281\n",
      "Epoch 420/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19351.1035 - val_loss: 32974.7852\n",
      "Epoch 421/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19006.7871 - val_loss: 33177.8359\n",
      "Epoch 422/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19123.4238 - val_loss: 32928.5430\n",
      "Epoch 423/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19009.6523 - val_loss: 32997.0703\n",
      "Epoch 424/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18893.7617 - val_loss: 33002.3789\n",
      "Epoch 425/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19309.7227 - val_loss: 32949.4219\n",
      "Epoch 426/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18804.8945 - val_loss: 32924.3242\n",
      "Epoch 427/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19029.4102 - val_loss: 32850.3438\n",
      "Epoch 428/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18929.1602 - val_loss: 32951.9102\n",
      "Epoch 429/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18924.4668 - val_loss: 32951.4609\n",
      "Epoch 430/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18824.0137 - val_loss: 32971.6602\n",
      "Epoch 431/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19072.4922 - val_loss: 32999.2344\n",
      "Epoch 432/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18878.4512 - val_loss: 33030.8750\n",
      "Epoch 433/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18935.5137 - val_loss: 32913.5312\n",
      "Epoch 434/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19051.3691 - val_loss: 32932.2930\n",
      "Epoch 435/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19108.4492 - val_loss: 33052.0820\n",
      "Epoch 436/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18733.9043 - val_loss: 32985.5000\n",
      "Epoch 437/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18946.4082 - val_loss: 33147.3281\n",
      "Epoch 438/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18975.8320 - val_loss: 32889.7656\n",
      "Epoch 439/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18867.6738 - val_loss: 32977.7773\n",
      "Epoch 440/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18753.4805 - val_loss: 33013.2461\n",
      "Epoch 441/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 19057.3711 - val_loss: 32968.8789\n",
      "Epoch 442/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18851.7148 - val_loss: 32913.5703\n",
      "Epoch 443/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18807.9727 - val_loss: 32915.7422\n",
      "Epoch 444/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18806.1758 - val_loss: 32967.2305\n",
      "Epoch 445/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18719.2930 - val_loss: 33149.7500\n",
      "Epoch 446/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18843.0195 - val_loss: 32975.0703\n",
      "Epoch 447/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18280.0664 - val_loss: 33052.7070\n",
      "Epoch 448/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18519.1738 - val_loss: 33036.1992\n",
      "Epoch 449/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18566.0215 - val_loss: 33100.7070\n",
      "Epoch 450/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18491.0000 - val_loss: 32939.5781\n",
      "Epoch 451/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18520.0410 - val_loss: 32962.4883\n",
      "Epoch 452/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18536.9355 - val_loss: 33042.0938\n",
      "Epoch 453/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18678.3301 - val_loss: 32944.5312\n",
      "Epoch 454/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18594.1953 - val_loss: 32947.4336\n",
      "Epoch 455/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18544.9512 - val_loss: 33140.7070\n",
      "Epoch 456/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18496.4023 - val_loss: 33027.2266\n",
      "Epoch 457/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18635.1289 - val_loss: 32981.2695\n",
      "Epoch 458/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 18408.0488 - val_loss: 33109.1680\n",
      "Epoch 459/1000\n",
      "114/114 [==============================] - 0s 994us/step - loss: 18356.9609 - val_loss: 32977.9922\n",
      "Epoch 460/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18453.5488 - val_loss: 33007.7070\n",
      "Epoch 461/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18454.6348 - val_loss: 33202.0703\n",
      "Epoch 462/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18673.9414 - val_loss: 33089.7969\n",
      "Epoch 463/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18604.0449 - val_loss: 33060.1719\n",
      "Epoch 464/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18186.5215 - val_loss: 33067.8438\n",
      "Epoch 465/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18389.1152 - val_loss: 33041.0586\n",
      "Epoch 466/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18159.6230 - val_loss: 33339.8711\n",
      "Epoch 467/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18325.3750 - val_loss: 33116.0977\n",
      "Epoch 468/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17950.3867 - val_loss: 33112.3828\n",
      "Epoch 469/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18487.1406 - val_loss: 33055.2734\n",
      "Epoch 470/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18423.2363 - val_loss: 33087.0078\n",
      "Epoch 471/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18487.5137 - val_loss: 33085.9688\n",
      "Epoch 472/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18442.1270 - val_loss: 33169.5156\n",
      "Epoch 473/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18136.6367 - val_loss: 33116.8633\n",
      "Epoch 474/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18421.8789 - val_loss: 33065.1562\n",
      "Epoch 475/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18309.6719 - val_loss: 33152.6602\n",
      "Epoch 476/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18205.4004 - val_loss: 33123.2578\n",
      "Epoch 477/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18362.8945 - val_loss: 33013.0430\n",
      "Epoch 478/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18270.1152 - val_loss: 33087.9492\n",
      "Epoch 479/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18290.3828 - val_loss: 33283.8086\n",
      "Epoch 480/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18491.9316 - val_loss: 33052.3672\n",
      "Epoch 481/1000\n",
      "114/114 [==============================] - 0s 958us/step - loss: 18175.5039 - val_loss: 33076.4531\n",
      "Epoch 482/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18181.6152 - val_loss: 33270.3359\n",
      "Epoch 483/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17981.7031 - val_loss: 33052.6562\n",
      "Epoch 484/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18194.3359 - val_loss: 33215.6328\n",
      "Epoch 485/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18191.3008 - val_loss: 33253.9492\n",
      "Epoch 486/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18372.9980 - val_loss: 33291.6094\n",
      "Epoch 487/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18084.2910 - val_loss: 33067.2617\n",
      "Epoch 488/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18094.3770 - val_loss: 33129.0352\n",
      "Epoch 489/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17696.1855 - val_loss: 33203.2578\n",
      "Epoch 490/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17964.8457 - val_loss: 33199.7422\n",
      "Epoch 491/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18007.4492 - val_loss: 33172.5000\n",
      "Epoch 492/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18097.1523 - val_loss: 33164.2578\n",
      "Epoch 493/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17844.5332 - val_loss: 33151.0234\n",
      "Epoch 494/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18190.1914 - val_loss: 33203.8711\n",
      "Epoch 495/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17948.2871 - val_loss: 33092.0586\n",
      "Epoch 496/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17719.4102 - val_loss: 33125.8008\n",
      "Epoch 497/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18172.3633 - val_loss: 33174.0156\n",
      "Epoch 498/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18017.5156 - val_loss: 33204.6055\n",
      "Epoch 499/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17726.0098 - val_loss: 33041.5664\n",
      "Epoch 500/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17905.0957 - val_loss: 33100.3828\n",
      "Epoch 501/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17794.5195 - val_loss: 33246.8125\n",
      "Epoch 502/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18188.6250 - val_loss: 33159.5703\n",
      "Epoch 503/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17908.6074 - val_loss: 33231.5352\n",
      "Epoch 504/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17984.1582 - val_loss: 33196.5625\n",
      "Epoch 505/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18100.0098 - val_loss: 33253.1328\n",
      "Epoch 506/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17898.2109 - val_loss: 33221.9609\n",
      "Epoch 507/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17803.2715 - val_loss: 33163.1484\n",
      "Epoch 508/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17552.3184 - val_loss: 33280.6250\n",
      "Epoch 509/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17918.0879 - val_loss: 33311.5977\n",
      "Epoch 510/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17913.6738 - val_loss: 33239.1914\n",
      "Epoch 511/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17613.5859 - val_loss: 33119.6250\n",
      "Epoch 512/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 17641.1406 - val_loss: 33080.8359\n",
      "Epoch 513/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17982.3613 - val_loss: 33197.5195\n",
      "Epoch 514/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17734.9375 - val_loss: 33169.0547\n",
      "Epoch 515/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17785.8223 - val_loss: 33165.0977\n",
      "Epoch 516/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17456.8145 - val_loss: 33318.7266\n",
      "Epoch 517/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17787.4453 - val_loss: 33362.0586\n",
      "Epoch 518/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17659.1406 - val_loss: 33217.4492\n",
      "Epoch 519/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17654.8047 - val_loss: 33236.4023\n",
      "Epoch 520/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17663.2168 - val_loss: 33341.2930\n",
      "Epoch 521/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17496.7227 - val_loss: 33310.3281\n",
      "Epoch 522/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17504.2305 - val_loss: 33259.0430\n",
      "Epoch 523/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17667.6191 - val_loss: 33221.5508\n",
      "Epoch 524/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17657.5254 - val_loss: 33248.9883\n",
      "Epoch 525/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17566.4473 - val_loss: 33182.3242\n",
      "Epoch 526/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17675.5000 - val_loss: 33300.7422\n",
      "Epoch 527/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17607.0352 - val_loss: 33274.0391\n",
      "Epoch 528/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17532.2754 - val_loss: 33270.4141\n",
      "Epoch 529/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17347.1523 - val_loss: 33399.1445\n",
      "Epoch 530/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17550.6250 - val_loss: 33179.4961\n",
      "Epoch 531/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17347.6973 - val_loss: 33344.1016\n",
      "Epoch 532/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17378.4824 - val_loss: 33331.3906\n",
      "Epoch 533/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17527.4414 - val_loss: 33268.5586\n",
      "Epoch 534/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17463.4219 - val_loss: 33253.0781\n",
      "Epoch 535/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17592.6719 - val_loss: 33329.4609\n",
      "Epoch 536/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17242.3086 - val_loss: 33372.5000\n",
      "Epoch 537/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17416.7051 - val_loss: 33260.1328\n",
      "Epoch 538/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17182.7578 - val_loss: 33350.7461\n",
      "Epoch 539/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17396.5215 - val_loss: 33222.6992\n",
      "Epoch 540/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16942.3574 - val_loss: 33370.7109\n",
      "Epoch 541/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17259.6250 - val_loss: 33430.6289\n",
      "Epoch 542/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17537.6777 - val_loss: 33346.4492\n",
      "Epoch 543/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17216.4863 - val_loss: 33282.2070\n",
      "Epoch 544/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17231.1680 - val_loss: 33232.7930\n",
      "Epoch 545/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17392.1328 - val_loss: 33252.0234\n",
      "Epoch 546/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17306.9102 - val_loss: 33380.1289\n",
      "Epoch 547/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17163.3320 - val_loss: 33254.6289\n",
      "Epoch 548/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17209.8477 - val_loss: 33208.8750\n",
      "Epoch 549/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17234.2734 - val_loss: 33203.5117\n",
      "Epoch 550/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17269.2012 - val_loss: 33270.6562\n",
      "Epoch 551/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 17335.5430 - val_loss: 33510.5703\n",
      "Epoch 552/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17462.9043 - val_loss: 33246.7656\n",
      "Epoch 553/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17368.7871 - val_loss: 33236.0312\n",
      "Epoch 554/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17349.6543 - val_loss: 33314.6602\n",
      "Epoch 555/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17288.1738 - val_loss: 33350.4297\n",
      "Epoch 556/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17101.3320 - val_loss: 33452.2930\n",
      "Epoch 557/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17048.0605 - val_loss: 33306.6289\n",
      "Epoch 558/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17083.0469 - val_loss: 33435.6484\n",
      "Epoch 559/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17211.4355 - val_loss: 33361.0859\n",
      "Epoch 560/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17198.2090 - val_loss: 33228.0312\n",
      "Epoch 561/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17001.5098 - val_loss: 33340.4648\n",
      "Epoch 562/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17121.8809 - val_loss: 33300.6367\n",
      "Epoch 563/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17174.3008 - val_loss: 33368.2266\n",
      "Epoch 564/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17073.2363 - val_loss: 33414.0156\n",
      "Epoch 565/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17009.5195 - val_loss: 33267.7734\n",
      "Epoch 566/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16962.1562 - val_loss: 33244.5039\n",
      "Epoch 567/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16987.3223 - val_loss: 33325.4297\n",
      "Epoch 568/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16883.2070 - val_loss: 33217.7227\n",
      "Epoch 569/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16884.0312 - val_loss: 33355.8516\n",
      "Epoch 570/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16706.7363 - val_loss: 33324.7461\n",
      "Epoch 571/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16774.5312 - val_loss: 33582.5000\n",
      "Epoch 572/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16735.6406 - val_loss: 33437.7227\n",
      "Epoch 573/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 17077.3184 - val_loss: 33223.4336\n",
      "Epoch 574/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16918.4629 - val_loss: 33359.8516\n",
      "Epoch 575/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16733.7578 - val_loss: 33317.0117\n",
      "Epoch 576/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16976.2090 - val_loss: 33458.1094\n",
      "Epoch 577/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16894.5098 - val_loss: 33448.1602\n",
      "Epoch 578/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16591.4590 - val_loss: 33473.5703\n",
      "Epoch 579/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16802.5000 - val_loss: 33342.0703\n",
      "Epoch 580/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16872.7715 - val_loss: 33410.8477\n",
      "Epoch 581/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16381.4990 - val_loss: 33263.9297\n",
      "Epoch 582/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16678.2734 - val_loss: 33300.4297\n",
      "Epoch 583/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16709.6367 - val_loss: 33261.0859\n",
      "Epoch 584/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16759.4922 - val_loss: 33436.6211\n",
      "Epoch 585/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16672.7676 - val_loss: 33436.3945\n",
      "Epoch 586/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16909.6387 - val_loss: 33371.2578\n",
      "Epoch 587/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16730.9512 - val_loss: 33457.0820\n",
      "Epoch 588/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16698.8867 - val_loss: 33437.6641\n",
      "Epoch 589/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17067.6094 - val_loss: 33594.8242\n",
      "Epoch 590/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16886.9785 - val_loss: 33365.6680\n",
      "Epoch 591/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16625.7305 - val_loss: 33317.8867\n",
      "Epoch 592/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16715.6523 - val_loss: 33395.6914\n",
      "Epoch 593/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16809.4941 - val_loss: 33404.5898\n",
      "Epoch 594/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16592.1309 - val_loss: 33342.2891\n",
      "Epoch 595/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16313.1787 - val_loss: 33400.4375\n",
      "Epoch 596/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16595.2871 - val_loss: 33416.6641\n",
      "Epoch 597/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16712.2910 - val_loss: 33314.2148\n",
      "Epoch 598/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16795.4062 - val_loss: 33394.9297\n",
      "Epoch 599/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16769.8828 - val_loss: 33547.1523\n",
      "Epoch 600/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16489.6973 - val_loss: 33427.2930\n",
      "Epoch 601/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16554.5098 - val_loss: 33452.2422\n",
      "Epoch 602/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16689.1426 - val_loss: 33454.7148\n",
      "Epoch 603/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16840.9102 - val_loss: 33548.6445\n",
      "Epoch 604/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16444.9844 - val_loss: 33616.1875\n",
      "Epoch 605/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16474.4336 - val_loss: 33603.5898\n",
      "Epoch 606/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16495.4512 - val_loss: 33423.8555\n",
      "Epoch 607/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16063.4951 - val_loss: 33491.8203\n",
      "Epoch 608/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16535.7754 - val_loss: 33576.7500\n",
      "Epoch 609/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16650.7773 - val_loss: 33540.9688\n",
      "Epoch 610/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16404.5410 - val_loss: 33491.1445\n",
      "Epoch 611/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16625.9121 - val_loss: 33450.2227\n",
      "Epoch 612/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16540.3242 - val_loss: 33530.7617\n",
      "Epoch 613/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16620.1543 - val_loss: 33478.2734\n",
      "Epoch 614/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16572.1738 - val_loss: 33438.8359\n",
      "Epoch 615/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16397.7070 - val_loss: 33408.5039\n",
      "Epoch 616/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16330.7617 - val_loss: 33554.4766\n",
      "Epoch 617/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16224.5859 - val_loss: 33361.5703\n",
      "Epoch 618/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16486.7520 - val_loss: 33502.3789\n",
      "Epoch 619/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16401.4785 - val_loss: 33482.9531\n",
      "Epoch 620/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16525.4609 - val_loss: 33509.1016\n",
      "Epoch 621/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16296.8740 - val_loss: 33479.8281\n",
      "Epoch 622/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16395.8809 - val_loss: 33485.3320\n",
      "Epoch 623/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16528.4297 - val_loss: 33560.1016\n",
      "Epoch 624/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16626.4492 - val_loss: 33469.7969\n",
      "Epoch 625/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16283.8594 - val_loss: 33409.4844\n",
      "Epoch 626/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16244.0547 - val_loss: 33536.5977\n",
      "Epoch 627/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16166.7861 - val_loss: 33298.7188\n",
      "Epoch 628/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16156.1279 - val_loss: 33342.8633\n",
      "Epoch 629/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16318.1846 - val_loss: 33468.4922\n",
      "Epoch 630/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16090.6240 - val_loss: 33481.3555\n",
      "Epoch 631/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16463.7441 - val_loss: 33555.4961\n",
      "Epoch 632/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15964.0771 - val_loss: 33527.5742\n",
      "Epoch 633/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16093.0273 - val_loss: 33604.2734\n",
      "Epoch 634/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16232.7178 - val_loss: 33508.6719\n",
      "Epoch 635/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16427.6719 - val_loss: 33757.4180\n",
      "Epoch 636/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15977.7275 - val_loss: 33547.0586\n",
      "Epoch 637/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16379.4443 - val_loss: 33551.1172\n",
      "Epoch 638/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16108.1641 - val_loss: 33488.6914\n",
      "Epoch 639/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16059.2773 - val_loss: 33581.7422\n",
      "Epoch 640/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16213.7129 - val_loss: 33590.5391\n",
      "Epoch 641/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16209.6514 - val_loss: 33565.0781\n",
      "Epoch 642/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16116.6211 - val_loss: 33609.6914\n",
      "Epoch 643/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15828.5752 - val_loss: 33516.5586\n",
      "Epoch 644/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16003.9775 - val_loss: 33486.6211\n",
      "Epoch 645/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15777.6113 - val_loss: 33521.6836\n",
      "Epoch 646/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16079.2520 - val_loss: 33467.2656\n",
      "Epoch 647/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16152.2109 - val_loss: 33549.7070\n",
      "Epoch 648/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15685.3857 - val_loss: 33425.6953\n",
      "Epoch 649/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15964.4912 - val_loss: 33590.3633\n",
      "Epoch 650/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16219.4844 - val_loss: 33716.2930\n",
      "Epoch 651/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15864.3184 - val_loss: 33534.4180\n",
      "Epoch 652/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16153.5957 - val_loss: 33643.8750\n",
      "Epoch 653/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16027.7803 - val_loss: 33641.8750\n",
      "Epoch 654/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16135.5889 - val_loss: 33486.5703\n",
      "Epoch 655/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15997.0840 - val_loss: 33508.1016\n",
      "Epoch 656/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 16032.3252 - val_loss: 33532.9062\n",
      "Epoch 657/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15886.4395 - val_loss: 33582.5352\n",
      "Epoch 658/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 15951.0889 - val_loss: 33585.2695\n",
      "Epoch 659/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15926.4629 - val_loss: 33545.1875\n",
      "Epoch 660/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15799.5830 - val_loss: 33662.0312\n",
      "Epoch 661/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15808.3223 - val_loss: 33616.7656\n",
      "Epoch 662/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15923.5518 - val_loss: 33501.0742\n",
      "Epoch 663/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15867.6133 - val_loss: 33474.5234\n",
      "Epoch 664/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15695.3652 - val_loss: 33523.4219\n",
      "Epoch 665/1000\n",
      "114/114 [==============================] - ETA: 0s - loss: 16028.294 - 0s 2ms/step - loss: 15999.0137 - val_loss: 33571.3477\n",
      "Epoch 666/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15844.6934 - val_loss: 33548.2695\n",
      "Epoch 667/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15829.6182 - val_loss: 33556.8828\n",
      "Epoch 668/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15749.4297 - val_loss: 33528.8359\n",
      "Epoch 669/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16027.1484 - val_loss: 33397.1289\n",
      "Epoch 670/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15844.0635 - val_loss: 33663.9062\n",
      "Epoch 671/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15503.2100 - val_loss: 33535.7539\n",
      "Epoch 672/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15231.6729 - val_loss: 33513.2578\n",
      "Epoch 673/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15795.8135 - val_loss: 33448.8398\n",
      "Epoch 674/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15740.8711 - val_loss: 33619.6562\n",
      "Epoch 675/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15766.0967 - val_loss: 33445.2422\n",
      "Epoch 676/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15957.2363 - val_loss: 33474.8633\n",
      "Epoch 677/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15664.8584 - val_loss: 33553.7070\n",
      "Epoch 678/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15549.2432 - val_loss: 33516.5430\n",
      "Epoch 679/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15674.6299 - val_loss: 33487.1953\n",
      "Epoch 680/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15833.5781 - val_loss: 33557.6367\n",
      "Epoch 681/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15800.9482 - val_loss: 33539.5781\n",
      "Epoch 682/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15562.8232 - val_loss: 33454.6953\n",
      "Epoch 683/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15635.7344 - val_loss: 33592.2305\n",
      "Epoch 684/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15610.3623 - val_loss: 33501.4180\n",
      "Epoch 685/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15396.0918 - val_loss: 33589.2539\n",
      "Epoch 686/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15693.2344 - val_loss: 33520.4688\n",
      "Epoch 687/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15436.2129 - val_loss: 33537.3594\n",
      "Epoch 688/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15524.1104 - val_loss: 33655.8789\n",
      "Epoch 689/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15402.5840 - val_loss: 33609.7852\n",
      "Epoch 690/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15236.7227 - val_loss: 33548.5703\n",
      "Epoch 691/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15249.0059 - val_loss: 33566.9453\n",
      "Epoch 692/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15726.6016 - val_loss: 33596.3750\n",
      "Epoch 693/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15415.6309 - val_loss: 33685.9570\n",
      "Epoch 694/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15453.5039 - val_loss: 33454.7305\n",
      "Epoch 695/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15472.4922 - val_loss: 33480.2812\n",
      "Epoch 696/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15065.9229 - val_loss: 33560.0977\n",
      "Epoch 697/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15583.6943 - val_loss: 33645.9609\n",
      "Epoch 698/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15315.5059 - val_loss: 33522.5312\n",
      "Epoch 699/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15467.7207 - val_loss: 33705.2070\n",
      "Epoch 700/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15643.6465 - val_loss: 33508.3672\n",
      "Epoch 701/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15501.8906 - val_loss: 33483.8320\n",
      "Epoch 702/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15471.2861 - val_loss: 33451.9648\n",
      "Epoch 703/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15462.6631 - val_loss: 33681.1875\n",
      "Epoch 704/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15214.8721 - val_loss: 33584.2305\n",
      "Epoch 705/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15613.4072 - val_loss: 33579.3906\n",
      "Epoch 706/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15310.2705 - val_loss: 33646.8008\n",
      "Epoch 707/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15522.5205 - val_loss: 33747.1445\n",
      "Epoch 708/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15544.6152 - val_loss: 33607.5352\n",
      "Epoch 709/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15413.4072 - val_loss: 33631.6367\n",
      "Epoch 710/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15385.3857 - val_loss: 33513.8477\n",
      "Epoch 711/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15403.4404 - val_loss: 33595.4023\n",
      "Epoch 712/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15231.6025 - val_loss: 33645.8242\n",
      "Epoch 713/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14849.3916 - val_loss: 33670.5000\n",
      "Epoch 714/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15282.4922 - val_loss: 33552.7500\n",
      "Epoch 715/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15218.4189 - val_loss: 33546.9258\n",
      "Epoch 716/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15424.6152 - val_loss: 33638.7188\n",
      "Epoch 717/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15234.9590 - val_loss: 33556.5586\n",
      "Epoch 718/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15306.8652 - val_loss: 33628.1719\n",
      "Epoch 719/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15237.2695 - val_loss: 33558.5703\n",
      "Epoch 720/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15280.4023 - val_loss: 33586.4883\n",
      "Epoch 721/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15236.8428 - val_loss: 33611.7891\n",
      "Epoch 722/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15446.7705 - val_loss: 33802.9570\n",
      "Epoch 723/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15317.7744 - val_loss: 33531.1641\n",
      "Epoch 724/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15393.8467 - val_loss: 33696.1211\n",
      "Epoch 725/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15267.6377 - val_loss: 33586.3906\n",
      "Epoch 726/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15356.6055 - val_loss: 33608.0781\n",
      "Epoch 727/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15134.5449 - val_loss: 33768.7070\n",
      "Epoch 728/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15529.0625 - val_loss: 33603.1797\n",
      "Epoch 729/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15228.1650 - val_loss: 33582.6758\n",
      "Epoch 730/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15167.1396 - val_loss: 33541.8945\n",
      "Epoch 731/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 15001.9600 - val_loss: 33502.6719\n",
      "Epoch 732/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15198.4854 - val_loss: 33820.6953\n",
      "Epoch 733/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15207.5215 - val_loss: 33695.4336\n",
      "Epoch 734/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15062.0547 - val_loss: 33640.7422\n",
      "Epoch 735/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15089.1836 - val_loss: 33682.5977\n",
      "Epoch 736/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15125.0430 - val_loss: 33797.3984\n",
      "Epoch 737/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14975.0273 - val_loss: 33847.3125\n",
      "Epoch 738/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15162.8096 - val_loss: 33732.3086\n",
      "Epoch 739/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15135.5303 - val_loss: 33640.6797\n",
      "Epoch 740/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15073.8271 - val_loss: 33658.6641\n",
      "Epoch 741/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15033.3936 - val_loss: 33620.9141\n",
      "Epoch 742/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15032.4521 - val_loss: 33579.5195\n",
      "Epoch 743/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15139.2578 - val_loss: 33767.1445\n",
      "Epoch 744/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15176.4961 - val_loss: 33779.6367\n",
      "Epoch 745/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15114.9180 - val_loss: 33706.7344\n",
      "Epoch 746/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15068.3379 - val_loss: 33602.6875\n",
      "Epoch 747/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15343.2158 - val_loss: 33669.4961\n",
      "Epoch 748/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14824.6436 - val_loss: 33690.3906\n",
      "Epoch 749/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15013.4814 - val_loss: 33703.4883\n",
      "Epoch 750/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14928.8828 - val_loss: 33679.0781\n",
      "Epoch 751/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15039.8555 - val_loss: 33759.6367\n",
      "Epoch 752/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14990.8018 - val_loss: 33724.3828\n",
      "Epoch 753/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15019.1904 - val_loss: 33585.7812\n",
      "Epoch 754/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 15124.9814 - val_loss: 33808.4922\n",
      "Epoch 755/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15005.6064 - val_loss: 33622.8789\n",
      "Epoch 756/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15014.5469 - val_loss: 33826.8906\n",
      "Epoch 757/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14921.6094 - val_loss: 33762.6875\n",
      "Epoch 758/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15076.4521 - val_loss: 33739.3047\n",
      "Epoch 759/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14401.3711 - val_loss: 33740.8242\n",
      "Epoch 760/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15025.6709 - val_loss: 33642.7539\n",
      "Epoch 761/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14990.2168 - val_loss: 33745.6367\n",
      "Epoch 762/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15073.3154 - val_loss: 33835.0781\n",
      "Epoch 763/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14999.6660 - val_loss: 33853.7617\n",
      "Epoch 764/1000\n",
      "114/114 [==============================] - ETA: 0s - loss: 14800.366 - 0s 1ms/step - loss: 14724.6338 - val_loss: 33792.9180\n",
      "Epoch 765/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 15043.4424 - val_loss: 33909.4648\n",
      "Epoch 766/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14651.2197 - val_loss: 33834.8906\n",
      "Epoch 767/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14784.3643 - val_loss: 33758.0430\n",
      "Epoch 768/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14891.5283 - val_loss: 33666.0586\n",
      "Epoch 769/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14612.3594 - val_loss: 33794.0859\n",
      "Epoch 770/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14793.6201 - val_loss: 33678.3945\n",
      "Epoch 771/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14675.4102 - val_loss: 33773.1211\n",
      "Epoch 772/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14707.9951 - val_loss: 33690.0508\n",
      "Epoch 773/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14784.5801 - val_loss: 33762.0625\n",
      "Epoch 774/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14908.2236 - val_loss: 33876.3906\n",
      "Epoch 775/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14835.1924 - val_loss: 33866.4258\n",
      "Epoch 776/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14695.1992 - val_loss: 33823.7617\n",
      "Epoch 777/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14659.5488 - val_loss: 33805.0820\n",
      "Epoch 778/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14770.8145 - val_loss: 33759.8438\n",
      "Epoch 779/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14613.3535 - val_loss: 33642.8438\n",
      "Epoch 780/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14499.6562 - val_loss: 33721.2656\n",
      "Epoch 781/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14293.1641 - val_loss: 33741.1953\n",
      "Epoch 782/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14854.1123 - val_loss: 33817.4258\n",
      "Epoch 783/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14812.7031 - val_loss: 33814.6836\n",
      "Epoch 784/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14685.6904 - val_loss: 33671.0820\n",
      "Epoch 785/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14553.5371 - val_loss: 33876.2070\n",
      "Epoch 786/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14738.2754 - val_loss: 33961.0273\n",
      "Epoch 787/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14734.4072 - val_loss: 33957.5234\n",
      "Epoch 788/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14598.9863 - val_loss: 33817.4922\n",
      "Epoch 789/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14450.8516 - val_loss: 33889.1641\n",
      "Epoch 790/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14641.9648 - val_loss: 33672.7773\n",
      "Epoch 791/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14607.3672 - val_loss: 33805.6992\n",
      "Epoch 792/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14671.2539 - val_loss: 33679.5547\n",
      "Epoch 793/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14754.9629 - val_loss: 33833.4570\n",
      "Epoch 794/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14274.6016 - val_loss: 33759.8984\n",
      "Epoch 795/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14479.5625 - val_loss: 33772.3125\n",
      "Epoch 796/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14540.1729 - val_loss: 33764.6016\n",
      "Epoch 797/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14541.0078 - val_loss: 33838.9258\n",
      "Epoch 798/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14576.3955 - val_loss: 33754.3789\n",
      "Epoch 799/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14667.9404 - val_loss: 33755.3203\n",
      "Epoch 800/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14491.7988 - val_loss: 33803.1094\n",
      "Epoch 801/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14750.0918 - val_loss: 33830.9648\n",
      "Epoch 802/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14350.0498 - val_loss: 33856.3711\n",
      "Epoch 803/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14391.9268 - val_loss: 33804.4375\n",
      "Epoch 804/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 14648.1338 - val_loss: 33785.6992\n",
      "Epoch 805/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14464.2803 - val_loss: 33871.8750\n",
      "Epoch 806/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14623.2910 - val_loss: 33793.4492\n",
      "Epoch 807/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14223.4717 - val_loss: 33804.8828\n",
      "Epoch 808/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14414.6357 - val_loss: 33942.8438\n",
      "Epoch 809/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14235.6201 - val_loss: 33871.8594\n",
      "Epoch 810/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14457.1064 - val_loss: 33861.1836\n",
      "Epoch 811/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14354.4424 - val_loss: 34017.7148\n",
      "Epoch 812/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14251.7109 - val_loss: 33775.7031\n",
      "Epoch 813/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14451.0176 - val_loss: 33776.2344\n",
      "Epoch 814/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14447.2568 - val_loss: 33826.5430\n",
      "Epoch 815/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14359.5391 - val_loss: 33806.7773\n",
      "Epoch 816/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14473.5996 - val_loss: 33944.6406\n",
      "Epoch 817/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14329.5879 - val_loss: 33728.5352\n",
      "Epoch 818/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14224.2051 - val_loss: 33764.8516\n",
      "Epoch 819/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14490.3164 - val_loss: 33776.3594\n",
      "Epoch 820/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14312.1191 - val_loss: 33835.6094\n",
      "Epoch 821/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14287.7490 - val_loss: 33899.9219\n",
      "Epoch 822/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14177.6436 - val_loss: 33844.5703\n",
      "Epoch 823/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14471.6475 - val_loss: 33823.5352\n",
      "Epoch 824/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14215.0068 - val_loss: 33882.7656\n",
      "Epoch 825/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14345.6455 - val_loss: 33913.2461\n",
      "Epoch 826/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14325.9844 - val_loss: 33853.1523\n",
      "Epoch 827/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14470.7871 - val_loss: 33810.1211\n",
      "Epoch 828/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14149.1709 - val_loss: 33897.9297\n",
      "Epoch 829/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14339.6523 - val_loss: 33877.0781\n",
      "Epoch 830/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14428.7822 - val_loss: 33880.3867\n",
      "Epoch 831/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14450.3984 - val_loss: 33861.0352\n",
      "Epoch 832/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14330.4951 - val_loss: 34032.0078\n",
      "Epoch 833/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14313.1523 - val_loss: 33776.7070\n",
      "Epoch 834/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13795.8398 - val_loss: 33986.2930\n",
      "Epoch 835/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14060.7041 - val_loss: 33759.4648\n",
      "Epoch 836/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14386.7676 - val_loss: 33906.2188\n",
      "Epoch 837/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14304.4277 - val_loss: 33881.9492\n",
      "Epoch 838/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14278.4023 - val_loss: 33916.8047\n",
      "Epoch 839/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14187.0352 - val_loss: 33762.2891\n",
      "Epoch 840/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14159.7686 - val_loss: 33836.7188\n",
      "Epoch 841/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13984.4844 - val_loss: 33958.4844\n",
      "Epoch 842/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14280.5742 - val_loss: 33873.5977\n",
      "Epoch 843/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14168.8818 - val_loss: 33898.6133\n",
      "Epoch 844/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14225.0439 - val_loss: 33944.4844\n",
      "Epoch 845/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14180.7168 - val_loss: 33961.2500\n",
      "Epoch 846/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14041.8525 - val_loss: 33984.1328\n",
      "Epoch 847/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14020.2637 - val_loss: 33811.4648\n",
      "Epoch 848/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14155.9727 - val_loss: 33878.7266\n",
      "Epoch 849/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14078.1611 - val_loss: 34063.5352\n",
      "Epoch 850/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13964.2520 - val_loss: 33885.4023\n",
      "Epoch 851/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14102.8799 - val_loss: 33922.3984\n",
      "Epoch 852/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14076.6025 - val_loss: 33851.1484\n",
      "Epoch 853/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14214.0039 - val_loss: 33970.7031\n",
      "Epoch 854/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14202.1846 - val_loss: 33985.5938\n",
      "Epoch 855/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13970.9336 - val_loss: 33952.2930\n",
      "Epoch 856/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13884.8633 - val_loss: 34002.7969\n",
      "Epoch 857/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14290.7441 - val_loss: 34072.0586\n",
      "Epoch 858/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13738.8770 - val_loss: 34061.2070\n",
      "Epoch 859/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14040.7100 - val_loss: 34065.8516\n",
      "Epoch 860/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14088.0039 - val_loss: 34051.9648\n",
      "Epoch 861/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14168.9561 - val_loss: 34007.0586\n",
      "Epoch 862/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 14131.8164 - val_loss: 34105.8320\n",
      "Epoch 863/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13466.0010 - val_loss: 34060.9883\n",
      "Epoch 864/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13973.1074 - val_loss: 34041.5547\n",
      "Epoch 865/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14225.8291 - val_loss: 33998.0156\n",
      "Epoch 866/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14032.7861 - val_loss: 34188.4023\n",
      "Epoch 867/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13665.3457 - val_loss: 34033.2109\n",
      "Epoch 868/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14205.2959 - val_loss: 33887.3281\n",
      "Epoch 869/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13889.1016 - val_loss: 33976.6602\n",
      "Epoch 870/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13829.1709 - val_loss: 34010.8633\n",
      "Epoch 871/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13828.5615 - val_loss: 34007.9492\n",
      "Epoch 872/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13952.3027 - val_loss: 33997.5039\n",
      "Epoch 873/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13749.5898 - val_loss: 33938.5234\n",
      "Epoch 874/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13981.3135 - val_loss: 34049.8789\n",
      "Epoch 875/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14114.3027 - val_loss: 34038.3633\n",
      "Epoch 876/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13887.1084 - val_loss: 33979.3281\n",
      "Epoch 877/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 14065.8027 - val_loss: 34033.1523\n",
      "Epoch 878/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13972.6924 - val_loss: 34020.6953\n",
      "Epoch 879/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13977.8564 - val_loss: 34036.4375\n",
      "Epoch 880/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13576.3398 - val_loss: 34045.7227\n",
      "Epoch 881/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13905.2881 - val_loss: 34042.3281\n",
      "Epoch 882/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13875.1055 - val_loss: 34118.8828\n",
      "Epoch 883/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13863.5127 - val_loss: 33964.4609\n",
      "Epoch 884/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13768.9248 - val_loss: 34008.1250\n",
      "Epoch 885/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13887.6641 - val_loss: 34016.0156\n",
      "Epoch 886/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13727.0068 - val_loss: 34007.5508\n",
      "Epoch 887/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13787.7344 - val_loss: 34003.4648\n",
      "Epoch 888/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13752.7920 - val_loss: 33960.1602\n",
      "Epoch 889/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13734.0557 - val_loss: 34050.2695\n",
      "Epoch 890/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13808.1572 - val_loss: 34080.4961\n",
      "Epoch 891/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13601.5000 - val_loss: 34042.7500\n",
      "Epoch 892/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13697.8301 - val_loss: 34020.1250\n",
      "Epoch 893/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13837.3799 - val_loss: 33976.1133\n",
      "Epoch 894/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13752.3750 - val_loss: 33894.7109\n",
      "Epoch 895/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13819.3047 - val_loss: 34109.6016\n",
      "Epoch 896/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13578.8691 - val_loss: 33874.5703\n",
      "Epoch 897/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13668.2031 - val_loss: 34070.4648\n",
      "Epoch 898/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13806.3535 - val_loss: 33924.3828\n",
      "Epoch 899/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13781.3057 - val_loss: 34075.4609\n",
      "Epoch 900/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13694.5684 - val_loss: 34120.8281\n",
      "Epoch 901/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13566.2539 - val_loss: 34042.4297\n",
      "Epoch 902/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13664.7568 - val_loss: 33959.7812\n",
      "Epoch 903/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13138.9414 - val_loss: 34023.9102\n",
      "Epoch 904/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13306.0576 - val_loss: 34069.4102\n",
      "Epoch 905/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13660.4561 - val_loss: 34030.1992\n",
      "Epoch 906/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13418.0752 - val_loss: 34084.1484\n",
      "Epoch 907/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13747.2168 - val_loss: 33985.2461\n",
      "Epoch 908/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13610.8760 - val_loss: 34176.4414\n",
      "Epoch 909/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13473.9141 - val_loss: 34068.3633\n",
      "Epoch 910/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13654.6084 - val_loss: 34180.7734\n",
      "Epoch 911/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13625.6885 - val_loss: 34145.5312\n",
      "Epoch 912/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13649.9736 - val_loss: 34250.3789\n",
      "Epoch 913/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13679.9854 - val_loss: 34209.0391\n",
      "Epoch 914/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13384.6816 - val_loss: 34198.8203\n",
      "Epoch 915/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13295.3057 - val_loss: 34181.5352\n",
      "Epoch 916/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13417.4219 - val_loss: 34361.6602\n",
      "Epoch 917/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13310.7207 - val_loss: 34197.6055\n",
      "Epoch 918/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13616.0518 - val_loss: 34213.7500\n",
      "Epoch 919/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13253.1240 - val_loss: 34177.5430\n",
      "Epoch 920/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13594.8447 - val_loss: 34141.8633\n",
      "Epoch 921/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13414.2227 - val_loss: 34160.3281\n",
      "Epoch 922/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13682.3584 - val_loss: 34221.5156\n",
      "Epoch 923/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13487.6699 - val_loss: 34221.1016\n",
      "Epoch 924/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13206.6455 - val_loss: 34276.7070\n",
      "Epoch 925/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13410.9580 - val_loss: 34045.1445\n",
      "Epoch 926/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13568.2393 - val_loss: 34201.6211\n",
      "Epoch 927/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13635.7549 - val_loss: 34216.1719\n",
      "Epoch 928/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13324.3740 - val_loss: 34211.5469\n",
      "Epoch 929/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13560.6016 - val_loss: 34132.3359\n",
      "Epoch 930/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13302.0479 - val_loss: 34075.7266\n",
      "Epoch 931/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13488.5703 - val_loss: 34160.2852\n",
      "Epoch 932/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13329.2344 - val_loss: 34286.7227\n",
      "Epoch 933/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13490.4834 - val_loss: 34403.0938\n",
      "Epoch 934/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13301.2217 - val_loss: 34353.1484\n",
      "Epoch 935/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13395.0166 - val_loss: 34166.3047\n",
      "Epoch 936/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13653.2080 - val_loss: 34077.0156\n",
      "Epoch 937/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13561.1602 - val_loss: 34190.0234\n",
      "Epoch 938/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13367.7910 - val_loss: 34262.3281\n",
      "Epoch 939/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13219.5000 - val_loss: 34152.4258\n",
      "Epoch 940/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13361.7559 - val_loss: 34317.0898\n",
      "Epoch 941/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13487.5977 - val_loss: 34313.1250\n",
      "Epoch 942/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13130.9814 - val_loss: 34301.4414\n",
      "Epoch 943/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13148.8643 - val_loss: 34243.7812\n",
      "Epoch 944/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13374.4072 - val_loss: 34180.5273\n",
      "Epoch 945/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13293.3174 - val_loss: 34203.2539\n",
      "Epoch 946/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13233.6553 - val_loss: 34337.2656\n",
      "Epoch 947/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13229.2344 - val_loss: 34191.6875\n",
      "Epoch 948/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13200.7461 - val_loss: 34374.9258\n",
      "Epoch 949/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13499.4736 - val_loss: 34214.7422\n",
      "Epoch 950/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 13369.7734 - val_loss: 34212.6562\n",
      "Epoch 951/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 13180.0137 - val_loss: 34124.0508\n",
      "Epoch 952/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13112.6426 - val_loss: 34236.2031\n",
      "Epoch 953/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 13451.5254 - val_loss: 34178.5156\n",
      "Epoch 954/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13267.1973 - val_loss: 34291.3047\n",
      "Epoch 955/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13123.5742 - val_loss: 34289.7305\n",
      "Epoch 956/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13187.0410 - val_loss: 34202.1211\n",
      "Epoch 957/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13359.7705 - val_loss: 34285.6484\n",
      "Epoch 958/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13219.8223 - val_loss: 34261.0898\n",
      "Epoch 959/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13142.2305 - val_loss: 34339.6055\n",
      "Epoch 960/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12935.9648 - val_loss: 34161.7578\n",
      "Epoch 961/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13256.4912 - val_loss: 34160.0391\n",
      "Epoch 962/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13226.0752 - val_loss: 34343.5391\n",
      "Epoch 963/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13220.7959 - val_loss: 34286.7930\n",
      "Epoch 964/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13392.9756 - val_loss: 34313.9141\n",
      "Epoch 965/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13168.0361 - val_loss: 34211.1953\n",
      "Epoch 966/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 13081.2773 - val_loss: 34234.9258\n",
      "Epoch 967/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13117.4277 - val_loss: 34212.3164\n",
      "Epoch 968/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13169.3057 - val_loss: 34304.7227\n",
      "Epoch 969/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13325.6191 - val_loss: 34413.0234\n",
      "Epoch 970/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13166.9590 - val_loss: 34174.8555\n",
      "Epoch 971/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13118.3721 - val_loss: 34299.0977\n",
      "Epoch 972/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13172.5566 - val_loss: 34225.2656\n",
      "Epoch 973/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12973.6299 - val_loss: 34309.5352\n",
      "Epoch 974/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12940.5195 - val_loss: 34220.2852\n",
      "Epoch 975/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13292.2910 - val_loss: 34216.5039\n",
      "Epoch 976/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12983.6182 - val_loss: 34363.9297\n",
      "Epoch 977/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12966.3486 - val_loss: 34350.6211\n",
      "Epoch 978/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13044.6367 - val_loss: 34359.0820\n",
      "Epoch 979/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13018.9941 - val_loss: 34298.4961\n",
      "Epoch 980/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13015.7451 - val_loss: 34252.5430\n",
      "Epoch 981/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13127.1621 - val_loss: 34426.9180\n",
      "Epoch 982/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12733.0928 - val_loss: 34452.4219\n",
      "Epoch 983/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12896.9238 - val_loss: 34321.7734\n",
      "Epoch 984/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12947.4043 - val_loss: 34379.1914\n",
      "Epoch 985/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12731.4111 - val_loss: 34482.1250\n",
      "Epoch 986/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12892.3447 - val_loss: 34611.7734\n",
      "Epoch 987/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13228.0400 - val_loss: 34261.6641\n",
      "Epoch 988/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12943.6201 - val_loss: 34250.1328\n",
      "Epoch 989/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12888.7734 - val_loss: 34376.5195\n",
      "Epoch 990/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13056.4951 - val_loss: 34308.5195\n",
      "Epoch 991/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12975.4482 - val_loss: 34316.9961\n",
      "Epoch 992/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13076.4736 - val_loss: 34441.8555\n",
      "Epoch 993/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12999.1553 - val_loss: 34285.8281\n",
      "Epoch 994/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 13032.3438 - val_loss: 34394.3477\n",
      "Epoch 995/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12983.2422 - val_loss: 34464.6367\n",
      "Epoch 996/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12618.5137 - val_loss: 34277.5195\n",
      "Epoch 997/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12852.1074 - val_loss: 34329.1250\n",
      "Epoch 998/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12989.0312 - val_loss: 34334.8711\n",
      "Epoch 999/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 12801.7266 - val_loss: 34434.5352\n",
      "Epoch 1000/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 12968.4609 - val_loss: 34442.7461\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(50, kernel_initializer='he_uniform', activation='relu',input_dim=60))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(25, kernel_initializer='he_uniform', activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(50, kernel_initializer='he_uniform', activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(1, kernel_initializer = 'he_uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred=classifier.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_test, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred=pd.DataFrame(ann_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
