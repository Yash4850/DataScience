{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Competition for House Prices: Advanced Regression Techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping features which have high null values or which are not so relevant\n",
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)\n",
    "df.drop(['Alley'],axis=1,inplace=True)\n",
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)\n",
    "df.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill Missing Values\n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())\n",
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])\n",
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])\n",
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])\n",
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])\n",
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])\n",
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 75)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "                ..\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2142fb9af70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##HAndle Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine Test Data \n",
    "\n",
    "test_df=pd.read_csv('formulatedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg         Lvl   \n",
       "1          20       RL         81.0    14267   Pave      IR1         Lvl   \n",
       "2          60       RL         74.0    13830   Pave      IR1         Lvl   \n",
       "3          60       RL         78.0     9978   Pave      IR1         Lvl   \n",
       "4         120       RL         43.0     5005   Pave      IR1         HLS   \n",
       "\n",
       "  Utilities LotConfig LandSlope      ...      OpenPorchSF EnclosedPorch  \\\n",
       "0    AllPub    Inside       Gtl      ...                0             0   \n",
       "1    AllPub    Corner       Gtl      ...               36             0   \n",
       "2    AllPub    Inside       Gtl      ...               34             0   \n",
       "3    AllPub    Inside       Gtl      ...               36             0   \n",
       "4    AllPub    Inside       Gtl      ...               82             0   \n",
       "\n",
       "  3SsnPorch ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType  \\\n",
       "0         0         120        0        0       6    2010        WD   \n",
       "1         0           0        0    12500       6    2010        WD   \n",
       "2         0           0        0        0       3    2010        WD   \n",
       "3         0           0        0        0       6    2010        WD   \n",
       "4         0         144        0        0       1    2010        WD   \n",
       "\n",
       "  SaleCondition  \n",
       "0        Normal  \n",
       "1        Normal  \n",
       "2        Normal  \n",
       "3        Normal  \n",
       "4        Normal  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "final_df=pd.concat([df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500.0\n",
       "1       181500.0\n",
       "2       223500.0\n",
       "3       140000.0\n",
       "4       250000.0\n",
       "5       143000.0\n",
       "6       307000.0\n",
       "7       200000.0\n",
       "8       129900.0\n",
       "9       118000.0\n",
       "10      129500.0\n",
       "11      345000.0\n",
       "12      144000.0\n",
       "13      279500.0\n",
       "14      157000.0\n",
       "15      132000.0\n",
       "16      149000.0\n",
       "18      159000.0\n",
       "19      139000.0\n",
       "20      325300.0\n",
       "21      139400.0\n",
       "22      230000.0\n",
       "23      129900.0\n",
       "24      154000.0\n",
       "25      256300.0\n",
       "26      134800.0\n",
       "27      306000.0\n",
       "28      207500.0\n",
       "29       68500.0\n",
       "30       40000.0\n",
       "          ...   \n",
       "1429         NaN\n",
       "1430         NaN\n",
       "1431         NaN\n",
       "1432         NaN\n",
       "1433         NaN\n",
       "1434         NaN\n",
       "1435         NaN\n",
       "1436         NaN\n",
       "1437         NaN\n",
       "1438         NaN\n",
       "1439         NaN\n",
       "1440         NaN\n",
       "1441         NaN\n",
       "1442         NaN\n",
       "1443         NaN\n",
       "1444         NaN\n",
       "1445         NaN\n",
       "1446         NaN\n",
       "1447         NaN\n",
       "1448         NaN\n",
       "1449         NaN\n",
       "1450         NaN\n",
       "1451         NaN\n",
       "1452         NaN\n",
       "1453         NaN\n",
       "1454         NaN\n",
       "1455         NaN\n",
       "1456         NaN\n",
       "1457         NaN\n",
       "1458         NaN\n",
       "Name: SalePrice, Length: 2881, dtype: float64"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 75)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 235)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>796</td>\n",
       "      <td>566</td>\n",
       "      <td>320</td>\n",
       "      <td>1</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1369.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1107</td>\n",
       "      <td>983</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>859.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>228</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1022</td>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>851.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>906.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1182</td>\n",
       "      <td>1142</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>998.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>733.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>578.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>646.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1158</td>\n",
       "      <td>1218</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>188.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>234.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>649</td>\n",
       "      <td>668</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>967</td>\n",
       "      <td>671</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>967.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>1060</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>576</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>1778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>1646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>1625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>776.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>1664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>1210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>909.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>1838</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>1368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>616</td>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>1652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>1360</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>119.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>408.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>996</td>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2881 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0          856       854          0             3       706.0         0.0   \n",
       "1         1262         0          0             3       978.0         0.0   \n",
       "2          920       866          0             3       486.0         0.0   \n",
       "3          961       756          0             3       216.0         0.0   \n",
       "4         1145      1053          0             4       655.0         0.0   \n",
       "5          796       566        320             1       732.0         0.0   \n",
       "6         1694         0          0             3      1369.0         0.0   \n",
       "7         1107       983          0             3       859.0        32.0   \n",
       "8         1022       752          0             2         0.0         0.0   \n",
       "9         1077         0          0             2       851.0         0.0   \n",
       "10        1040         0          0             3       906.0         0.0   \n",
       "11        1182      1142          0             4       998.0         0.0   \n",
       "12         912         0          0             2       737.0         0.0   \n",
       "13        1494         0          0             3         0.0         0.0   \n",
       "14        1253         0          0             2       733.0         0.0   \n",
       "15         854         0          0             2         0.0         0.0   \n",
       "16        1004         0          0             2       578.0         0.0   \n",
       "18        1114         0          0             3       646.0         0.0   \n",
       "19        1339         0          0             3       504.0         0.0   \n",
       "20        1158      1218          0             4         0.0         0.0   \n",
       "21        1108         0          0             3         0.0         0.0   \n",
       "22        1795         0          0             3         0.0         0.0   \n",
       "23        1060         0          0             3       840.0         0.0   \n",
       "24        1060         0          0             3       188.0       668.0   \n",
       "25        1600         0          0             3         0.0         0.0   \n",
       "26         900         0          0             3       234.0       486.0   \n",
       "27        1704         0          0             3      1218.0         0.0   \n",
       "28        1600         0          0             2      1277.0         0.0   \n",
       "29         520         0          0             1         0.0         0.0   \n",
       "30         649       668          0             3         0.0         0.0   \n",
       "...        ...       ...        ...           ...         ...         ...   \n",
       "1429       641         0          0             2         0.0         0.0   \n",
       "1430       967       671          0             4         0.0         0.0   \n",
       "1431       729         0          0             2         0.0         0.0   \n",
       "1432      1060       336          0             4         0.0         0.0   \n",
       "1433       576       360          0             2         0.0         0.0   \n",
       "1434      1778         0          0             2      1573.0         0.0   \n",
       "1435      1646         0          0             2      1564.0         0.0   \n",
       "1436      1625         0          0             3       776.0         0.0   \n",
       "1437      1664         0          0             4         0.0         0.0   \n",
       "1438      1491         0          0             3         0.0         0.0   \n",
       "1439      1210         0          0             3       576.0         0.0   \n",
       "1440      1650         0          0             2       909.0         0.0   \n",
       "1441      1403         0          0             2      1136.0       116.0   \n",
       "1442      1960         0          0             3      1350.0         0.0   \n",
       "1443      1838         0          0             3      1455.0         0.0   \n",
       "1444      1600         0          0             3         0.0         0.0   \n",
       "1445      1368         0          0             2      1243.0         0.0   \n",
       "1446       616       688          0             3         0.0         0.0   \n",
       "1447       874         0          0             3       441.0         0.0   \n",
       "1448      1652         0          0             4       149.0         0.0   \n",
       "1449       630         0          0             1       522.0         0.0   \n",
       "1450       546       546          0             3       252.0         0.0   \n",
       "1451      1360         0          0             3       119.0       344.0   \n",
       "1452       546       546          0             3       408.0         0.0   \n",
       "1453       546       546          0             3         0.0         0.0   \n",
       "1454       546       546          0             3         0.0         0.0   \n",
       "1455       546       546          0             3       252.0         0.0   \n",
       "1456      1224         0          0             4      1224.0         0.0   \n",
       "1457       970         0          0             3       337.0         0.0   \n",
       "1458       996      1004          0             3       758.0         0.0   \n",
       "\n",
       "      BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  \\\n",
       "0              1.0           0.0      150.0              0 ...     0     0   \n",
       "1              0.0           1.0      284.0              0 ...     0     0   \n",
       "2              1.0           0.0      434.0              0 ...     0     0   \n",
       "3              1.0           0.0      540.0            272 ...     0     0   \n",
       "4              1.0           0.0      490.0              0 ...     0     0   \n",
       "5              1.0           0.0       64.0              0 ...     0     0   \n",
       "6              1.0           0.0      317.0              0 ...     0     0   \n",
       "7              1.0           0.0      216.0            228 ...     0     0   \n",
       "8              0.0           0.0      952.0            205 ...     1     0   \n",
       "9              1.0           0.0      140.0              0 ...     0     0   \n",
       "10             1.0           0.0      134.0              0 ...     0     0   \n",
       "11             1.0           0.0      177.0              0 ...     0     0   \n",
       "12             1.0           0.0      175.0              0 ...     0     0   \n",
       "13             0.0           0.0     1494.0              0 ...     0     0   \n",
       "14             1.0           0.0      520.0            176 ...     0     0   \n",
       "15             0.0           0.0      832.0              0 ...     0     0   \n",
       "16             1.0           0.0      426.0              0 ...     0     0   \n",
       "18             1.0           0.0      468.0              0 ...     0     0   \n",
       "19             0.0           0.0      525.0              0 ...     1     0   \n",
       "20             0.0           0.0     1158.0              0 ...     0     0   \n",
       "21             0.0           0.0      637.0            205 ...     0     0   \n",
       "22             0.0           0.0     1777.0              0 ...     0     0   \n",
       "23             1.0           0.0      200.0              0 ...     0     0   \n",
       "24             1.0           0.0      204.0              0 ...     0     0   \n",
       "25             0.0           0.0     1566.0              0 ...     0     0   \n",
       "26             0.0           1.0      180.0              0 ...     0     0   \n",
       "27             1.0           0.0      486.0              0 ...     0     0   \n",
       "28             1.0           0.0      207.0              0 ...     0     0   \n",
       "29             0.0           0.0      520.0             87 ...     0     0   \n",
       "30             0.0           0.0      649.0            172 ...     0     0   \n",
       "...            ...           ...        ...            ... ...   ...   ...   \n",
       "1429           0.0           0.0      641.0             70 ...     0     0   \n",
       "1430           0.0           0.0      967.0              0 ...     0     0   \n",
       "1431           0.0           0.0        0.0             23 ...     0     0   \n",
       "1432           0.0           0.0      660.0              0 ...     0     1   \n",
       "1433           0.0           0.0      216.0              0 ...     0     0   \n",
       "1434           2.0           0.0        0.0              0 ...     0     0   \n",
       "1435           1.0           1.0       30.0              0 ...     0     0   \n",
       "1436           0.0           1.0      849.0              0 ...     0     0   \n",
       "1437           0.0           0.0     1664.0              0 ...     0     0   \n",
       "1438           0.0           0.0     1491.0              0 ...     0     0   \n",
       "1439           1.0           0.0      552.0              0 ...     0     0   \n",
       "1440           1.0           0.0      723.0              0 ...     0     0   \n",
       "1441           1.0           0.0      129.0              0 ...     0     0   \n",
       "1442           1.0           0.0      378.0              0 ...     0     0   \n",
       "1443           1.0           0.0      383.0              0 ...     0     0   \n",
       "1444           0.0           0.0        0.0            135 ...     0     0   \n",
       "1445           2.0           0.0       45.0              0 ...     0     0   \n",
       "1446           0.0           0.0      264.0              0 ...     0     0   \n",
       "1447           1.0           0.0      423.0              0 ...     0     0   \n",
       "1448           0.0           0.0     1503.0              0 ...     0     0   \n",
       "1449           1.0           0.0      108.0              0 ...     0     0   \n",
       "1450           0.0           0.0      294.0              0 ...     0     0   \n",
       "1451           1.0           0.0      641.0              0 ...     0     0   \n",
       "1452           0.0           0.0      138.0              0 ...     0     0   \n",
       "1453           0.0           0.0      546.0              0 ...     0     0   \n",
       "1454           0.0           0.0      546.0              0 ...     0     0   \n",
       "1455           0.0           0.0      294.0              0 ...     0     0   \n",
       "1456           1.0           0.0        0.0              0 ...     0     0   \n",
       "1457           0.0           1.0      575.0              0 ...     0     0   \n",
       "1458           0.0           0.0      238.0              0 ...     0     0   \n",
       "\n",
       "      Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1       1        0        0        0       0    1  0  \n",
       "1       1       1        0        0        0       0    1  0  \n",
       "2       1       1        0        0        0       0    1  0  \n",
       "3       1       0        0        0        0       1    0  0  \n",
       "4       1       1        0        0        0       0    1  0  \n",
       "5       1       1        0        0        0       0    0  0  \n",
       "6       1       1        0        0        0       0    1  0  \n",
       "7       1       1        0        0        0       0    1  0  \n",
       "8       0       0        0        0        0       1    0  0  \n",
       "9       1       1        0        0        0       0    1  0  \n",
       "10      1       0        0        0        0       1    0  0  \n",
       "11      1       0        0        1        0       0    0  0  \n",
       "12      1       0        0        0        0       1    0  0  \n",
       "13      1       1        0        0        0       0    1  0  \n",
       "14      1       1        0        0        0       0    1  0  \n",
       "15      1       0        0        0        0       1    0  0  \n",
       "16      1       1        0        0        0       0    0  0  \n",
       "18      1       0        0        0        0       1    0  0  \n",
       "19      0       1        0        0        0       0    0  0  \n",
       "20      1       0        0        1        0       0    1  0  \n",
       "21      1       1        0        0        0       0    0  0  \n",
       "22      1       1        0        0        0       0    1  0  \n",
       "23      1       1        0        0        0       0    0  0  \n",
       "24      1       1        0        0        0       0    0  0  \n",
       "25      1       1        0        0        0       0    1  0  \n",
       "26      1       0        0        0        0       1    0  0  \n",
       "27      1       1        0        0        0       0    1  0  \n",
       "28      1       1        0        0        0       0    1  0  \n",
       "29      1       0        0        0        0       1    0  0  \n",
       "30      1       0        0        0        0       1    0  0  \n",
       "...   ...     ...      ...      ...      ...     ...  ... ..  \n",
       "1429    1       0        0        0        0       1    0  0  \n",
       "1430    1       0        0        0        0       1    0  0  \n",
       "1431    0       1        0        0        0       0    0  0  \n",
       "1432    0       1        0        0        0       0    0  0  \n",
       "1433    1       1        0        0        0       0    0  0  \n",
       "1434    1       1        0        0        0       0    0  0  \n",
       "1435    1       1        0        0        0       0    0  0  \n",
       "1436    1       1        0        0        0       0    0  0  \n",
       "1437    1       0        0        0        0       0    0  0  \n",
       "1438    1       1        0        0        0       0    1  0  \n",
       "1439    1       1        0        0        0       0    0  0  \n",
       "1440    1       1        0        0        0       0    0  0  \n",
       "1441    1       1        0        0        0       0    0  0  \n",
       "1442    1       1        0        0        0       0    0  0  \n",
       "1443    1       1        0        0        0       0    0  0  \n",
       "1444    0       1        0        0        0       0    0  0  \n",
       "1445    1       1        0        0        0       0    0  0  \n",
       "1446    1       0        0        1        0       0    1  0  \n",
       "1447    1       1        0        0        0       0    1  0  \n",
       "1448    1       0        0        0        0       0    0  0  \n",
       "1449    1       1        0        0        0       0    0  0  \n",
       "1450    1       1        0        0        0       0    0  0  \n",
       "1451    1       1        0        0        0       0    1  0  \n",
       "1452    1       0        0        0        1       0    0  0  \n",
       "1453    1       1        0        0        0       0    0  0  \n",
       "1454    1       1        0        0        0       0    0  0  \n",
       "1455    1       0        0        0        1       0    0  0  \n",
       "1456    1       0        0        0        0       1    0  0  \n",
       "1457    1       1        0        0        0       0    0  0  \n",
       "1458    1       1        0        0        0       0    0  0  \n",
       "\n",
       "[2881 rows x 175 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=final_df.iloc[:1422,:]\n",
    "df_Test=final_df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       856       854          0             3       706.0         0.0   \n",
       "1      1262         0          0             3       978.0         0.0   \n",
       "2       920       866          0             3       486.0         0.0   \n",
       "3       961       756          0             3       216.0         0.0   \n",
       "4      1145      1053          0             4       655.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
       "0           1.0           0.0      150.0              0 ...     0     0    1   \n",
       "1           0.0           1.0      284.0              0 ...     0     0    1   \n",
       "2           1.0           0.0      434.0              0 ...     0     0    1   \n",
       "3           1.0           0.0      540.0            272 ...     0     0    1   \n",
       "4           1.0           0.0      490.0              0 ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    1  0  \n",
       "1       1        0        0        0       0    1  0  \n",
       "2       1        0        0        0       0    1  0  \n",
       "3       0        0        0        0       1    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
       "0           0.0           0.0      270.0              0 ...     0     0    1   \n",
       "1           0.0           0.0      406.0              0 ...     0     0    1   \n",
       "2           0.0           0.0      137.0              0 ...     0     0    1   \n",
       "3           0.0           0.0      324.0              0 ...     0     0    1   \n",
       "4           0.0           0.0     1017.0              0 ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 175)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "regressor=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=4,\n",
       "          param_distributions={'n_estimators': [100, 500, 900, 1100, 1500], 'max_depth': [2, 3, 5, 10, 15], 'learning_rate': [0.05, 0.1, 0.15, 0.2], 'min_child_weight': [1, 2, 3, 4], 'booster': ['gbtree', 'gblinear'], 'base_score': [0.25, 0.5, 0.75, 1]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "          verbose=5)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 174)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121033.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155717.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185616.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189161.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175323.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch      ...        Min2  \\\n",
       "0           0.0           0.0      270.0              0      ...           0   \n",
       "1           0.0           0.0      406.0              0      ...           0   \n",
       "2           0.0           0.0      137.0              0      ...           0   \n",
       "3           0.0           0.0      324.0              0      ...           0   \n",
       "4           0.0           0.0     1017.0              0      ...           0   \n",
       "\n",
       "   Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P      SalePrice  \n",
       "0    1       1        0        0        0       0    0  0  121033.398438  \n",
       "1    1       1        0        0        0       0    0  0  155717.390625  \n",
       "2    1       1        0        0        0       0    0  0  185616.859375  \n",
       "3    1       1        0        0        0       0    0  0  189161.546875  \n",
       "4    1       1        0        0        0       0    1  0  175323.750000  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
       "0           0.0           0.0      270.0              0 ...     0     0    1   \n",
       "1           0.0           0.0      406.0              0 ...     0     0    1   \n",
       "2           0.0           0.0      137.0              0 ...     0     0    1   \n",
       "3           0.0           0.0      324.0              0 ...     0     0    1   \n",
       "4           0.0           0.0     1017.0              0 ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=regressor.predict(df_Test.drop(['SalePrice'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([119179.125, 158328.88 , 183704.81 , ..., 165757.22 , 118693.11 ,\n",
       "       230294.19 ], dtype=float32)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred=pd.DataFrame(ann_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.columns=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=df_Train['SalePrice'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.column=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=pd.concat([df_Train,temp_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121033.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155717.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185616.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189161.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175323.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch      ...        Min2  \\\n",
       "0           0.0           0.0      270.0              0      ...           0   \n",
       "1           0.0           0.0      406.0              0      ...           0   \n",
       "2           0.0           0.0      137.0              0      ...           0   \n",
       "3           0.0           0.0      324.0              0      ...           0   \n",
       "4           0.0           0.0     1017.0              0      ...           0   \n",
       "\n",
       "   Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P      SalePrice  \n",
       "0    1       1        0        0        0       0    0  0  121033.398438  \n",
       "1    1       1        0        0        0       0    0  0  155717.390625  \n",
       "2    1       1        0        0        0       0    0  0  185616.859375  \n",
       "3    1       1        0        0        0       0    0  0  189161.546875  \n",
       "4    1       1        0        0        0       0    1  0  175323.750000  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test=pd.concat([df_Test,pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 175)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=pd.concat([df_Train,df_Test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2304 samples, validate on 577 samples\n",
      "Epoch 1/1000\n",
      "2304/2304 [==============================] - 2s 1ms/step - loss: 113530.5093 - val_loss: 56624.8765\n",
      "Epoch 2/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 62615.1298 - val_loss: 50444.1900\n",
      "Epoch 3/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 56279.5739 - val_loss: 44504.8296\n",
      "Epoch 4/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 50261.0310 - val_loss: 39335.5723\n",
      "Epoch 5/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 44449.5163 - val_loss: 35396.5539\n",
      "Epoch 6/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 40090.4315 - val_loss: 35178.2237\n",
      "Epoch 7/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 37493.4126 - val_loss: 31983.3301\n",
      "Epoch 8/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 36462.1401 - val_loss: 34241.1639\n",
      "Epoch 9/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 35635.4539 - val_loss: 32087.6040\n",
      "Epoch 10/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 35851.5885 - val_loss: 32125.1113\n",
      "Epoch 11/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 35622.6530 - val_loss: 31914.6602\n",
      "Epoch 12/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 35187.7144 - val_loss: 31882.3983\n",
      "Epoch 13/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 35196.1213 - val_loss: 32342.4395\n",
      "Epoch 14/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 34929.6660 - val_loss: 31565.0875\n",
      "Epoch 15/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 34672.9052 - val_loss: 32177.3833\n",
      "Epoch 16/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 34501.2563 - val_loss: 31293.5959\n",
      "Epoch 17/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 34804.2316 - val_loss: 31182.3204\n",
      "Epoch 18/1000\n",
      "2304/2304 [==============================] - 2s 778us/step - loss: 34455.4584 - val_loss: 31376.9020\n",
      "Epoch 19/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 34377.8071 - val_loss: 31301.4047\n",
      "Epoch 20/1000\n",
      "2304/2304 [==============================] - 1s 477us/step - loss: 34164.2543 - val_loss: 31142.9020\n",
      "Epoch 21/1000\n",
      "2304/2304 [==============================] - 1s 469us/step - loss: 34009.0316 - val_loss: 31243.3016\n",
      "Epoch 22/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 33660.4401 - val_loss: 31494.8445\n",
      "Epoch 23/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 33812.4372 - val_loss: 31299.1932\n",
      "Epoch 24/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 33589.9288 - val_loss: 31848.2731\n",
      "Epoch 25/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 33607.1809 - val_loss: 30390.6748\n",
      "Epoch 26/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 33473.9579 - val_loss: 30910.1593\n",
      "Epoch 27/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 33236.2349 - val_loss: 30219.5441\n",
      "Epoch 28/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 33243.2710 - val_loss: 30179.0993\n",
      "Epoch 29/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 32929.2295 - val_loss: 30128.3545\n",
      "Epoch 30/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 32963.0511 - val_loss: 30510.0357\n",
      "Epoch 31/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 32787.1626 - val_loss: 29853.5188\n",
      "Epoch 32/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 32766.8486 - val_loss: 30704.6890\n",
      "Epoch 33/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 32790.5330 - val_loss: 30381.5674\n",
      "Epoch 34/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 32740.6885 - val_loss: 29614.6660\n",
      "Epoch 35/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 32658.3221 - val_loss: 30323.1913\n",
      "Epoch 36/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 32570.0888 - val_loss: 30407.4534\n",
      "Epoch 37/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 32189.7531 - val_loss: 30379.3509\n",
      "Epoch 38/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 32140.4911 - val_loss: 29347.5356\n",
      "Epoch 39/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 31913.3835 - val_loss: 29861.8741\n",
      "Epoch 40/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 32135.0634 - val_loss: 29108.2475\n",
      "Epoch 41/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 32026.9856 - val_loss: 29142.3169\n",
      "Epoch 42/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 31792.7488 - val_loss: 29323.2182\n",
      "Epoch 43/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 31622.7127 - val_loss: 29028.4757\n",
      "Epoch 44/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 31769.7568 - val_loss: 29493.1864\n",
      "Epoch 45/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 31732.7656 - val_loss: 29812.4935\n",
      "Epoch 46/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 31434.8387 - val_loss: 28903.6488\n",
      "Epoch 47/1000\n",
      "2304/2304 [==============================] - 1s 414us/step - loss: 31234.3539 - val_loss: 28895.0965\n",
      "Epoch 48/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 31151.4855 - val_loss: 28861.3638\n",
      "Epoch 49/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 31274.5573 - val_loss: 29427.3137\n",
      "Epoch 50/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 31510.8220 - val_loss: 28567.3384\n",
      "Epoch 51/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 31460.1977 - val_loss: 28814.4977\n",
      "Epoch 52/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 31085.8429 - val_loss: 28524.2395\n",
      "Epoch 53/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 30989.9977 - val_loss: 28568.5788\n",
      "Epoch 54/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 31092.4584 - val_loss: 28378.7455\n",
      "Epoch 55/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 30932.9268 - val_loss: 30094.5473\n",
      "Epoch 56/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 30684.4676 - val_loss: 28414.4087\n",
      "Epoch 57/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 30493.6564 - val_loss: 29508.0253\n",
      "Epoch 58/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 30652.6024 - val_loss: 28326.5143\n",
      "Epoch 59/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 30778.1669 - val_loss: 28056.4234\n",
      "Epoch 60/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 30424.7307 - val_loss: 28010.0378\n",
      "Epoch 61/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 30072.8579 - val_loss: 28027.6187\n",
      "Epoch 62/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 30334.3219 - val_loss: 28459.9857\n",
      "Epoch 63/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 30427.8750 - val_loss: 29863.5684\n",
      "Epoch 64/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 30285.2018 - val_loss: 28957.1549\n",
      "Epoch 65/1000\n",
      "2304/2304 [==============================] - 1s 417us/step - loss: 30310.4877 - val_loss: 28183.0357\n",
      "Epoch 66/1000\n",
      "2304/2304 [==============================] - 1s 405us/step - loss: 30276.2501 - val_loss: 27665.3018\n",
      "Epoch 67/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 29832.1718 - val_loss: 27712.5372\n",
      "Epoch 68/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 30272.4041 - val_loss: 27718.7824\n",
      "Epoch 69/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 30113.7119 - val_loss: 28000.3839\n",
      "Epoch 70/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 29942.6214 - val_loss: 27786.2428\n",
      "Epoch 71/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 29859.0674 - val_loss: 27215.5401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 29209.5491 - val_loss: 27173.5760\n",
      "Epoch 73/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 29919.4843 - val_loss: 27220.3691\n",
      "Epoch 74/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 29509.6134 - val_loss: 27340.0882\n",
      "Epoch 75/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 29708.4845 - val_loss: 27312.6990\n",
      "Epoch 76/1000\n",
      "2304/2304 [==============================] - 1s 473us/step - loss: 29519.9725 - val_loss: 27508.6494\n",
      "Epoch 77/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 29357.4566 - val_loss: 26867.6287\n",
      "Epoch 78/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 29159.6736 - val_loss: 26893.8640\n",
      "Epoch 79/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 29366.9112 - val_loss: 26603.1912\n",
      "Epoch 80/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 29120.4931 - val_loss: 26661.9235\n",
      "Epoch 81/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 28946.7935 - val_loss: 27871.8099\n",
      "Epoch 82/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 29138.3855 - val_loss: 26531.3914\n",
      "Epoch 83/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 28846.1910 - val_loss: 28481.5947\n",
      "Epoch 84/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 29017.1691 - val_loss: 26508.0993\n",
      "Epoch 85/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 28775.6919 - val_loss: 26779.5843\n",
      "Epoch 86/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 29089.2547 - val_loss: 27172.3217\n",
      "Epoch 87/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 28686.1871 - val_loss: 26091.4350\n",
      "Epoch 88/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 28698.4660 - val_loss: 26102.4028\n",
      "Epoch 89/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 28699.3697 - val_loss: 26289.4353\n",
      "Epoch 90/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 28489.5871 - val_loss: 27897.5505\n",
      "Epoch 91/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 28665.1914 - val_loss: 25854.9589\n",
      "Epoch 92/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 28285.7090 - val_loss: 25977.9663\n",
      "Epoch 93/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 28285.7983 - val_loss: 25438.4628\n",
      "Epoch 94/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 28321.3720 - val_loss: 25585.6818\n",
      "Epoch 95/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 28190.3902 - val_loss: 25334.2817\n",
      "Epoch 96/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 28360.6425 - val_loss: 25095.3392\n",
      "Epoch 97/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 28196.4608 - val_loss: 24977.6499\n",
      "Epoch 98/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 28143.1103 - val_loss: 24957.5144\n",
      "Epoch 99/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 28541.725 - 1s 465us/step - loss: 28404.1788 - val_loss: 25377.6330\n",
      "Epoch 100/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 27923.1122 - val_loss: 25035.9833\n",
      "Epoch 101/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 28224.6294 - val_loss: 24864.9644\n",
      "Epoch 102/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 27838.1132 - val_loss: 26435.8536\n",
      "Epoch 103/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 27936.2079 - val_loss: 24885.9012\n",
      "Epoch 104/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 27583.212 - 1s 450us/step - loss: 27619.0787 - val_loss: 24613.4044\n",
      "Epoch 105/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 27628.1560 - val_loss: 24228.4823\n",
      "Epoch 106/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 27878.6943 - val_loss: 24845.3175\n",
      "Epoch 107/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 27493.7438 - val_loss: 24612.2324\n",
      "Epoch 108/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 27134.2120 - val_loss: 25914.3079\n",
      "Epoch 109/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 27448.0619 - val_loss: 23640.7174\n",
      "Epoch 110/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 27225.6602 - val_loss: 24300.4790\n",
      "Epoch 111/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 27457.5783 - val_loss: 23591.0836\n",
      "Epoch 112/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 27562.5854 - val_loss: 23601.4916\n",
      "Epoch 113/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 26970.8130 - val_loss: 23496.5879\n",
      "Epoch 114/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 27141.8372 - val_loss: 24716.6597\n",
      "Epoch 115/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 26687.5030 - val_loss: 25936.5065\n",
      "Epoch 116/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 26811.0217 - val_loss: 23067.7963\n",
      "Epoch 117/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 26862.9685 - val_loss: 23789.6916\n",
      "Epoch 118/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 26478.2679 - val_loss: 24595.6749\n",
      "Epoch 119/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 26766.5188 - val_loss: 23377.8840\n",
      "Epoch 120/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 26545.6570 - val_loss: 22453.2940\n",
      "Epoch 121/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 26442.3213 - val_loss: 22567.1628\n",
      "Epoch 122/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 26011.6722 - val_loss: 24087.4123\n",
      "Epoch 123/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 26506.6031 - val_loss: 22453.8540\n",
      "Epoch 124/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 26042.1024 - val_loss: 22348.5490\n",
      "Epoch 125/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 26685.7815 - val_loss: 21968.0753\n",
      "Epoch 126/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 25654.7254 - val_loss: 22398.2175\n",
      "Epoch 127/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 25909.7507 - val_loss: 21961.1548\n",
      "Epoch 128/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 25938.8809 - val_loss: 21437.6150\n",
      "Epoch 129/1000\n",
      "2304/2304 [==============================] - 1s 476us/step - loss: 25268.5747 - val_loss: 21907.7049\n",
      "Epoch 130/1000\n",
      "2304/2304 [==============================] - 1s 470us/step - loss: 25609.2470 - val_loss: 21246.5780\n",
      "Epoch 131/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 25023.4624 - val_loss: 24637.6923\n",
      "Epoch 132/1000\n",
      "2304/2304 [==============================] - 1s 520us/step - loss: 25366.8912 - val_loss: 21211.1705\n",
      "Epoch 133/1000\n",
      "2304/2304 [==============================] - 1s 479us/step - loss: 25424.9557 - val_loss: 21021.8191\n",
      "Epoch 134/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 25343.5929 - val_loss: 21586.6650\n",
      "Epoch 135/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 24995.2175 - val_loss: 21105.6569\n",
      "Epoch 136/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 24986.7363 - val_loss: 20605.5033\n",
      "Epoch 137/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 25225.4030 - val_loss: 20552.5941\n",
      "Epoch 138/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 25014.9195 - val_loss: 21813.1205\n",
      "Epoch 139/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 24983.0982 - val_loss: 20684.3204\n",
      "Epoch 140/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 24864.2334 - val_loss: 20245.8430\n",
      "Epoch 141/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 24915.6213 - val_loss: 19954.3808\n",
      "Epoch 142/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 24832.0423 - val_loss: 22799.6597\n",
      "Epoch 143/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 24758.2035 - val_loss: 20148.5544\n",
      "Epoch 144/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 24726.4656 - val_loss: 19816.7254\n",
      "Epoch 145/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 24342.4105 - val_loss: 21506.8392\n",
      "Epoch 146/1000\n",
      "2304/2304 [==============================] - 1s 494us/step - loss: 24704.4509 - val_loss: 19672.9874\n",
      "Epoch 147/1000\n",
      "2304/2304 [==============================] - 1s 483us/step - loss: 24873.8309 - val_loss: 19765.3019\n",
      "Epoch 148/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 24126.7666 - val_loss: 21504.0878\n",
      "Epoch 149/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 24424.1095 - val_loss: 21462.0763\n",
      "Epoch 150/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 24470.7238 - val_loss: 19617.8413\n",
      "Epoch 151/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 24235.2767 - val_loss: 20478.6877\n",
      "Epoch 152/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 23886.3026 - val_loss: 19679.8546\n",
      "Epoch 153/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 24203.4083 - val_loss: 19225.7126\n",
      "Epoch 154/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 24125.6937 - val_loss: 18712.8627\n",
      "Epoch 155/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 23699.3783 - val_loss: 19005.6716\n",
      "Epoch 156/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 23628.8058 - val_loss: 20574.2034\n",
      "Epoch 157/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 23527.5995 - val_loss: 20440.9397\n",
      "Epoch 158/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 23367.5987 - val_loss: 20027.8654\n",
      "Epoch 159/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 23393.3923 - val_loss: 18406.9154\n",
      "Epoch 160/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 23547.7516 - val_loss: 19510.1907\n",
      "Epoch 161/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 23700.4968 - val_loss: 19711.2351\n",
      "Epoch 162/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 23521.9805 - val_loss: 19353.0765\n",
      "Epoch 163/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 23289.4974 - val_loss: 18495.0024\n",
      "Epoch 164/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 23146.1177 - val_loss: 18525.8958\n",
      "Epoch 165/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 23378.2289 - val_loss: 18674.6753\n",
      "Epoch 166/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 22990.6150 - val_loss: 18405.3405\n",
      "Epoch 167/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 23208.1085 - val_loss: 18444.8079\n",
      "Epoch 168/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 23341.9950 - val_loss: 18214.6930\n",
      "Epoch 169/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22968.4293 - val_loss: 18287.0789\n",
      "Epoch 170/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 23336.9285 - val_loss: 19328.6353\n",
      "Epoch 171/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 23004.5811 - val_loss: 22645.0320\n",
      "Epoch 172/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 23450.7607 - val_loss: 18237.4190\n",
      "Epoch 173/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 23322.7922 - val_loss: 18528.1455\n",
      "Epoch 174/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 22646.3451 - val_loss: 18115.4026\n",
      "Epoch 175/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 22568.9873 - val_loss: 19539.2561\n",
      "Epoch 176/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 23544.2008 - val_loss: 17933.2717\n",
      "Epoch 177/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 22497.0116 - val_loss: 17354.5006\n",
      "Epoch 178/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 22879.9811 - val_loss: 17579.1927\n",
      "Epoch 179/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22938.6665 - val_loss: 18413.8741\n",
      "Epoch 180/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22665.2603 - val_loss: 19428.7250\n",
      "Epoch 181/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 22319.2484 - val_loss: 17366.1969\n",
      "Epoch 182/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 22669.5232 - val_loss: 18838.8342\n",
      "Epoch 183/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 22451.1597 - val_loss: 18472.8874\n",
      "Epoch 184/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 22706.7617 - val_loss: 18255.4424\n",
      "Epoch 185/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22957.0078 - val_loss: 17473.3416\n",
      "Epoch 186/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22531.9464 - val_loss: 16844.6493\n",
      "Epoch 187/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 22240.5742 - val_loss: 17564.5887\n",
      "Epoch 188/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 22642.6283 - val_loss: 17112.6908\n",
      "Epoch 189/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 22320.6819 - val_loss: 17639.8543\n",
      "Epoch 190/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22117.3255 - val_loss: 17005.3269\n",
      "Epoch 191/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22249.5553 - val_loss: 18395.3013\n",
      "Epoch 192/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 22401.0267 - val_loss: 16680.4410\n",
      "Epoch 193/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 22384.8159 - val_loss: 17162.2615\n",
      "Epoch 194/1000\n",
      "2304/2304 [==============================] - 1s 475us/step - loss: 21983.3552 - val_loss: 18605.2577\n",
      "Epoch 195/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22257.2526 - val_loss: 17034.5954\n",
      "Epoch 196/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 22122.9456 - val_loss: 17328.9022\n",
      "Epoch 197/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 22467.4348 - val_loss: 17312.1251\n",
      "Epoch 198/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 22034.0424 - val_loss: 16346.6881\n",
      "Epoch 199/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 21772.8173 - val_loss: 16449.1762\n",
      "Epoch 200/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 21616.0995 - val_loss: 19556.2224\n",
      "Epoch 201/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 22326.2749 - val_loss: 16196.6720\n",
      "Epoch 202/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 22678.2432 - val_loss: 16400.9500\n",
      "Epoch 203/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 21954.1421 - val_loss: 17115.8815\n",
      "Epoch 204/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21574.3031 - val_loss: 16127.1571\n",
      "Epoch 205/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 22338.9508 - val_loss: 19444.3208\n",
      "Epoch 206/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21852.7934 - val_loss: 19308.3233\n",
      "Epoch 207/1000\n",
      "2304/2304 [==============================] - 1s 473us/step - loss: 21872.5774 - val_loss: 17685.5849\n",
      "Epoch 208/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 21486.7361 - val_loss: 16639.5072\n",
      "Epoch 209/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 21571.2908 - val_loss: 16761.9651\n",
      "Epoch 210/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 21631.3609 - val_loss: 15658.4923\n",
      "Epoch 211/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 21486.4054 - val_loss: 15814.1505\n",
      "Epoch 212/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21541.5087 - val_loss: 17495.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 22039.3132 - val_loss: 18907.8804\n",
      "Epoch 214/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21535.5008 - val_loss: 16334.5270\n",
      "Epoch 215/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 21397.5464 - val_loss: 15527.8804\n",
      "Epoch 216/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20970.6127 - val_loss: 15893.2644\n",
      "Epoch 217/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 21382.1890 - val_loss: 16356.3695\n",
      "Epoch 218/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21161.6115 - val_loss: 17358.3467\n",
      "Epoch 219/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 21313.9134 - val_loss: 16149.4819\n",
      "Epoch 220/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21500.9419 - val_loss: 15796.3191\n",
      "Epoch 221/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 21536.2349 - val_loss: 15471.1339\n",
      "Epoch 222/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 21088.8941 - val_loss: 15343.0244\n",
      "Epoch 223/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 21667.5794 - val_loss: 17580.5199\n",
      "Epoch 224/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 20965.1858 - val_loss: 15803.6322\n",
      "Epoch 225/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21442.6807 - val_loss: 17598.5028\n",
      "Epoch 226/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 21107.7338 - val_loss: 15927.4279\n",
      "Epoch 227/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20982.8748 - val_loss: 16270.2747\n",
      "Epoch 228/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21420.9400 - val_loss: 15423.4538\n",
      "Epoch 229/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 20855.8819 - val_loss: 16644.8780\n",
      "Epoch 230/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 20768.6303 - val_loss: 15575.5588\n",
      "Epoch 231/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21261.2271 - val_loss: 16437.3966\n",
      "Epoch 232/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 21497.1832 - val_loss: 15420.6945\n",
      "Epoch 233/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 20544.3840 - val_loss: 15224.6794\n",
      "Epoch 234/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21233.0104 - val_loss: 15038.2329\n",
      "Epoch 235/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21491.5446 - val_loss: 17434.5473\n",
      "Epoch 236/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 21326.1712 - val_loss: 16683.8884\n",
      "Epoch 237/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 21116.4700 - val_loss: 15612.9380\n",
      "Epoch 238/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22033.4280 - val_loss: 15167.3380\n",
      "Epoch 239/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21327.5555 - val_loss: 15373.3279\n",
      "Epoch 240/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 20829.2319 - val_loss: 15861.8656\n",
      "Epoch 241/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 20925.8254 - val_loss: 15428.4299\n",
      "Epoch 242/1000\n",
      "2304/2304 [==============================] - 1s 510us/step - loss: 21137.2842 - val_loss: 19346.3964\n",
      "Epoch 243/1000\n",
      "2304/2304 [==============================] - 1s 495us/step - loss: 20912.4358 - val_loss: 15086.4801\n",
      "Epoch 244/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 20783.2399 - val_loss: 17047.4020\n",
      "Epoch 245/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 20600.0964 - val_loss: 16235.3380\n",
      "Epoch 246/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20756.1085 - val_loss: 15630.0819\n",
      "Epoch 247/1000\n",
      "2304/2304 [==============================] - 1s 487us/step - loss: 20794.2793 - val_loss: 15813.6791\n",
      "Epoch 248/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 20578.2091 - val_loss: 14941.2435\n",
      "Epoch 249/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20526.0308 - val_loss: 17806.7003\n",
      "Epoch 250/1000\n",
      "2304/2304 [==============================] - 1s 583us/step - loss: 20334.8256 - val_loss: 18193.9887\n",
      "Epoch 251/1000\n",
      "2304/2304 [==============================] - 1s 530us/step - loss: 20293.9275 - val_loss: 17792.9437\n",
      "Epoch 252/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 20567.1465 - val_loss: 15440.0669\n",
      "Epoch 253/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 20427.0153 - val_loss: 14923.4824\n",
      "Epoch 254/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 20450.5625 - val_loss: 16042.9484\n",
      "Epoch 255/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 20198.3318 - val_loss: 16222.9939\n",
      "Epoch 256/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 20533.8341 - val_loss: 16831.9639\n",
      "Epoch 257/1000\n",
      "2304/2304 [==============================] - 1s 509us/step - loss: 20154.9191 - val_loss: 14754.8845\n",
      "Epoch 258/1000\n",
      "2304/2304 [==============================] - 1s 469us/step - loss: 20387.4427 - val_loss: 15878.7856\n",
      "Epoch 259/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 20359.2988 - val_loss: 16003.4819\n",
      "Epoch 260/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 20531.9542 - val_loss: 16200.7362\n",
      "Epoch 261/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 20018.3629 - val_loss: 15491.6521\n",
      "Epoch 262/1000\n",
      "2304/2304 [==============================] - 1s 481us/step - loss: 20267.9428 - val_loss: 15069.8928\n",
      "Epoch 263/1000\n",
      "2304/2304 [==============================] - 1s 479us/step - loss: 20530.1369 - val_loss: 15627.3145\n",
      "Epoch 264/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 20294.7257 - val_loss: 17765.7470\n",
      "Epoch 265/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 20360.8740 - val_loss: 14508.3821\n",
      "Epoch 266/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 20267.8221 - val_loss: 15420.8517\n",
      "Epoch 267/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 19862.5230 - val_loss: 14701.4737\n",
      "Epoch 268/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 19815.6728 - val_loss: 14743.0286\n",
      "Epoch 269/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19757.1898 - val_loss: 16036.5053\n",
      "Epoch 270/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 19572.5032 - val_loss: 15336.2828\n",
      "Epoch 271/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19700.6566 - val_loss: 15040.9445\n",
      "Epoch 272/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19473.6894 - val_loss: 15602.6384\n",
      "Epoch 273/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 19906.8170 - val_loss: 14509.2126\n",
      "Epoch 274/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 19699.7736 - val_loss: 15772.0936\n",
      "Epoch 275/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 20105.0729 - val_loss: 14584.7437\n",
      "Epoch 276/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 20147.8612 - val_loss: 15057.5087\n",
      "Epoch 277/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 19881.5120 - val_loss: 18572.5668\n",
      "Epoch 278/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19517.4842 - val_loss: 16397.4856\n",
      "Epoch 279/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 19976.7596 - val_loss: 15108.0453\n",
      "Epoch 280/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 19935.8306 - val_loss: 15692.7591\n",
      "Epoch 281/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 19793.6322 - val_loss: 14389.2686\n",
      "Epoch 282/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19412.6952 - val_loss: 15312.0001\n",
      "Epoch 283/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 20059.2136 - val_loss: 15273.2969\n",
      "Epoch 284/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19604.2384 - val_loss: 14420.2558\n",
      "Epoch 285/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 19496.6790 - val_loss: 14708.9673\n",
      "Epoch 286/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 20049.3460 - val_loss: 16034.7254\n",
      "Epoch 287/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 19478.0735 - val_loss: 14571.8502\n",
      "Epoch 288/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19667.3767 - val_loss: 14611.5370\n",
      "Epoch 289/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19504.3439 - val_loss: 14015.6003\n",
      "Epoch 290/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19758.8318 - val_loss: 16997.5221\n",
      "Epoch 291/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 19601.7732 - val_loss: 17615.9217\n",
      "Epoch 292/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 19661.4567 - val_loss: 16816.5259\n",
      "Epoch 293/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19131.7665 - val_loss: 14086.0776\n",
      "Epoch 294/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 19576.5483 - val_loss: 14701.9938\n",
      "Epoch 295/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 19444.5205 - val_loss: 14263.2803\n",
      "Epoch 296/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 19304.4485 - val_loss: 14911.7827\n",
      "Epoch 297/1000\n",
      "2304/2304 [==============================] - 2s 687us/step - loss: 19703.8128 - val_loss: 16053.4814\n",
      "Epoch 298/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 19346.9465 - val_loss: 14261.0299\n",
      "Epoch 299/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 19704.9612 - val_loss: 14267.3405\n",
      "Epoch 300/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 19352.9026 - val_loss: 14148.4302\n",
      "Epoch 301/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 19498.7444 - val_loss: 14138.5259\n",
      "Epoch 302/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18726.3407 - val_loss: 15887.5956\n",
      "Epoch 303/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 19946.6447 - val_loss: 16257.2649\n",
      "Epoch 304/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 19362.7704 - val_loss: 13983.4914\n",
      "Epoch 305/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 18790.8474 - val_loss: 14023.9126\n",
      "Epoch 306/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19160.9730 - val_loss: 14827.6932\n",
      "Epoch 307/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19190.6534 - val_loss: 18906.2787\n",
      "Epoch 308/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 19401.0639 - val_loss: 14333.4869\n",
      "Epoch 309/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19238.1993 - val_loss: 19174.5764\n",
      "Epoch 310/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 20029.8387 - val_loss: 14179.8829\n",
      "Epoch 311/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 18918.1769 - val_loss: 15346.9258\n",
      "Epoch 312/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19041.3360 - val_loss: 15424.8321\n",
      "Epoch 313/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19119.5293 - val_loss: 14270.7577\n",
      "Epoch 314/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 19292.8256 - val_loss: 14625.2434\n",
      "Epoch 315/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 19020.3923 - val_loss: 15541.8373\n",
      "Epoch 316/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19109.0529 - val_loss: 14618.3543\n",
      "Epoch 317/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18554.5315 - val_loss: 14239.7411\n",
      "Epoch 318/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19012.3046 - val_loss: 14200.9190\n",
      "Epoch 319/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18846.4739 - val_loss: 14101.2692\n",
      "Epoch 320/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 18813.7599 - val_loss: 14046.8665\n",
      "Epoch 321/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18852.2364 - val_loss: 15203.3614\n",
      "Epoch 322/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 19056.3984 - val_loss: 14890.5568\n",
      "Epoch 323/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 18563.3026 - val_loss: 13836.5927\n",
      "Epoch 324/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 19340.7887 - val_loss: 14266.8893\n",
      "Epoch 325/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 19060.3305 - val_loss: 15360.9089\n",
      "Epoch 326/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18662.2458 - val_loss: 14017.1838\n",
      "Epoch 327/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 18428.4088 - val_loss: 14745.7661\n",
      "Epoch 328/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 19135.0274 - val_loss: 15207.9820\n",
      "Epoch 329/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18923.7394 - val_loss: 14965.7481\n",
      "Epoch 330/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 18535.9474 - val_loss: 17499.9861\n",
      "Epoch 331/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 19013.6725 - val_loss: 15235.5978\n",
      "Epoch 332/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 18596.5386 - val_loss: 15663.1766\n",
      "Epoch 333/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 18753.9279 - val_loss: 14441.8432\n",
      "Epoch 334/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18830.9042 - val_loss: 14302.3303\n",
      "Epoch 335/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18712.8998 - val_loss: 14407.8947\n",
      "Epoch 336/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18339.9842 - val_loss: 16368.5578\n",
      "Epoch 337/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 18322.5995 - val_loss: 14554.7695\n",
      "Epoch 338/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18302.4392 - val_loss: 18285.9036\n",
      "Epoch 339/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 18712.5002 - val_loss: 16307.5702\n",
      "Epoch 340/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18290.9863 - val_loss: 14239.9206\n",
      "Epoch 341/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18704.4309 - val_loss: 14550.0324\n",
      "Epoch 342/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18247.0918 - val_loss: 14879.0659\n",
      "Epoch 343/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 18006.7334 - val_loss: 18404.3097\n",
      "Epoch 344/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 18743.3766 - val_loss: 14351.7088\n",
      "Epoch 345/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 18354.7083 - val_loss: 13809.4760\n",
      "Epoch 346/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 18344.7377 - val_loss: 14164.0234\n",
      "Epoch 347/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17953.9372 - val_loss: 15203.0973\n",
      "Epoch 348/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 18169.8337 - val_loss: 15557.0146\n",
      "Epoch 349/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 18846.4769 - val_loss: 13736.5097\n",
      "Epoch 350/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 18310.2781 - val_loss: 15919.4781\n",
      "Epoch 351/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17808.3110 - val_loss: 16368.7301\n",
      "Epoch 352/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18350.3996 - val_loss: 14352.2247\n",
      "Epoch 353/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 18125.6151 - val_loss: 14588.8044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17982.2255 - val_loss: 15111.4960\n",
      "Epoch 355/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 18200.9428 - val_loss: 16779.2044\n",
      "Epoch 356/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17829.2466 - val_loss: 15074.7010\n",
      "Epoch 357/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 18016.9196 - val_loss: 14864.5632\n",
      "Epoch 358/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 17915.1799 - val_loss: 24316.4935\n",
      "Epoch 359/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19223.4313 - val_loss: 14180.9230\n",
      "Epoch 360/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 18647.8201 - val_loss: 13863.6924\n",
      "Epoch 361/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 18664.2566 - val_loss: 15385.2874\n",
      "Epoch 362/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17911.7704 - val_loss: 14680.4609\n",
      "Epoch 363/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 17927.6700 - val_loss: 14011.2587\n",
      "Epoch 364/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 17879.9066 - val_loss: 14464.9448\n",
      "Epoch 365/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18198.5349 - val_loss: 15854.3383\n",
      "Epoch 366/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17806.2551 - val_loss: 16639.1137\n",
      "Epoch 367/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17713.9328 - val_loss: 15978.6447\n",
      "Epoch 368/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18191.1775 - val_loss: 13860.3972\n",
      "Epoch 369/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 17839.4774 - val_loss: 16243.3496\n",
      "Epoch 370/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18056.7944 - val_loss: 13988.9696\n",
      "Epoch 371/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17830.5053 - val_loss: 13991.4631\n",
      "Epoch 372/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 17826.4593 - val_loss: 14288.8727\n",
      "Epoch 373/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18230.0502 - val_loss: 13970.4442\n",
      "Epoch 374/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18149.2701 - val_loss: 13912.5779\n",
      "Epoch 375/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17991.8544 - val_loss: 14408.1569\n",
      "Epoch 376/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17852.9588 - val_loss: 13976.1019\n",
      "Epoch 377/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17220.9854 - val_loss: 14601.7443\n",
      "Epoch 378/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 18052.9831 - val_loss: 14810.8670\n",
      "Epoch 379/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 17936.4085 - val_loss: 15385.9314\n",
      "Epoch 380/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17604.2571 - val_loss: 22286.7142\n",
      "Epoch 381/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18617.3345 - val_loss: 16034.6185\n",
      "Epoch 382/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17403.8869 - val_loss: 14999.4376\n",
      "Epoch 383/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17939.8127 - val_loss: 14766.4007\n",
      "Epoch 384/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 18240.0339 - val_loss: 14057.3904\n",
      "Epoch 385/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 17869.7416 - val_loss: 17336.3759\n",
      "Epoch 386/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17826.6345 - val_loss: 15285.4909\n",
      "Epoch 387/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17667.2922 - val_loss: 14430.3984\n",
      "Epoch 388/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 17571.7256 - val_loss: 14216.6904\n",
      "Epoch 389/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 17352.5210 - val_loss: 13842.0403\n",
      "Epoch 390/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17804.1591 - val_loss: 14489.6196\n",
      "Epoch 391/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17290.5272 - val_loss: 15556.0982\n",
      "Epoch 392/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17562.2438 - val_loss: 14057.2289\n",
      "Epoch 393/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17475.4925 - val_loss: 14393.1716\n",
      "Epoch 394/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 17683.2711 - val_loss: 13867.6408\n",
      "Epoch 395/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18206.1145 - val_loss: 14119.2243\n",
      "Epoch 396/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17573.8009 - val_loss: 14654.6191\n",
      "Epoch 397/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17220.1603 - val_loss: 17501.2350\n",
      "Epoch 398/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17444.1953 - val_loss: 15443.5200\n",
      "Epoch 399/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17212.9262 - val_loss: 14271.1408\n",
      "Epoch 400/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18024.3335 - val_loss: 14294.3726\n",
      "Epoch 401/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17486.2469 - val_loss: 13969.2431\n",
      "Epoch 402/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17356.3129 - val_loss: 14932.2968\n",
      "Epoch 403/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17733.6313 - val_loss: 15349.2541\n",
      "Epoch 404/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17096.2496 - val_loss: 14960.6332\n",
      "Epoch 405/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17120.7252 - val_loss: 14787.6082\n",
      "Epoch 406/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 17491.6736 - val_loss: 19178.5432\n",
      "Epoch 407/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17724.7867 - val_loss: 14122.0443\n",
      "Epoch 408/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17579.8739 - val_loss: 14003.0985\n",
      "Epoch 409/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17608.8391 - val_loss: 17843.3101\n",
      "Epoch 410/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17523.1099 - val_loss: 14959.4707\n",
      "Epoch 411/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16910.8874 - val_loss: 13747.2737\n",
      "Epoch 412/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17539.3152 - val_loss: 14720.9098\n",
      "Epoch 413/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17267.5506 - val_loss: 14258.4516\n",
      "Epoch 414/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17315.9268 - val_loss: 13593.2258\n",
      "Epoch 415/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17380.5531 - val_loss: 14079.7826\n",
      "Epoch 416/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16996.8228 - val_loss: 15113.6179\n",
      "Epoch 417/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17600.8175 - val_loss: 18986.0353\n",
      "Epoch 418/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17023.1818 - val_loss: 14341.5397\n",
      "Epoch 419/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17573.1886 - val_loss: 14370.9430\n",
      "Epoch 420/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17225.8739 - val_loss: 15407.3638\n",
      "Epoch 421/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17412.0493 - val_loss: 19036.0672\n",
      "Epoch 422/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17108.0607 - val_loss: 15606.9727\n",
      "Epoch 423/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17136.4948 - val_loss: 15391.9444\n",
      "Epoch 424/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17093.5108 - val_loss: 14448.2228\n",
      "Epoch 425/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16837.8037 - val_loss: 16118.2474\n",
      "Epoch 426/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17296.2004 - val_loss: 13944.9400\n",
      "Epoch 427/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17272.2626 - val_loss: 13772.1651\n",
      "Epoch 428/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17281.5558 - val_loss: 13642.4159\n",
      "Epoch 429/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17101.2987 - val_loss: 15898.3358\n",
      "Epoch 430/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16709.3143 - val_loss: 19334.2600\n",
      "Epoch 431/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 16868.6854 - val_loss: 16250.8959\n",
      "Epoch 432/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17385.3112 - val_loss: 13705.7346\n",
      "Epoch 433/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17247.9291 - val_loss: 14623.1077\n",
      "Epoch 434/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17188.4737 - val_loss: 13852.3366\n",
      "Epoch 435/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16656.4663 - val_loss: 14797.9058\n",
      "Epoch 436/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 17156.8052 - val_loss: 13735.2475\n",
      "Epoch 437/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 17050.5127 - val_loss: 17040.0685\n",
      "Epoch 438/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16785.3803 - val_loss: 15292.6484\n",
      "Epoch 439/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16491.9697 - val_loss: 15786.6080\n",
      "Epoch 440/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17464.6337 - val_loss: 15852.0196\n",
      "Epoch 441/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17213.6505 - val_loss: 15082.6042\n",
      "Epoch 442/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17345.8611 - val_loss: 14912.8041\n",
      "Epoch 443/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16981.0900 - val_loss: 18065.5751\n",
      "Epoch 444/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 17532.0109 - val_loss: 16386.4432\n",
      "Epoch 445/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17591.5213 - val_loss: 14487.9600\n",
      "Epoch 446/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17624.2621 - val_loss: 16752.8077\n",
      "Epoch 447/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16998.9168 - val_loss: 13496.9836\n",
      "Epoch 448/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 16836.7056 - val_loss: 14631.2539\n",
      "Epoch 449/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16696.3389 - val_loss: 16631.2494\n",
      "Epoch 450/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16983.9090 - val_loss: 15312.0523\n",
      "Epoch 451/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16810.2610 - val_loss: 14278.9533\n",
      "Epoch 452/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17404.3263 - val_loss: 15086.4043\n",
      "Epoch 453/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17100.2959 - val_loss: 13936.6329\n",
      "Epoch 454/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16667.1507 - val_loss: 18293.9448\n",
      "Epoch 455/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 17168.9288- ETA: 0s - - 1s 438us/step - loss: 17086.7000 - val_loss: 13579.2260\n",
      "Epoch 456/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16701.5239 - val_loss: 14569.9128\n",
      "Epoch 457/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16879.7268 - val_loss: 13863.3398\n",
      "Epoch 458/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 16426.4349 - val_loss: 17490.6424\n",
      "Epoch 459/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 17047.0664 - val_loss: 14906.5276\n",
      "Epoch 460/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 17470.8861 - val_loss: 14052.3652\n",
      "Epoch 461/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16674.0154 - val_loss: 17727.5517\n",
      "Epoch 462/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17145.5984 - val_loss: 14692.3786\n",
      "Epoch 463/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17166.9755 - val_loss: 14124.9136\n",
      "Epoch 464/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16679.6169 - val_loss: 19373.4150\n",
      "Epoch 465/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 16774.5541 - val_loss: 14200.0199\n",
      "Epoch 466/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16595.9005 - val_loss: 14423.6457\n",
      "Epoch 467/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16689.2204 - val_loss: 14240.4985\n",
      "Epoch 468/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16708.0954 - val_loss: 14334.9017\n",
      "Epoch 469/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 17191.4972 - val_loss: 13775.6621\n",
      "Epoch 470/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17505.5673 - val_loss: 13765.9852\n",
      "Epoch 471/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 17377.3753 - val_loss: 16874.4895\n",
      "Epoch 472/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16932.0075 - val_loss: 15280.1072\n",
      "Epoch 473/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16530.4014 - val_loss: 14520.9200\n",
      "Epoch 474/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17395.5364 - val_loss: 13848.9501\n",
      "Epoch 475/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16857.5059 - val_loss: 13565.6380\n",
      "Epoch 476/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 16767.7075 - val_loss: 19872.7868\n",
      "Epoch 477/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16884.9123 - val_loss: 13176.7210\n",
      "Epoch 478/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16330.7191 - val_loss: 14813.3151\n",
      "Epoch 479/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 16560.1846 - val_loss: 13560.4959\n",
      "Epoch 480/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 16994.8374 - val_loss: 13748.0220\n",
      "Epoch 481/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 17105.0768 - val_loss: 13977.5572\n",
      "Epoch 482/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 16926.7186 - val_loss: 15421.4735\n",
      "Epoch 483/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 17416.383 - 1s 442us/step - loss: 17520.7117 - val_loss: 14974.8713\n",
      "Epoch 484/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17241.7099 - val_loss: 16109.2987\n",
      "Epoch 485/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 16878.6128 - val_loss: 13340.2037\n",
      "Epoch 486/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 16567.2597 - val_loss: 13226.7989\n",
      "Epoch 487/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17009.0485 - val_loss: 14334.8273\n",
      "Epoch 488/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17224.3196 - val_loss: 15182.8221\n",
      "Epoch 489/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16113.3428 - val_loss: 14707.3002\n",
      "Epoch 490/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16157.4614 - val_loss: 17262.7748\n",
      "Epoch 491/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16754.3682 - val_loss: 17514.4146\n",
      "Epoch 492/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16435.4573 - val_loss: 13711.0666\n",
      "Epoch 493/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17039.9159 - val_loss: 15920.7148\n",
      "Epoch 494/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 1s 443us/step - loss: 16618.5890 - val_loss: 13543.7893\n",
      "Epoch 495/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17146.2448 - val_loss: 18693.5495\n",
      "Epoch 496/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16916.5060 - val_loss: 13491.6188\n",
      "Epoch 497/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16322.7569 - val_loss: 14055.7516\n",
      "Epoch 498/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16738.7356 - val_loss: 13729.1235\n",
      "Epoch 499/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17037.1458 - val_loss: 19032.3017\n",
      "Epoch 500/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17037.1399 - val_loss: 13309.6670\n",
      "Epoch 501/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16405.3647 - val_loss: 13464.1638\n",
      "Epoch 502/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 17211.2725 - val_loss: 17083.4213\n",
      "Epoch 503/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 17172.4802 - val_loss: 13478.5523\n",
      "Epoch 504/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16247.5303 - val_loss: 14198.8873\n",
      "Epoch 505/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16671.5918 - val_loss: 13535.8521\n",
      "Epoch 506/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16185.6086 - val_loss: 14095.6265\n",
      "Epoch 507/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16207.7347 - val_loss: 14325.4418\n",
      "Epoch 508/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16652.1647 - val_loss: 14851.3673\n",
      "Epoch 509/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 16606.8829 - val_loss: 14483.6561\n",
      "Epoch 510/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16154.6917 - val_loss: 13027.8321\n",
      "Epoch 511/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 16352.7531 - val_loss: 13074.6578\n",
      "Epoch 512/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16269.5398 - val_loss: 15614.6946\n",
      "Epoch 513/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16844.1695 - val_loss: 13532.4958\n",
      "Epoch 514/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16391.5720 - val_loss: 13839.0900\n",
      "Epoch 515/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16910.4774 - val_loss: 13006.5320\n",
      "Epoch 516/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16441.9044 - val_loss: 13741.3823\n",
      "Epoch 517/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16175.2031 - val_loss: 13118.6830\n",
      "Epoch 518/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16029.5415 - val_loss: 13535.7123\n",
      "Epoch 519/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16822.5800 - val_loss: 12918.1999\n",
      "Epoch 520/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16400.1417 - val_loss: 13436.6186\n",
      "Epoch 521/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 16581.6498 - val_loss: 13149.8857\n",
      "Epoch 522/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16398.8991 - val_loss: 13370.1782\n",
      "Epoch 523/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16296.1482 - val_loss: 16340.5884\n",
      "Epoch 524/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16327.9647 - val_loss: 13298.2406\n",
      "Epoch 525/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16280.1426 - val_loss: 13291.0479\n",
      "Epoch 526/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16098.8848 - val_loss: 13626.7445\n",
      "Epoch 527/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16265.7438 - val_loss: 13826.5380\n",
      "Epoch 528/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15989.9011 - val_loss: 14713.3395\n",
      "Epoch 529/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15569.1148 - val_loss: 13209.5831\n",
      "Epoch 530/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16541.1532 - val_loss: 17341.2461\n",
      "Epoch 531/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16239.2389 - val_loss: 13829.2114\n",
      "Epoch 532/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16521.4224 - val_loss: 15856.1819\n",
      "Epoch 533/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15968.5748 - val_loss: 12955.7784\n",
      "Epoch 534/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 16293.7703 - val_loss: 13159.6920\n",
      "Epoch 535/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15915.4719 - val_loss: 15236.5337\n",
      "Epoch 536/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16546.5183 - val_loss: 16853.1425\n",
      "Epoch 537/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16415.3709 - val_loss: 22590.1958\n",
      "Epoch 538/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16038.1731 - val_loss: 15478.0320\n",
      "Epoch 539/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16662.2867 - val_loss: 13633.4050\n",
      "Epoch 540/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16813.9251 - val_loss: 12660.4432\n",
      "Epoch 541/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 16527.9992 - val_loss: 14913.9604\n",
      "Epoch 542/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 16079.3291 - val_loss: 13788.1918\n",
      "Epoch 543/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16225.2902 - val_loss: 14426.3797\n",
      "Epoch 544/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 15732.6024 - val_loss: 13636.5850\n",
      "Epoch 545/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16214.2543 - val_loss: 21259.3888\n",
      "Epoch 546/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 16336.5275 - val_loss: 13642.9841\n",
      "Epoch 547/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16242.7494 - val_loss: 12891.3443\n",
      "Epoch 548/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15609.3064 - val_loss: 15241.3289\n",
      "Epoch 549/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 16055.6001 - val_loss: 15129.6870\n",
      "Epoch 550/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 16056.1482 - val_loss: 13194.1173\n",
      "Epoch 551/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16373.1419 - val_loss: 13835.9007\n",
      "Epoch 552/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 16585.9757 - val_loss: 15642.5804\n",
      "Epoch 553/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 16268.6899 - val_loss: 12619.5854\n",
      "Epoch 554/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16432.3227 - val_loss: 14910.7167\n",
      "Epoch 555/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15964.3666 - val_loss: 13346.9381\n",
      "Epoch 556/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15907.5030 - val_loss: 12983.0486\n",
      "Epoch 557/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15918.8584 - val_loss: 13650.5844\n",
      "Epoch 558/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16200.4612 - val_loss: 12951.2539\n",
      "Epoch 559/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15835.6661 - val_loss: 14813.2323\n",
      "Epoch 560/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16570.0578 - val_loss: 14454.0631\n",
      "Epoch 561/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16869.6169 - val_loss: 13610.7718\n",
      "Epoch 562/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16840.4261 - val_loss: 13181.9136\n",
      "Epoch 563/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15979.8033 - val_loss: 13446.4118\n",
      "Epoch 564/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15563.6671 - val_loss: 13199.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15908.4225 - val_loss: 15984.1726\n",
      "Epoch 566/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16004.9399 - val_loss: 13905.7834\n",
      "Epoch 567/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16389.2974 - val_loss: 13452.7645\n",
      "Epoch 568/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15584.9971 - val_loss: 14775.5267\n",
      "Epoch 569/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15664.2811 - val_loss: 13648.0294\n",
      "Epoch 570/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16375.2549 - val_loss: 13240.0203\n",
      "Epoch 571/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15903.5278 - val_loss: 14575.3229\n",
      "Epoch 572/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16540.2915 - val_loss: 12986.2193\n",
      "Epoch 573/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15546.8738 - val_loss: 12724.5387\n",
      "Epoch 574/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15573.6981 - val_loss: 14370.9492\n",
      "Epoch 575/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15998.9777 - val_loss: 14381.9216\n",
      "Epoch 576/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 16236.6067 - val_loss: 13139.3926\n",
      "Epoch 577/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16401.3169 - val_loss: 12909.4291\n",
      "Epoch 578/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 15951.6085 - val_loss: 13372.4539\n",
      "Epoch 579/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15390.301 - 1s 447us/step - loss: 15447.2109 - val_loss: 16080.7027\n",
      "Epoch 580/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15932.6666 - val_loss: 13824.2292\n",
      "Epoch 581/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15664.1162 - val_loss: 14778.0713\n",
      "Epoch 582/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15933.7029 - val_loss: 13003.9517\n",
      "Epoch 583/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15956.3189 - val_loss: 16177.6614\n",
      "Epoch 584/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15874.3583 - val_loss: 13080.2921\n",
      "Epoch 585/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16791.4277 - val_loss: 14088.6852\n",
      "Epoch 586/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15705.0799 - val_loss: 18454.0310\n",
      "Epoch 587/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15808.1309 - val_loss: 16820.5833\n",
      "Epoch 588/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 16183.8922 - val_loss: 14711.2256\n",
      "Epoch 589/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15707.8248 - val_loss: 13111.5689\n",
      "Epoch 590/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16598.3475 - val_loss: 15295.8216\n",
      "Epoch 591/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15327.5790 - val_loss: 13901.1989\n",
      "Epoch 592/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15704.7646 - val_loss: 13032.4837\n",
      "Epoch 593/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15951.6286 - val_loss: 13004.5162\n",
      "Epoch 594/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 15690.0711 - val_loss: 12766.9858\n",
      "Epoch 595/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15764.8322 - val_loss: 14098.1799\n",
      "Epoch 596/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 16039.9761 - val_loss: 14123.3657\n",
      "Epoch 597/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16197.0552 - val_loss: 13257.4783\n",
      "Epoch 598/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15653.8917 - val_loss: 13044.1128\n",
      "Epoch 599/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 16027.9724 - val_loss: 14400.0111\n",
      "Epoch 600/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 15569.4053 - val_loss: 14585.1445\n",
      "Epoch 601/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16236.5629 - val_loss: 14213.7991\n",
      "Epoch 602/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15410.8726 - val_loss: 13744.9428\n",
      "Epoch 603/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15623.0107 - val_loss: 13769.4555\n",
      "Epoch 604/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15422.4580 - val_loss: 13720.9273\n",
      "Epoch 605/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15629.3536 - val_loss: 13780.4440\n",
      "Epoch 606/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15512.328 - 1s 449us/step - loss: 15667.5894 - val_loss: 15107.2038\n",
      "Epoch 607/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15842.8541 - val_loss: 15396.6564\n",
      "Epoch 608/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16343.3226 - val_loss: 16418.3831\n",
      "Epoch 609/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15627.2895 - val_loss: 13080.5057\n",
      "Epoch 610/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 16138.2899 - val_loss: 13839.8605\n",
      "Epoch 611/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15795.7646 - val_loss: 14323.5030\n",
      "Epoch 612/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16000.4406 - val_loss: 14379.4820\n",
      "Epoch 613/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15908.1178 - val_loss: 12850.5682\n",
      "Epoch 614/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16145.5608 - val_loss: 13584.1879\n",
      "Epoch 615/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15431.5824 - val_loss: 13392.1331\n",
      "Epoch 616/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16703.4658 - val_loss: 14792.3624\n",
      "Epoch 617/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15772.0554 - val_loss: 15436.8464\n",
      "Epoch 618/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15374.9280 - val_loss: 13229.2396\n",
      "Epoch 619/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15145.3295 - val_loss: 14809.5443\n",
      "Epoch 620/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15543.2908 - val_loss: 16547.6276\n",
      "Epoch 621/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15959.9643 - val_loss: 16376.9515\n",
      "Epoch 622/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15781.9054 - val_loss: 15017.2809\n",
      "Epoch 623/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15574.1608 - val_loss: 12977.8039\n",
      "Epoch 624/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15664.0746 - val_loss: 16512.8301\n",
      "Epoch 625/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15434.6600 - val_loss: 13110.2442\n",
      "Epoch 626/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15833.0265 - val_loss: 13771.7392\n",
      "Epoch 627/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15141.2832 - val_loss: 12895.8720\n",
      "Epoch 628/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15806.2560 - val_loss: 12599.8844\n",
      "Epoch 629/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 15253.5951 - val_loss: 15702.9138\n",
      "Epoch 630/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 16220.005 - 1s 446us/step - loss: 16211.7160 - val_loss: 13587.7423\n",
      "Epoch 631/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15374.0106 - val_loss: 16109.5302\n",
      "Epoch 632/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15973.8315 - val_loss: 14559.4370\n",
      "Epoch 633/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15757.8239 - val_loss: 14605.0098\n",
      "Epoch 634/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15382.4610 - val_loss: 15446.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 635/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15981.6069 - val_loss: 14574.5966\n",
      "Epoch 636/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15255.1359 - val_loss: 16051.3238\n",
      "Epoch 637/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15448.6940 - val_loss: 13010.1859\n",
      "Epoch 638/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15537.2544 - val_loss: 14263.5028\n",
      "Epoch 639/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15717.0864 - val_loss: 13682.7131\n",
      "Epoch 640/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15358.8598 - val_loss: 13410.3975\n",
      "Epoch 641/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15642.4729 - val_loss: 13778.9329\n",
      "Epoch 642/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16350.4903 - val_loss: 21586.3186\n",
      "Epoch 643/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15697.2444 - val_loss: 13705.7611\n",
      "Epoch 644/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15046.5153 - val_loss: 16719.6757\n",
      "Epoch 645/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15784.5210 - val_loss: 13796.9106\n",
      "Epoch 646/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15669.4205 - val_loss: 12644.5263\n",
      "Epoch 647/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15642.5598 - val_loss: 13163.1053\n",
      "Epoch 648/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15469.4455 - val_loss: 14157.4993\n",
      "Epoch 649/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15148.3762 - val_loss: 12870.2361\n",
      "Epoch 650/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15614.2960 - val_loss: 12830.4788\n",
      "Epoch 651/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15455.5890 - val_loss: 14309.9376\n",
      "Epoch 652/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15504.0487 - val_loss: 12620.4909\n",
      "Epoch 653/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15521.0770 - val_loss: 13617.4397\n",
      "Epoch 654/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15487.8799 - val_loss: 13259.1685\n",
      "Epoch 655/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15204.8147 - val_loss: 13958.5722\n",
      "Epoch 656/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15702.2916 - val_loss: 13165.9372\n",
      "Epoch 657/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15200.5446 - val_loss: 14146.9903\n",
      "Epoch 658/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 15479.8287 - val_loss: 13355.3974\n",
      "Epoch 659/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15440.6843 - val_loss: 13331.1294\n",
      "Epoch 660/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 15174.4019 - val_loss: 12858.8573\n",
      "Epoch 661/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15110.9219 - val_loss: 12799.9921\n",
      "Epoch 662/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15598.324 - 1s 448us/step - loss: 15515.2419 - val_loss: 12942.6975\n",
      "Epoch 663/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16275.1000 - val_loss: 16717.4047\n",
      "Epoch 664/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16169.6125 - val_loss: 12684.8459\n",
      "Epoch 665/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15119.5771 - val_loss: 17778.7259\n",
      "Epoch 666/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15477.4023 - val_loss: 13685.2982\n",
      "Epoch 667/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15982.5753 - val_loss: 14503.3253\n",
      "Epoch 668/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15682.8486 - val_loss: 15272.2460\n",
      "Epoch 669/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15223.0342 - val_loss: 12861.6631\n",
      "Epoch 670/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 15199.3037 - val_loss: 12720.9584\n",
      "Epoch 671/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15367.5364 - val_loss: 12661.7466\n",
      "Epoch 672/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15171.9637 - val_loss: 13398.3861\n",
      "Epoch 673/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15272.5848 - val_loss: 13891.8174\n",
      "Epoch 674/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 15364.4168 - val_loss: 13129.6698\n",
      "Epoch 675/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15352.5513 - val_loss: 13137.0173\n",
      "Epoch 676/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15420.8494 - val_loss: 14306.8728\n",
      "Epoch 677/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15816.9606 - val_loss: 13225.2205\n",
      "Epoch 678/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15520.9441 - val_loss: 12961.2857\n",
      "Epoch 679/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16166.1388 - val_loss: 13093.5504\n",
      "Epoch 680/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15809.7020 - val_loss: 12755.8231\n",
      "Epoch 681/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15275.4096 - val_loss: 14574.4372\n",
      "Epoch 682/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15262.1467 - val_loss: 15008.6220\n",
      "Epoch 683/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15541.8515 - val_loss: 12507.0198\n",
      "Epoch 684/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 15458.2967 - val_loss: 12919.8445\n",
      "Epoch 685/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15089.8102 - val_loss: 13483.9403\n",
      "Epoch 686/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15078.7916 - val_loss: 13308.9251\n",
      "Epoch 687/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14969.1277 - val_loss: 15465.7025\n",
      "Epoch 688/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15335.7592 - val_loss: 12952.5697\n",
      "Epoch 689/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15527.9751 - val_loss: 17052.4783\n",
      "Epoch 690/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15339.5878 - val_loss: 14415.3618\n",
      "Epoch 691/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15469.8665 - val_loss: 14247.9914\n",
      "Epoch 692/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15702.3830 - val_loss: 17907.0751\n",
      "Epoch 693/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15765.4085 - val_loss: 13254.7512\n",
      "Epoch 694/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15332.0656 - val_loss: 18456.6299\n",
      "Epoch 695/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15447.8551 - val_loss: 12613.2257\n",
      "Epoch 696/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14687.8422 - val_loss: 13083.2457\n",
      "Epoch 697/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15330.3883 - val_loss: 18014.6404\n",
      "Epoch 698/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15781.9598 - val_loss: 16162.5326\n",
      "Epoch 699/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15493.8309 - val_loss: 17285.5977\n",
      "Epoch 700/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15423.0763 - val_loss: 12625.9207\n",
      "Epoch 701/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15297.0811 - val_loss: 13373.4003\n",
      "Epoch 702/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15426.0078 - val_loss: 13488.4394\n",
      "Epoch 703/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15466.9557 - val_loss: 14845.1572\n",
      "Epoch 704/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15065.8811 - val_loss: 12732.2395\n",
      "Epoch 705/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15026.7516 - val_loss: 13223.4333\n",
      "Epoch 706/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15230.2854 - val_loss: 14756.2749\n",
      "Epoch 707/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15406.9381 - val_loss: 13308.5025\n",
      "Epoch 708/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15260.3629 - val_loss: 18116.0258\n",
      "Epoch 709/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15283.3038 - val_loss: 13337.3922\n",
      "Epoch 710/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15137.5314 - val_loss: 13265.3038\n",
      "Epoch 711/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15759.4561 - val_loss: 14528.8233\n",
      "Epoch 712/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15241.5850 - val_loss: 12762.3783\n",
      "Epoch 713/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14968.4679 - val_loss: 13901.8424\n",
      "Epoch 714/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15471.8470 - val_loss: 13121.6925\n",
      "Epoch 715/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15340.8782 - val_loss: 16421.3447\n",
      "Epoch 716/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15203.0577 - val_loss: 13425.4123\n",
      "Epoch 717/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15364.1613 - val_loss: 14678.5288\n",
      "Epoch 718/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15190.8276 - val_loss: 13293.1317\n",
      "Epoch 719/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15485.2657 - val_loss: 16684.7799\n",
      "Epoch 720/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16062.7201 - val_loss: 12756.5438\n",
      "Epoch 721/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15582.1366 - val_loss: 13934.6589\n",
      "Epoch 722/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14930.4560 - val_loss: 14532.9120\n",
      "Epoch 723/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15068.7575 - val_loss: 12634.7672\n",
      "Epoch 724/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15363.4014 - val_loss: 13434.6976\n",
      "Epoch 725/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15257.4327 - val_loss: 18779.9918\n",
      "Epoch 726/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15877.7786 - val_loss: 13005.0797\n",
      "Epoch 727/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15261.8529 - val_loss: 12943.7489\n",
      "Epoch 728/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15631.8654 - val_loss: 12685.7935\n",
      "Epoch 729/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15082.9631 - val_loss: 12853.9259\n",
      "Epoch 730/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14789.6620 - val_loss: 13291.1079\n",
      "Epoch 731/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14779.1322 - val_loss: 12923.7221\n",
      "Epoch 732/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14957.5461 - val_loss: 14639.1517\n",
      "Epoch 733/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15424.5130 - val_loss: 12906.5334\n",
      "Epoch 734/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15092.7149 - val_loss: 12938.7308\n",
      "Epoch 735/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14993.9403 - val_loss: 13545.9049\n",
      "Epoch 736/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 14567.7017 - val_loss: 13553.1889\n",
      "Epoch 737/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 15193.0467 - val_loss: 16555.1944\n",
      "Epoch 738/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15208.2199 - val_loss: 13473.8713\n",
      "Epoch 739/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15558.0719 - val_loss: 13306.9156\n",
      "Epoch 740/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15205.8590 - val_loss: 13603.1274\n",
      "Epoch 741/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14711.1822 - val_loss: 17975.5598\n",
      "Epoch 742/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15439.0352 - val_loss: 18252.7317\n",
      "Epoch 743/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14858.0257 - val_loss: 13080.7335\n",
      "Epoch 744/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15334.4735 - val_loss: 12367.6314\n",
      "Epoch 745/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15592.4208 - val_loss: 12456.6742\n",
      "Epoch 746/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15372.3296 - val_loss: 13681.8867\n",
      "Epoch 747/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15552.5056 - val_loss: 13359.9924\n",
      "Epoch 748/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15025.2245 - val_loss: 13198.7190\n",
      "Epoch 749/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15587.6711 - val_loss: 13291.3897\n",
      "Epoch 750/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15234.3599 - val_loss: 13104.8654\n",
      "Epoch 751/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15286.4515 - val_loss: 13389.0263\n",
      "Epoch 752/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15011.1919 - val_loss: 13671.0663\n",
      "Epoch 753/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 14678.4676 - val_loss: 13171.7875\n",
      "Epoch 754/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 14898.6622 - val_loss: 16745.6186\n",
      "Epoch 755/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14864.0150 - val_loss: 14502.9875\n",
      "Epoch 756/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 14996.6706 - val_loss: 14170.1225\n",
      "Epoch 757/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14958.4556 - val_loss: 13103.1940\n",
      "Epoch 758/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14827.0645 - val_loss: 12728.4479\n",
      "Epoch 759/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15163.0861 - val_loss: 13287.7952\n",
      "Epoch 760/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14740.0526 - val_loss: 12897.9880\n",
      "Epoch 761/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14966.5553 - val_loss: 13621.3832\n",
      "Epoch 762/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14799.1578 - val_loss: 14286.3744\n",
      "Epoch 763/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14436.9415 - val_loss: 13498.1127\n",
      "Epoch 764/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15144.7726 - val_loss: 12865.2890\n",
      "Epoch 765/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15369.3907 - val_loss: 13159.7846\n",
      "Epoch 766/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14932.8306 - val_loss: 13319.9050\n",
      "Epoch 767/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14700.5915 - val_loss: 12496.0247\n",
      "Epoch 768/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14422.4766 - val_loss: 12903.3622\n",
      "Epoch 769/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 14772.8422 - val_loss: 12729.0690\n",
      "Epoch 770/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15411.607 - 1s 442us/step - loss: 15346.0232 - val_loss: 14042.6256\n",
      "Epoch 771/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15231.9011 - val_loss: 13969.7030\n",
      "Epoch 772/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15155.9134 - val_loss: 14454.8772\n",
      "Epoch 773/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 15267.4308 - val_loss: 13259.2004\n",
      "Epoch 774/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14596.1594 - val_loss: 13166.8524\n",
      "Epoch 775/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 1s 420us/step - loss: 14974.0176 - val_loss: 15539.5823\n",
      "Epoch 776/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15169.9119 - val_loss: 13228.7943\n",
      "Epoch 777/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14630.1758 - val_loss: 13663.6288\n",
      "Epoch 778/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 14674.2638 - val_loss: 12558.5938\n",
      "Epoch 779/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14920.9787 - val_loss: 13532.3238\n",
      "Epoch 780/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 15182.5596 - val_loss: 15951.0021\n",
      "Epoch 781/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14665.4194 - val_loss: 12908.2029\n",
      "Epoch 782/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14690.0533 - val_loss: 14167.9302\n",
      "Epoch 783/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14653.5695 - val_loss: 17030.5262\n",
      "Epoch 784/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15122.4909 - val_loss: 12568.5641\n",
      "Epoch 785/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15265.6583 - val_loss: 12658.0560\n",
      "Epoch 786/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 14948.2878 - val_loss: 13892.8752\n",
      "Epoch 787/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14933.4436 - val_loss: 14457.1670\n",
      "Epoch 788/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15085.2040 - val_loss: 13747.4289\n",
      "Epoch 789/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15379.0492 - val_loss: 19403.6576\n",
      "Epoch 790/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 15351.0965 - val_loss: 15456.3321\n",
      "Epoch 791/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14805.4371 - val_loss: 12852.0827\n",
      "Epoch 792/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14794.1490 - val_loss: 12984.7817\n",
      "Epoch 793/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 14434.4702 - val_loss: 12845.6965\n",
      "Epoch 794/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 14672.0893 - val_loss: 13594.8156\n",
      "Epoch 795/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 14665.5351 - val_loss: 13367.0068\n",
      "Epoch 796/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14691.3304 - val_loss: 12902.3428\n",
      "Epoch 797/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15322.3794 - val_loss: 13206.3453\n",
      "Epoch 798/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14591.8013 - val_loss: 12691.5457\n",
      "Epoch 799/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14238.9320 - val_loss: 12883.0565\n",
      "Epoch 800/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14562.4019 - val_loss: 13239.7346\n",
      "Epoch 801/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14895.1009 - val_loss: 12925.1134\n",
      "Epoch 802/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14640.8927 - val_loss: 12759.0829\n",
      "Epoch 803/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14646.1457 - val_loss: 12718.9311\n",
      "Epoch 804/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14635.7928 - val_loss: 12636.7899\n",
      "Epoch 805/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 13996.3517 - val_loss: 14381.3851\n",
      "Epoch 806/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14318.8125 - val_loss: 15468.8791\n",
      "Epoch 807/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14880.0421 - val_loss: 13126.8431\n",
      "Epoch 808/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15080.8034 - val_loss: 14136.3962\n",
      "Epoch 809/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15469.5417 - val_loss: 12694.9700\n",
      "Epoch 810/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14256.0116 - val_loss: 12779.1585\n",
      "Epoch 811/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 15062.1193 - val_loss: 13845.3082\n",
      "Epoch 812/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14080.0018 - val_loss: 13449.0193\n",
      "Epoch 813/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14612.0249 - val_loss: 13226.6961\n",
      "Epoch 814/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14793.5876 - val_loss: 12672.4397\n",
      "Epoch 815/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14473.2528 - val_loss: 12693.7991\n",
      "Epoch 816/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 14533.8183 - val_loss: 13692.2471\n",
      "Epoch 817/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14729.4543 - val_loss: 13083.3531\n",
      "Epoch 818/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14497.7936 - val_loss: 13903.4400\n",
      "Epoch 819/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14109.7411 - val_loss: 13386.7339\n",
      "Epoch 820/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14994.6687 - val_loss: 14384.5567\n",
      "Epoch 821/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14667.1439 - val_loss: 16717.5792\n",
      "Epoch 822/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 15194.1799 - val_loss: 12673.5339\n",
      "Epoch 823/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14383.1840 - val_loss: 13179.6093\n",
      "Epoch 824/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14762.0785 - val_loss: 12920.0712\n",
      "Epoch 825/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14621.4354 - val_loss: 13191.5815\n",
      "Epoch 826/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14784.9669 - val_loss: 12863.7764\n",
      "Epoch 827/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14490.9969 - val_loss: 12752.3748\n",
      "Epoch 828/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14351.1834 - val_loss: 12576.6446\n",
      "Epoch 829/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 15036.8720 - val_loss: 12418.5804\n",
      "Epoch 830/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14464.0178 - val_loss: 12871.3090\n",
      "Epoch 831/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14654.7483 - val_loss: 13201.5221\n",
      "Epoch 832/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14462.2237 - val_loss: 13925.0163\n",
      "Epoch 833/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14949.5650 - val_loss: 13039.8272\n",
      "Epoch 834/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14270.4275 - val_loss: 12572.5281\n",
      "Epoch 835/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14900.3856 - val_loss: 12620.9649\n",
      "Epoch 836/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14709.6670 - val_loss: 12989.1388\n",
      "Epoch 837/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14657.4319 - val_loss: 13228.2369\n",
      "Epoch 838/1000\n",
      "2304/2304 [==============================] - 1s 472us/step - loss: 14724.9100 - val_loss: 12757.6617\n",
      "Epoch 839/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14601.4974 - val_loss: 12417.1430\n",
      "Epoch 840/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14986.3101 - val_loss: 17222.0426\n",
      "Epoch 841/1000\n",
      "2304/2304 [==============================] - 1s 411us/step - loss: 15089.0709 - val_loss: 12555.9500\n",
      "Epoch 842/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14993.7458 - val_loss: 14066.9829\n",
      "Epoch 843/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14532.6220 - val_loss: 18880.1531\n",
      "Epoch 844/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14584.9105 - val_loss: 13635.9832\n",
      "Epoch 845/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14396.5144 - val_loss: 12778.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 846/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14060.4311 - val_loss: 13225.5006\n",
      "Epoch 847/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14654.3758 - val_loss: 13023.3650\n",
      "Epoch 848/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14654.8375 - val_loss: 13103.5657\n",
      "Epoch 849/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 14830.6239 - val_loss: 13058.2414\n",
      "Epoch 850/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14764.2105 - val_loss: 13815.4281\n",
      "Epoch 851/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14613.9552 - val_loss: 13237.9735\n",
      "Epoch 852/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14611.7756 - val_loss: 13520.5362\n",
      "Epoch 853/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14431.8364 - val_loss: 13894.3668\n",
      "Epoch 854/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 15137.1521 - val_loss: 22284.5248\n",
      "Epoch 855/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14813.4715 - val_loss: 13260.7255\n",
      "Epoch 856/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14475.8784 - val_loss: 13210.7836\n",
      "Epoch 857/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 14933.4577 - val_loss: 12749.1952\n",
      "Epoch 858/1000\n",
      "2304/2304 [==============================] - 1s 412us/step - loss: 14291.2518 - val_loss: 14971.0328\n",
      "Epoch 859/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15208.3715 - val_loss: 15258.7614\n",
      "Epoch 860/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14987.8951 - val_loss: 13586.2548\n",
      "Epoch 861/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14492.0720 - val_loss: 17675.6073\n",
      "Epoch 862/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 14506.5116 - val_loss: 12518.2817\n",
      "Epoch 863/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14188.5038 - val_loss: 13342.0729\n",
      "Epoch 864/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15359.8370 - val_loss: 16495.8379\n",
      "Epoch 865/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14965.1403 - val_loss: 13083.3793\n",
      "Epoch 866/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14175.7473 - val_loss: 13919.3206\n",
      "Epoch 867/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14389.9764 - val_loss: 13285.3221\n",
      "Epoch 868/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14221.4755 - val_loss: 16674.3418\n",
      "Epoch 869/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 13982.3276 - val_loss: 14725.3013\n",
      "Epoch 870/1000\n",
      "2304/2304 [==============================] - 1s 370us/step - loss: 14150.5493 - val_loss: 12991.6504\n",
      "Epoch 871/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14241.1971 - val_loss: 14242.6713\n",
      "Epoch 872/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 14235.1650 - val_loss: 13106.2846\n",
      "Epoch 873/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14888.9844 - val_loss: 13805.2642\n",
      "Epoch 874/1000\n",
      "2304/2304 [==============================] - 1s 380us/step - loss: 14627.0407 - val_loss: 13571.2920\n",
      "Epoch 875/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14100.9699 - val_loss: 13488.7944\n",
      "Epoch 876/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14497.7654 - val_loss: 12479.8602\n",
      "Epoch 877/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 14594.8237 - val_loss: 12449.0825\n",
      "Epoch 878/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14203.2660 - val_loss: 12609.4652\n",
      "Epoch 879/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14727.8350 - val_loss: 12740.9682\n",
      "Epoch 880/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14200.1342 - val_loss: 12994.0223\n",
      "Epoch 881/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 14441.8817 - val_loss: 16508.9571\n",
      "Epoch 882/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 14590.5564 - val_loss: 12704.1016\n",
      "Epoch 883/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14141.6053 - val_loss: 14625.2396\n",
      "Epoch 884/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14457.2792 - val_loss: 13181.9282\n",
      "Epoch 885/1000\n",
      "2304/2304 [==============================] - 1s 395us/step - loss: 14154.0893 - val_loss: 13142.0646\n",
      "Epoch 886/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14099.0075 - val_loss: 12615.8368\n",
      "Epoch 887/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14432.0832 - val_loss: 13688.7647\n",
      "Epoch 888/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14763.6511 - val_loss: 12546.1383\n",
      "Epoch 889/1000\n",
      "2304/2304 [==============================] - 1s 400us/step - loss: 14257.1427 - val_loss: 15314.1020\n",
      "Epoch 890/1000\n",
      "2304/2304 [==============================] - 1s 407us/step - loss: 14685.3420 - val_loss: 12802.6904\n",
      "Epoch 891/1000\n",
      "2304/2304 [==============================] - 1s 398us/step - loss: 14311.2269 - val_loss: 13009.1204\n",
      "Epoch 892/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14441.2347 - val_loss: 13246.5764\n",
      "Epoch 893/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 13962.6542 - val_loss: 13388.3987\n",
      "Epoch 894/1000\n",
      "2304/2304 [==============================] - 1s 403us/step - loss: 14644.0992 - val_loss: 16022.9132\n",
      "Epoch 895/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14487.1708 - val_loss: 13156.4069\n",
      "Epoch 896/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14494.2526 - val_loss: 12960.4321\n",
      "Epoch 897/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14206.2011 - val_loss: 13049.3552\n",
      "Epoch 898/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14461.0843 - val_loss: 13081.9360\n",
      "Epoch 899/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14231.0203 - val_loss: 12909.8227\n",
      "Epoch 900/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14248.6927 - val_loss: 15215.5780\n",
      "Epoch 901/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14475.0888 - val_loss: 12317.9968\n",
      "Epoch 902/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14409.6735 - val_loss: 12467.8517\n",
      "Epoch 903/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 14274.7537 - val_loss: 13747.5079\n",
      "Epoch 904/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14452.9215 - val_loss: 12402.7182\n",
      "Epoch 905/1000\n",
      "2304/2304 [==============================] - 1s 410us/step - loss: 14406.0842 - val_loss: 13519.5157\n",
      "Epoch 906/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14147.5470 - val_loss: 15100.2449\n",
      "Epoch 907/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14430.0315 - val_loss: 13061.8966\n",
      "Epoch 908/1000\n",
      "2304/2304 [==============================] - 1s 392us/step - loss: 14037.1031 - val_loss: 15047.8518\n",
      "Epoch 909/1000\n",
      "2304/2304 [==============================] - 1s 404us/step - loss: 14497.5600 - val_loss: 12198.8537\n",
      "Epoch 910/1000\n",
      "2304/2304 [==============================] - 1s 411us/step - loss: 14366.8323 - val_loss: 14644.8727\n",
      "Epoch 911/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14138.7617 - val_loss: 13198.3730\n",
      "Epoch 912/1000\n",
      "2304/2304 [==============================] - 1s 387us/step - loss: 14551.6633 - val_loss: 12640.6007\n",
      "Epoch 913/1000\n",
      "2304/2304 [==============================] - 1s 395us/step - loss: 13842.8162 - val_loss: 13103.7514\n",
      "Epoch 914/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 14027.096 - 1s 406us/step - loss: 14014.5653 - val_loss: 13519.0226\n",
      "Epoch 915/1000\n",
      "2304/2304 [==============================] - 1s 406us/step - loss: 14198.5005 - val_loss: 13368.7286\n",
      "Epoch 916/1000\n",
      "2304/2304 [==============================] - 1s 399us/step - loss: 14822.5560 - val_loss: 15374.5320\n",
      "Epoch 917/1000\n",
      "2304/2304 [==============================] - 1s 402us/step - loss: 14289.0921 - val_loss: 14090.4929\n",
      "Epoch 918/1000\n",
      "2304/2304 [==============================] - 1s 414us/step - loss: 14206.7270 - val_loss: 13044.4802\n",
      "Epoch 919/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14460.7795 - val_loss: 13302.6180\n",
      "Epoch 920/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 14155.9907 - val_loss: 13949.3602\n",
      "Epoch 921/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 14249.6631 - val_loss: 13610.0707\n",
      "Epoch 922/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 13840.5041 - val_loss: 13909.9199\n",
      "Epoch 923/1000\n",
      "2304/2304 [==============================] - 1s 417us/step - loss: 13814.5286 - val_loss: 12826.1274\n",
      "Epoch 924/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14904.2527 - val_loss: 13254.0662\n",
      "Epoch 925/1000\n",
      "2304/2304 [==============================] - 1s 401us/step - loss: 14411.9720 - val_loss: 12841.3170\n",
      "Epoch 926/1000\n",
      "2304/2304 [==============================] - 1s 406us/step - loss: 14629.6957 - val_loss: 15033.8485\n",
      "Epoch 927/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14348.2908 - val_loss: 14876.2320\n",
      "Epoch 928/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14075.3151 - val_loss: 13959.1821\n",
      "Epoch 929/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14288.5601 - val_loss: 12458.3268\n",
      "Epoch 930/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14819.0479 - val_loss: 12861.2873\n",
      "Epoch 931/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 13920.4318 - val_loss: 12759.2584\n",
      "Epoch 932/1000\n",
      "2304/2304 [==============================] - 1s 410us/step - loss: 14030.5567 - val_loss: 16690.3853\n",
      "Epoch 933/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14995.1577 - val_loss: 12408.4145\n",
      "Epoch 934/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14364.7210 - val_loss: 13108.9323\n",
      "Epoch 935/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14219.7713 - val_loss: 12570.9672\n",
      "Epoch 936/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14441.0540 - val_loss: 12885.1096\n",
      "Epoch 937/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14052.5804 - val_loss: 12657.4459\n",
      "Epoch 938/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 13923.9323 - val_loss: 13260.1057\n",
      "Epoch 939/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 14013.6045 - val_loss: 13729.9309\n",
      "Epoch 940/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13959.4256 - val_loss: 12934.7212\n",
      "Epoch 941/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14320.5392 - val_loss: 13995.1145\n",
      "Epoch 942/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 14821.987 - 1s 402us/step - loss: 14817.3598 - val_loss: 12546.6118\n",
      "Epoch 943/1000\n",
      "2304/2304 [==============================] - 1s 400us/step - loss: 13632.6041 - val_loss: 12900.9206\n",
      "Epoch 944/1000\n",
      "2304/2304 [==============================] - 1s 392us/step - loss: 14375.1462 - val_loss: 12765.3758\n",
      "Epoch 945/1000\n",
      "2304/2304 [==============================] - 1s 378us/step - loss: 14128.5347 - val_loss: 14432.7357\n",
      "Epoch 946/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14197.4131 - val_loss: 13281.8154\n",
      "Epoch 947/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 14080.5850 - val_loss: 12181.3528\n",
      "Epoch 948/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14324.9667 - val_loss: 12349.6915\n",
      "Epoch 949/1000\n",
      "2304/2304 [==============================] - 1s 399us/step - loss: 14012.5511 - val_loss: 13018.6412\n",
      "Epoch 950/1000\n",
      "2304/2304 [==============================] - 1s 390us/step - loss: 14255.0074 - val_loss: 15873.9080\n",
      "Epoch 951/1000\n",
      "2304/2304 [==============================] - 1s 412us/step - loss: 14717.7372 - val_loss: 12762.9510\n",
      "Epoch 952/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13974.3436 - val_loss: 12546.4765\n",
      "Epoch 953/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 14234.0405 - val_loss: 13405.9529\n",
      "Epoch 954/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14021.4645 - val_loss: 12466.7760\n",
      "Epoch 955/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 13925.6977 - val_loss: 13453.8253\n",
      "Epoch 956/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14474.5282 - val_loss: 12504.4543\n",
      "Epoch 957/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 13990.5396 - val_loss: 12301.0943\n",
      "Epoch 958/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 13936.6069 - val_loss: 13217.6736\n",
      "Epoch 959/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 14229.4402 - val_loss: 12295.4087\n",
      "Epoch 960/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 14244.5842 - val_loss: 12878.1249\n",
      "Epoch 961/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 13966.3603 - val_loss: 13099.1012\n",
      "Epoch 962/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14448.5880 - val_loss: 13052.2593\n",
      "Epoch 963/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13804.9836 - val_loss: 13043.3453\n",
      "Epoch 964/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14432.2674 - val_loss: 12421.3675\n",
      "Epoch 965/1000\n",
      "2304/2304 [==============================] - 1s 389us/step - loss: 13866.9203 - val_loss: 12710.0364\n",
      "Epoch 966/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14118.5367 - val_loss: 12608.4325\n",
      "Epoch 967/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13863.9051 - val_loss: 12497.9934\n",
      "Epoch 968/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14055.5219 - val_loss: 12798.6343\n",
      "Epoch 969/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14203.0176 - val_loss: 12626.2237\n",
      "Epoch 970/1000\n",
      "2304/2304 [==============================] - 1s 370us/step - loss: 14280.9816 - val_loss: 12754.1671\n",
      "Epoch 971/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13951.1702 - val_loss: 12712.6477\n",
      "Epoch 972/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14304.2816 - val_loss: 17329.0146\n",
      "Epoch 973/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 15169.8071 - val_loss: 12271.1659\n",
      "Epoch 974/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14481.7509 - val_loss: 13241.9281\n",
      "Epoch 975/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13924.4217 - val_loss: 13457.2602\n",
      "Epoch 976/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 14402.3264 - val_loss: 12988.4250\n",
      "Epoch 977/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13917.5887 - val_loss: 14214.5680\n",
      "Epoch 978/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13851.6644 - val_loss: 14613.6863\n",
      "Epoch 979/1000\n",
      "2304/2304 [==============================] - 1s 375us/step - loss: 13638.6078 - val_loss: 12895.8128\n",
      "Epoch 980/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14048.2012 - val_loss: 15794.4410\n",
      "Epoch 981/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14248.7375 - val_loss: 12595.4897\n",
      "Epoch 982/1000\n",
      "2304/2304 [==============================] - 1s 378us/step - loss: 13976.9222 - val_loss: 12944.9743\n",
      "Epoch 983/1000\n",
      "2304/2304 [==============================] - 1s 380us/step - loss: 13878.1132 - val_loss: 14461.1452\n",
      "Epoch 984/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13750.8418 - val_loss: 13647.0555\n",
      "Epoch 985/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13821.2843 - val_loss: 15657.8466\n",
      "Epoch 986/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 1s 387us/step - loss: 13951.3668 - val_loss: 12503.4262\n",
      "Epoch 987/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13732.6873 - val_loss: 12674.2793\n",
      "Epoch 988/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14143.0375 - val_loss: 12801.1951\n",
      "Epoch 989/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14586.6882 - val_loss: 13891.1528\n",
      "Epoch 990/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14043.9540 - val_loss: 12848.9969\n",
      "Epoch 991/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14709.4745 - val_loss: 13196.8980\n",
      "Epoch 992/1000\n",
      "2304/2304 [==============================] - 1s 379us/step - loss: 13989.1206 - val_loss: 13358.9111\n",
      "Epoch 993/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13895.6108 - val_loss: 12177.6148\n",
      "Epoch 994/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13983.3783 - val_loss: 12892.7427\n",
      "Epoch 995/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14490.0895 - val_loss: 14749.1190\n",
      "Epoch 996/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14125.6700 - val_loss: 13738.9878\n",
      "Epoch 997/1000\n",
      "2304/2304 [==============================] - 1s 388us/step - loss: 14066.8977 - val_loss: 12453.9828\n",
      "Epoch 998/1000\n",
      "2304/2304 [==============================] - 1s 388us/step - loss: 13551.5174 - val_loss: 14619.2152\n",
      "Epoch 999/1000\n",
      "2304/2304 [==============================] - 1s 386us/step - loss: 13681.4783 - val_loss: 12727.4434\n",
      "Epoch 1000/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14083.6308 - val_loss: 13065.0160\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred=classifier.predict(df_Test.drop(['SalePrice'],axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
